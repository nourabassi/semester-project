Scientific Discourse of Citizen Scientists:A Collaborative Modeling as a Boundary ObjectJoey Huang, Indiana University, huang220@indiana.eduCindy Hmelo-Silver, Indiana University, chmelosi@indiana.eduRebecca Jordan, Rutgers University, rebecca.jordan@rutgers.eduTroy Frensley, Virginia Tech, btfren@vt.eduSteven Gray, Michigan State University, stevenallangray@gmail.comGreg Newman, Colorado State University, Gregory.Newman@colostate.eduAbstract: In this study, we examine participants’ practices in two citizen science projects inorder to explore the use of scientific knowledge and practices as they engage in collaborativemodeling. They use the Mental Modeler, an online resource to facilitate science engagementand collaboration. This paper applies an analytical approach that uses visual representations tounderstand the shifts in scientific discourse and interpret complex interaction patterns betweenparticipants and facilitators in two citizen science projects. The findings suggest that theMental Modeler serves as a boundary object that allows participants and facilitators tocollaboratively engage with scientific topics and practices through the development ofscientific discourse and learning.Keywords: citizen science, collaborative learning, scientific practices, engagementIntroductionCitizen science refers to partnerships between scientists and the public in scientific research in which real dataare collected and analyzed (Jordan, Ballard, & Phillips, 2012). Citizen science can provide opportunities forinformal learning as citizen volunteers are engaged in scientific practices, including modeling, gatheringevidence, and evaluating arguments. Most citizen science projects are contributory in which scientists design theproject and include the public in data collection (e.g., Nicosia et al., 2014). Participation tends to only involvedata collection rather than engaging in a full range of science practices. However, collaborative and co-createdprojects have great potential benefits to maintain participants’ engagement and closely address stakeholders’interests and concerns (Jordan et al., 2016). In addition, collaborative science projects can enhance publicengagement where researchers and citizen scientists collect new information and learn from each other inrelation to the local environmental issues. The processes of collaborative decision-making and project planningmay increase the capacity of scientific discourse and practices of both researchers and scientists. This studyincluded two collaborative projects in order to examine the processes of project planning, modeling, andcollaborative learning of citizen scientists.Although collaborative learning has been emphasized in science learning (e.g., Cornelius et al., 2013),it is only recently that informal online collaborative tools have been designed and used to facilitate learning andengagement in scientific practices among citizen scientists. The purpose of this study is to apply an analyticalapproach to investigate participants’ scientific knowledge, practices, and engagement with the use of onlinecollaborative tools. In addition, the analytical approach provides visual representations to better understand theshifts in scientific discourse and aid in interpretation of complex patterns between participants and facilitators ofcitizen science projects.Theoretical frameworkPublic engagement with science (PES) refers to an avenue for collaborative discourse in informal settings inwhich individuals with varied life experiences and scientific expertise participate and engage with scientificactivities or events (McCallie et al., 2009). During the process, they are able to share and articulate theirperspective, ideas, and knowledge within the scientific community of practice. However, although practices ofscientific argumentation have been considered a necessity in terms of learning and doing science, they are rarelytaught in formal education settings (Duschl et al. 2007). This study aims to illustrate and examine a designatedonline resource to better understand scientific discourse and engagement among citizen scientists.Collaborative Science (http://www.collaborativescience.org) includes a set of online resources such asvideos, scenario modeling tools, and supporting education materials on ecosystem functions, which are designedto scaffold the process of collaboration between researchers and citizen scientists. The resources provide aframework for engaging in environmental management projects through adaptive management and a modelingCSCL 2017 Proceedings399© ISLStool, Mental Modeler (www.mentalmodeler.org) (Gray et al., 2013, 2013). Mental Modeler enables analysis ofrepresentative shifts in participants’ individual and collective knowledge of their management problem. MentalModeler, shown in Figure 1 is based on Fuzzy Cognitive Mapping (FCM) which provides functionality for usersto develop concept mapping in terms of the variety and the impact strength of environmental and social factorsinfluencing their driving environmental problems (Kosko, 1986; Özesmi & Özesmi, 2004; Gray et al., 201).MentalModeler (Gray et al., 2013) can help participants track, monitor, and manage the processes of addressingecological concerns or issues related to their local environments. The practice of modeling continuallychallenges participants to reflect on and revise their ideas based on observations, serving as a working artifact tocollect and drive individual and collaborative knowledge development within a community (Wartofsky, 2012).In addition, boundary objects refer to artifacts or media, which serve as a bridging function for citizen scientistsand facilitators to communicate with each other across contexts and environments. These mental models canalso serve as a boundary object facilitating communication between the community and partners, particularlythose in scientific communities (i.e. land managers, professional researchers), by providing opportunities formore specific presentation of their concept development and feedback about their planning (Akkerman &Bakker, 2011; Hmelo-Silver, 2003). Although the Mental Modeler serves as a boundary object, we argue thatthe interactions between citizen scientists and facilitators across sites affect not only individuals but also thedifferent social and scientific practices at large. In this study, we aim to examine participants’ uses of scientificpractices as well as scientific knowledge through the development of concept mapping with the use of MentalModeler. In this study, we address the following research questions: (1) How does the opportunity to engage ina collaboratively created citizen science project afford engagement in scientific practices?; (2) How does acollaborative modeling tool serve as a boundary object that supports social practices of science that involvegenerating conjectures, constructing and evaluating models, and application of science knowledge?; (3) What isthe role of a more knowledgeable facilitator in supporting these practices?Figure 1. The Sparrow Swap Group Model.MethodsTwo groups of participants were included in the study. Participants from each group were engaged in two onehour webinar discussions. Participants had developed individual mental models before the webinars, and thegoal of the webinar discussions is to develop consensus based group models. The first webinar section wasabout model construction, and the second one focused on model refinement. The first group was called SparrowSwap, which had ten participants. A citizen scientist contacted the research team to share this project idea,which was then shared with the Virginia Master Naturalist (VMN) volunteers via email. Participants joined theproject voluntarily based on their interest. The primary goal of the Sparrow Swap project was to test theeffectiveness of replacing house sparrow eggs with artificial eggs as a technique to decrease competition withbetween native bluebirds and non-native house sparrows at nesting sites. The house sparrow eggs that wereremoved were sent to researchers for curation at the North Carolina Museum of Natural History and for testingof contaminants in the eggs to determine levels of certain pollutants in the environment. Participants used theMental Modeler to collectively develop their understanding of the key factors contributing to the complex issueof house sparrow competition on native songbirds.The second group was the Booker T. Washington Native Plantings Experiment (BOWA). Participantswere recruited via the Virginia Master Naturalists email list serve and during a presentation to the VMN chapterclosest to the Booker T. Washington National Monument. The group had 12 members and the purpose of thisCSCL 2017 Proceedings400© ISLSproject was to measure the success of native grass restoration following the removal of an invasive grass species(Johnson grass). Mental Modeler was used to help participants identify the relationships between various nativespecies and exotic Johnson grass in order to promote the success of native seed planting.During the discussion, participants from both groups developed and refined their group models.Facilitators from the research team helped guide the group discussion with the use of Mental Modeler. In thisway, participants and the facilitator could reason collaboratively and make decisions about what researchquestions they were addressing, add, changing, or revising variables, and developing a data collection plan.In order to create the initial consensus-based group models, it required two discussion sessions pergroup. Thus, the data sources were drawn from four webinars of the two groups, Sparrow Swap and BOWA,which were recorded and transcribed. Each webinar was about 72 minutes long, totaling 288 minutes, and with7-12 participants and 1-5 facilitators. Two coders scored a shared 20% of the data set, achieving a substantiallevel of interrater reliability, kappa = 0.84. One researcher coded the rest of the data. The videos were codedthrough the qualitative coding scheme presented in Table 1. The coding scheme was modified from HmeloSilver’s (2003) study, originally developed for an analysis of cognitive and social processes involved in theconstruction of a joint problem space in collaborative inquiry with a simulation. The coding scheme was adaptedin order to capture the representations of participants’ use of scientific knowledge and practices and groupdynamics and interactions and differentiate facilitators’ actions in terms of monitoring, explaining concepts, andproviding research instructions during the discussions (Hmelo et al., 2000, Hmelo-Silver et al., 2002). Thecoding scheme included 6 major categories and 24 subcategories. The first part of the coding scheme focused onthe individual level, including Knowledge used in the discussion (K1-K4), Scientific Practices related tomodeling (S1-S2), and Metacognition (M1-M4). The second part of coding scheme focused on the socialinteraction, including Questioning (Q1-Q5), Responses (R1-R6), and Facilitator(s) Input (F1-F5). Data werecoded at the unit of the conversational turn by speakers or were parsed when ideas or topics changed. Turnscould be coded on multiple dimensions. The total numbers of turns for the first webinar of the Sparrow Swapgroup was 325, and the second one was 208. In addition, the total turn numbers of initial discussion for theBOWA group was 211, and 264 for the second group discussion.To study how the conversation unfolded, we conducted a temporal analysis. The data were analyzed andrepresented via Chronologically-Ordered Representation of Discourse and Tool-Related Activity (CORDTRA)diagrams. CORDTRA diagrams provide visual representations, which can help in interpreting complex patternsand analyzing collaborative learning processes in CSCL (Computer-Supported Collaborative Learning)environments. In addition, CORDTRA analysis includes the analysis of coding schemes that quantify differenttypes of discourse moves which occurred in the discussion and a chronological picture in which multipleprocess are represented in parallel on one timeline (Hmelo-Silver et al., 2011).Table 1: Qualitative Coding SchemeCategoryCode SubcategoryKnowledgeK1Conceptual KnowledgeKnowledge expressed with justification/explanation (based on scientific practices).K2Conceptual ConjectureKnowledge expressed without justification/explanation.K3Anecdotal/Pattern ofExperienceExperience related as a one-time occurrence or story from anotherperson/Experience based on a regular observation or occurrence.K4Research ExperienceExperience related as part of previous regular field work.S1Top-downmodeling/planningRepresenting conceptual knowledge or learning more about their managementproblem/ Practical concerns.S2Bottom-upModeling/planningAdding removing components, low-level modeling and planningMonitoringChecking group progress, model components, planning concepts, or asking forother explanations.M2Evaluation /ReflectionThinking about specific actions and their outcomes.M3External resourcesSeeking expertise/resources outside of the group.M4Stakeholder ConcernsConsideration of how external social factors impact participants' planning.Q1Tool-relatedQuestions or issues pertaining to tool-useQ2Explanation relatedQuestions about causal antecedents, consequents, enabling conditions; tend to getScientificpracticeMetacognition M1QuestioningCSCL 2017 ProceedingsDefinition401© ISLSat how and why.ResponsesFacilitator(s)inputQ3DefinitionalParticipant asks definition for their ideas, or specific values related to the project.Q4ClarificationParticipant seeks verification for their ideas, or specific values related to theproject.Q5Meta questionRange of metacognitive questions to elicit meta responses, support groupdynamics or progress, self-regulated learning.R1Agreement withfacilitatorWhen participants show agreement to the views of the facilitator(s), coded incontext of facilitator(s) statement.R2Agreement with groupmemberParticipant agrees with view of their group member.R3Brief answerAnswers to general questions that do not include any explanationR4Minimal justificationAnswers that include a reason or justification.R5Elaborate justificationAnswers that include a detailed explanation to justify one's beliefs or share one'sknowledge.R6Conceptual conflictsAcknowledge or express different opinions through interaction/ over a componentof model or broader concepts involved in the project.F1MonitoringFacilitator check-in/monitor progress, and encourages participation.F2Explaining conceptsAddresses higher-level concepts that might help build the model.F3Research InstructionsFacilitators giving explicit guidance about research interventions.ResultsFor the CORDTRA diagrams (Figure 2), discourse codes were arranged in chronological order on the horizontalaxis (turn numbers). The vertical axis shows the categories of the qualitative coding scheme, from the top to thebottom, K1 to F5. Each point refers to what code(s) was/were coded at specific turn by speakers. CORDTRAdiagrams help distinguish the group dynamics and collaborative activity between two webinar sections. Theresults were also interpreted based on the percentages and frequencies of each code (Table 2). The percentageand frequency can help us to explain how cognitive engagement and communications may be different acrossthe two groups.First, for the Sparrow Swap group, participants shared more anecdotal (K3) and research experiences(K4) in the second group discussion than in the first meeting (Table 2), whereas there were slightly fewerknowledge practices (K1 & K2) shared in the second discussion. Since the first group discussion focused onidentifying the variables and defining the relationships between variables, bottom-up modeling (S2) was moreprominent in the first discussion. The second group meeting focused more on conceptual knowledge (S1) andpractical concerns (M4) for conducting the projects. Top-down modeling/planning was more prominent in thesecond discussion. The second group discussion also involved more group interactions (Questioning andResponses). The facilitators provided more monitoring for checking group progress and encouragingparticipants’ contributions in the first group meeting. In addition, the CORDTRA diagrams (Figure 2) helps usto zoom in certain time period to examine the interactions between participants and facilitator as well asscientific discourse more closely.CSCL 2017 Proceedings402© ISLSFigure 2. CORDTRA Sparrow Swap Group (Section I).To better understand the interaction, we provided an excerpt from Sparrow Swap below to illuminatehow scientific knowledge and practices are engaged while the group uses Mental Modeler. Additionally, thedata supported that the Mental Modeler tool served as a boundary object to help participants collaborativelybuild the model. In this group, Rena and Sam are the facilitators and the others are citizen scientists. Inparticular, this excerpt was selected to illustrate how the tool is a dialogical learning resource to help collectiveknowledge building. This occurred after Amy raised a question about bluebird boxes compared with naturalhabitats and the facilitator asked the group a meta-level question about what they think they should be talkingabout:01Rena:Is there a reason to specifically focus on our boxes (bluebird boxes)?02030405Amy:I think so because I mean, maybe this is jumping the gun, but we are talking aboutswapping eggs eventually so we are only going to be doing that on a bluebird trail withbluebird boxes… because bluebird population density. I mean it is going to be different ifwe have a natural habitat or just boxes. When we do this diagram. Does that make sense?06Rena:It does to me, others?07Anna:I changed it to success of bluebird nesting attempts in boxes specifically.08Rena:And so bluebird population density, how do we want to treat that in this model?091011Sam:I have questions about whether or not density is the interesting thing or is it the populationin the area, and I do not know if those are two different things... if these are two differentvariables…or just overall population.12131415Donna:I think the population in the area…and I am thinking that the population density, well themore bluebirds there are, the more likely one of them is going to choose a box, so...Unlessthere is an abundance in the natural habitat...I can't see how there would be a negativeimpact on nesting attempts if you have...high population density.16Rena:That makes sense. Do we want to keep both of these in the model (see Figure 3 below)?17181920Sam:I wonder as I hear Donna talking about it is there a feedback relationship between thedensity and success from year to year? So the more successful they are the higher thedensity, the higher the density, potentially the more success? Or is there kind of an arrowgoing one way, and an arrow going the other between these two?CSCL 2017 Proceedings403© ISLS21Amy:…I think that the more successful attempts you have the greater the population density.22Rena:Ok great.23Lee:I think it depends more on the population density of house sparrows.2425Rena:Ok, let’s look at our house sparrow population density then. What do we think anarrow…right there? Is that what you are thinking Lee?...During this five-minute conversation, participants and facilitators applied the tool as a boundary object todiscuss the components and the relationships between the components (Figure 3) as they engage in bottom-up andtop-down modeling/planning (Line 02-05). This suggests that they were reacting to issues raised in the discussion.Donna applied conceptual knowledge based on her pattern of experiences in Lines 12-15 with justification based onscientific practices to justify the connection between population density and bluebirds’ nesting attempts. The processof collaborative decision-making was dynamic and dialogical based on the use of the Mental Modeler (Line 16-25).Figure 3. Sparrow Swap model excerpt (Turns 91-105) that focuses on components that participantschanged.For the BOWA group, there are three major findings. First, more frequent and dense conceptualknowledge/conjecture (K1 and K2) was found during the second group meeting (Table 2). In addition, more ofthe individuals’ anecdotal and patterns of experiences (K3) were shared among participants in the second groupdiscussion, which means participants applied the experiences related as an one-time occurrence or based on aregular observation rather than an research experience which involves regular field work. Also, top-downmodeling and planning (S1), monitoring (M1), seeking external resources (M3), and stakeholder concerns (M4)also appeared more frequently in the second group discussion. However, there was less facilitator monitoring(F1), explaining concepts (F2), and research instructions (F3) during the second group discussion.More bottom-up modeling/ planning (S2) tasks were observed during the first group meeting for bothprojects. This finding suggests that participants began with a stage of defining system components and adding orremoving variables from the model. Once the variables and their relationships were determined after the firstdiscussion, participants shifted their discussions to top-down modeling/planning (S1), representing conceptualknowledge, and showing practical concerns and management problems. Although space precludes including theCORDTRA diagrams here, our visual inspection shows that how top-down versus bottom-up planning appeareddifferently throughout the two sections of webinar. Furthermore, the monitoring (M1) and facilitator monitoring(F5) codes were shared among participants and facilitators for most of time across all four webinar sections. Inaddition, facilitators’ inputs (F1-F3) were more frequent in the beginning and close to the end of discussions.Because there was more explaining and guiding during the first group discussion, facilitators’ inputs were codedmuch more frequently in the first than the second group discussion.Table 2: Frequency and Percentage Results of Sparrow Swap & BOWA GroupsSparrow SwapCategoryCodesCSCL 2017 ProceedingsI (325 Turns)BOWAII (208 Turns)404I (211 Turns)II (264 Turns)© ISLSFrequencyKnowledgeScientific PracticesMetacognitionQuestioningResponsesFacilitator(s) input%Frequency%Frequency%Frequency%K16319.44019.25727.07227.3K2237.1115.3178.13011.4K3278.3209.6104.7197.2K461.8104.831.431.1S1226.85626.94119.47729.2S214344.02411.55224.65320.1M117252.96732.29344.113450.8M2164.93516.83818.03312.5M320.662.994.3259.5M400.0104.894.32810.6Q1144.3136.362.820.8Q2175.2115.3115.2166.1Q330.910.531.400.0Q4216.5188.7125.7166.1Q55216.02713.04621.83814.4R1144.352.4136.2176.4R2185.5146.72411.43312.5R37422.85727.44923.27528.4R4278.33014.42913.7269.8R541.2104.883.8124.5R6134.073.462.8176.4F113441.27134.19243.67628.8F2103.1188.7188.5114.2F372.2157.283.851.9Conclusions and significanceThis study investigated changes over time in terms of scientific practices, monitoring, and interactions for twodifferent citizen science projects mediated by group modeling practices. The first webinar section focused onmodel construction, and the second one was about model refinement. Applying qualitative coding schemeshelped us to examine the process of negotiation and group interactions and identify different phases of activityand patterns of action. In particular, the way in which participants applied scientific knowledge and practices inmodeling and planning in different phases of group discussion, the overall relation of the discourse betweenfacilitators and participants, and the timing of facilitator input during the discussion suggest that collaborativemodeling provides a context for rich discussions with respect to collaborative problem-solving and decision-CSCL 2017 Proceedings405© ISLSmaking. The results suggested that these co-created citizen science projects provided participants withopportunities to work collaboratively and facilitated engagement in scientific practices. Additionally, thissupports our conjecture that the models serve as boundary objects for engaging in science practices such asdeveloping and using modeling, clarifying and identifying system components, and constructing solutions. Wefound there were patterns for group modeling in terms of shifting from bottom-up level to top-down level ofdiscussions. The findings related to the timing of facilitator input suggest that facilitator engagement wasstrongest in initiating and framing discussions and helping to wrap up the sessions with implications forengagement and ownership of the model as a shared object for negotiation of ideas and knowledge related to theenvironmental issue that the group was addressing. The facilitators’ inputs were less involved in the secondsessions for model refinement, which indicated the growth of engagement among participants. This studydemonstrates how a collaborative modeling tool can serve as a boundary object that allows citizen scientists andfacilitators can engage in meaning making around scientific practices. This suggests that CSCL research andpractice can contribute to public engagement in science accessible to a broader citizenry.ReferencesAkkerman, S. F., & Bakker, A. (2011). Boundary crossing and boundary objects. Review of educationalresearch, 81(2), 132-169.Cornelius, L. L., Herrenkohl, L. R., & Wolfstone-Hsy, J. (2013). Organizing collaborative learning experiencesaround subject matter domains. In C. E. Hmelo-Silver, C. A. Chinn, C. K. K. Chan & A. M. O'Donnell(Eds.), The international handbook of collaborative learning (pp. 333- 350). New York: Routledge.Duschl, R. A., Schweingruber, H. A., & Shouse, A. W. (Eds.). (2007). Taking science to school: Learning andteaching science in grades K-8. National Academies Press.Gray, S. A., Gray, S., Cox, L. J., & Henly-Shepard, S. (2013, January). Mental modeler: a fuzzy-logic cognitivemapping modeling tool for adaptive environmental management. In System Sciences (HICSS), 2013 46thHawaii International Conference on (pp. 965-973). IEEE.Gray, S. A., Zanre, E., & Gray, S. R. J. (2014). Fuzzy cognitive maps as representations of mental models andgroup beliefs. In Fuzzy Cognitive Maps for Applied Sciences and Engineering (pp. 29-48). SpringerBerlin Heidelberg.Hmelo-Silver, C. E., Jordan, R., Liu, L., & Chernobilsky, E. (2011). Representational tools for understandingcomplex computer-supported collaborative learning environments. In Analyzing interactions in CSCL(pp. 83-106). Springer US.Hmelo‐Silver, C. E., Nagarajan, A., & Day, R. S. (2002). “It's harder than we thought it would be”: Acomparative case study of expert–novice experimentation strategies. Science Education, 86(2), 219-243.Hmelo, C. E., Nagarajan, A., & Day, R. S. (2000). Effects of high and low prior knowledge on construction of ajoint problem space. The Journal of Experimental Education, 69(1), 36-56.Hmelo-Silver, C. E. (2003). Analyzing collaborative knowledge construction: Multiple methods for integratedunderstanding. Computers & Education, 41(4), 397-420.Jordan, R. C., Ballard, H. L., & Phillips, T. B. (2012). Key issues and new approaches for evaluating citizen‐science learning outcomes. Frontiers in Ecology and the Environment, 10(6), 307-309.Jordan, R., Gray, S., Sorensen, A., Newman, G., Mellor, D., Hmelo‐Silver, C., ... & Crall, A. (2016). Studyingcitizen science through adaptive management and learning feedbacks as mechanisms for improvingconservation. Conservation Biology, 30(3), 487-495.Kosko, B. (1986). Fuzzy cognitive maps. International Journal of man-machine studies, 24(1), 65-75.McCallie, E., Bell, L., Lohwater, T., Falk, J. H., Lehr, J. L., Lewenstein, B. V., ... & Wiehe, B. (2009). Manyexperts, many audiences: Public engagement with science and informal science education. A CAISEInquiry Group Report, 1-83.Özesmi, U., & Özesmi, S. L. (2004). Ecological models based on people’s knowledge: a multi-step fuzzycognitive mapping approach. Ecological modelling, 176(1), 43-64.Wartofsky, M. W. (2012). Models: Representation and the scientific understanding (Vol. 48). Springer Science& Business Media.CSCL 2017 Proceedings406© ISLS