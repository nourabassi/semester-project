Who Signs Up and Who Stays? Attraction and Retention in anAfter-School Computer-Supported ProgramMaggie Renken, Jonathan Cohen, Tugba Ayer, Brendan Calandra, and Aeslya Fuquamrenken@gsu.edu, jcohen@gsu.edu, tayer1@student.gsu.edu, bcalandra@gsu.edu, afuqua2@student.gsu.eduGeorgia State UniversityAbstract: We report findings from a study assessing computer-supported curriculum designedto engage low SES, underrepresented minority middle school students enrolled in an afterschool program with collaborative tasks that build 21st century skills, particularly related todigital literacy. Early in the program, we collected survey data from participants and from asample of after-school attendees who decided not to enroll in our program concerning theirgoals, feelings toward STEM, and experiences with and access to technology. Over the first 7weeks of programming, we also have collected attendance records. We report findings relatingstudents’ individual factors at program onset to their attraction to and retention in our program.Our findings shed light on important issues relevant to the CSCL community and the conferencetheme, including identifying potential for attrition among students and engaging a diverse poolof students in computer-supported collaborative learning.BackgroundComputer-supported collaboration has the potential to impact student learning in a personalized and engagingway (Jeong & Hmelo-Silver, 2016). Such programs may be particularly suited to increase interest and broadenparticipation to include underrepresented groups in STEM fields (Margolis, Ryoo, Sandoval, Lee, Goode, &Chapman, 2012; Peterson & Britsch, 2013). Recent initiatives and reports from national funding agencies placeemphasis on developing and evaluating the impact of such programs on student outcomes (e.g., 2014 Science andEngineering Indicators, National Science Board, 2014; Innovative Technology Experiences for Students andTeachers (ITEST), National Science Foundation, 2016). Before we can begin to consider the effect of computersupported educational programs on students’ interest and learning in STEM subjects, we must understand thecomplex issues associated with attracting and retaining students in these programs.Attraction and retention are particularly challenging when educational programs are housed in informalsettings (e.g., outside of the classroom), in which participation is not compulsory, and when working withadolescents from populations that are typically underrepresented or even marginalized in the targeted STEMdomains (Bell, Lewenstein, Shouse, & Feder, 2009; Hernandez et. al, 2013). Weisman and Gottfredson (2001)assessed 8 Maryland-based after school programs for youth in grades 4-8 from 1998 to 1999. 80% of their sampleself-reported race as Black, or non-White. Although the focus of their work was on relations between at-riskbehavior and retention in after school programming, they also found a third of program dropouts reported beingbored. The implication is that to recruit and maintain enrollment in such programs, activities must holdparticipants’ interest.The research reported here starts at a crucial point. First, we analyze patterns in student attendance anddetermine factors associated with student retention in a computer-based after-school program. Second, weexamine differences in factors across a subsample of students who chose to participate in our program and thosewho did not. Specifically, we consider students’ gender, goals, prior experiences, and access to technology asfactors that may influence students’ decision to participate in our program and to continue attending over time.Prior work supports relations between gender and interest in STEM (e.g., Peterson & Britsch, 2013); betweengoal orientation and persistence in STEM programs (e.g., Hernandez et al, 2013); and between experiences withand access to technology and STEM achievement (e.g., Judge, 2005). We extend this work to consider theserelations in an informal computer-supported program for Black or African American middle school students inan urban setting. We expect the findings we present here and any resulting discourse among researchers withsimilar aims to advance efforts in line with those of the CSCL 2017 Conference Theme, prioritizing equity andaccess in CSCL.MethodStudy contextFollowing two beta tests of an online learning environment (OLE), we are currently conducting a pilot test of asemester long curriculum that embeds the OLE. The pilot test described here is the first part of a design-basedCSCL 2017 Proceedings359© ISLSstudy to take place over 3 years to develop and assess informal after-school educational programming that fostersstudents’ 21st century skills through their participation in mock technology start-ups which develop products (e.g.,mobile applications) addressing some culturally relevant problem space. Our programming is housed within apre-existing, well-established after-school program at a single school site. The existing after-school program isstructured so that students may select activities to participate in from a menu of activities. Our program was listedamong others on a flyer describing program offerings and distributed to students. Students were free to self-selecttheir activities for the semester. At the writing of this paper, the semester-long pilot program is still underway.Our data are derived from the first 7 weeks of programming.ParticipantsTwenty-seven students have attended at least one session of programming over the first 7 weeks of programming,and fifteen of these attended more than one session. Eighteen of the participating students completed an onlinesurvey and served as a treatment group for the purposes of the current study. Of those, 16 participants reportedtheir race/ethnicity. Of these 16, 100% reported Black or African American as their race/ethnicity. Participantswere allowed to select multiple race/ethnicity identifications, and one participant selected Hispanic or Latino inaddition to Black or African American. 31% of participants with survey data were male and 69% were female. Ofall 27 participating students, 9 (33%) were male and 18 (67%) were female. All students were in middle schoolgrades. Participants’ ages ranged from 11-14, which is typical for American middle school grades.In addition to collecting data with participants enrolled in our program, we also collected data with 21students in the broader afterschool program who were not enrolled in our program. These participants served as acomparison group. Comparison group participants were those who did not elect to be in our program, and selectedanother offering instead. 62% of these participants were male and 38% were female ranging in age from 11-14.Of the 18 students who reported their race/ethnicity, 16 self-reported as Black or African American; two studentsselected Native American in addition to Black or African American.Design and procedureOver the course of 4 sessions for the treatment group and 3 sessions for the comparison group, a team of 1-6researchers visited the school site to collect data. Students who provided assent to participate in researchcompleted an online survey housed on Qualtrics. Items for each of the survey instruments described below werepresented in blocks. Blocks of items were randomized across students. While students worked on the survey atindividual computers in a group computer lab setting, students were pulled aside to work individually on a tabletbased Scratch Jr. task with a researcher observer. This task took 10 minutes to complete, and when studentsfinished, they returned to where they left off in the online survey. This procedure was the same for treatment andcomparison groups.Survey instrumentsStudent goals for and interest in the programStudents answered a multiple-choice, multiple-select question that included the following goals for theirparticipation in the program: “I want to have fun,” “I want to understand how to do stuff,” “I want to be betterthan my AMAYS groupmates,” and “I do not want to fail.” A second forced-choice question measured studentinterest in the program, with choices such as, "I can't wait to get started!" and "I'm not very interested, and I don'twant to do it."STEM Semantic SurveyThe STEM Semantic Survey includes 5 items concerning one’s feelings about STEM domains (science,technology, engineering, math, and STEM careers) (see Christensen, Knezek, & Tyler-Wood, 2014). Itemresponses are presented as dichotomous word-pairs (e.g., “interesting/boring” and “exciting/unexciting”), andstudents were asked to make selections on a 7-point scale, in which 7 indicated the highest affinity toward thedomain.Prior experience with technologyStudents answered a series of questions about the extent of their prior experience with technology. These itemsmeasured the students' technological education and prior use of both software, such as app building, and hardware,ranging from scanners to tablets. Questions about experience (e.g., “Have you ever worked with computer designtools?”) were presented as multiple choice questions with “yes,” “no,” or “I’m not sure,” as answer choices. If thestudent selected “yes,” the student then answered a clarifying question about where that experience occurred byCSCL 2017 Proceedings360© ISLSselecting one or more responses, including “at home for fun,” “at home for a project,” “at school for fun,” “atschool for a project,” “I’m still not sure,” and/or “some other place.” Students also had the option to elaboratefurther in a text box. These questions were derived from Barron, Walter, Martin, and Schatz (2010).Access to technologyWe also asked students where they had access to technology and to what degree. Items regarding electronic access(e.g., “Which tools and electronics do you have at home?”) were presented as multiple choice with the option toselect more than one answer. Students were asked to answer questions measuring frequency (e.g. “How often doyou use a computer in classes at school?”) by making selections on a 5-point scale in which 1 indicated “never”and 5 indicated “almost every day.” These questions also were derived from Barron, Walter, Martin, and Schatz(2010).ResultsAttraction to program: Individual factors in treatment vs. comparison groupsGenderBecause students could self-select into our program (i.e., treatment group) or some other afterschool activity (i.e.,comparison group), we consider differences in individual factors across the treatment and comparison groups toexamine factors related to attraction to our program. With regard to gender, among students who completed theonline survey measures, 33% of the treatment group participants was male and 67% was female, while 55% ofthe comparison group was male and 45% was female. A χ2 test of a 2 (condition) x 2 (gender) contingency tableindicated that gender composition did not differ across the treatment and comparison groups (χ2 = 2.03, df = 1, p= not significant).Mean Domain ScoreStudents’ feelings toward STEM and attraction to the programNext, we considered students’ feelings toward STEM domains, according to STEM Semantic Survey, acrosscondition (treatment vs. comparison). We assessed reliability of the domain scales within conditions. The itemsconverged in every domain except the STEM careers domain. We excluded STEM careers from analysis.Cronbach’s alpha ranged from .56 to .94 for the 4 remaining domain subscales (science, technology, engineering,and math).The mean technology domain score was 6.35, with a standard deviation of 1.54. One participant in thetreatment group responded to all of the items in the technology domain with a 1. With this student removed as anoutlier, the mean score on the technology scale rose to 6.68 (SD =.71), with a minimum score of 4.6 and maximumof 7. Subsequent analysis was run with the outlier excluded. We ran independent samples t-tests with conditionas the independent variable and mean domain score as the dependent variable for each of the four domains.Science was the only domain for which students’ feelings differed significantly as a function of condition (Figure1). Participants in the treatment group had more negative feelings toward science than did those in the comparisongroup (t = -4.73, df = 34, p < .001). Although not significantly different, we also point to the trend concerning thetechnology domain. This is the only domain for which the treatment group expressed more positive feelings thandid the comparison group. Within the treatment group only, a t-test of domain score as a function of domain(science vs. technology) revealed that mean student feelings toward technology were significantly greater thanstudent feelings toward science (t = 5.50, df = 33, p < .001).76543210treatment groupcomparison groupsciencetechnologyengineeringmathFigure 1. Students’ mean domain scores for both the treatment and comparison group in all 4 STEM domains.CSCL 2017 Proceedings361© ISLSPrior experience and attraction to the programTo consider the relation between students’ prior experiences with technology and their attraction to the program,we conducted chi-square tests of 2, 2 x 2 contingency tables: have you programmed before (yes vs. no) x condition(treatment vs. comparison) and have you tried to build an app before (yes vs. no) x condition (treatment vs.comparison). There was no difference in the treatment and comparison groups concerning prior experienceprogramming. There was, however, a significant difference in prior experience trying to build apps acrosscondition. The majority of participants in the treatment group (67%) had never tried to build an app before, whilethe majority of participants in the comparison group (61%) had (χ2 = 2.79, df = 1, p = .09).Access to technology and attraction to the programParticipants in the treatment group reported the most often computer use occurred at their own homes (mean use,treatment group = 4.28, SD = 1.18). The average number of computers treatment group participants reportedhaving at home was 2.5 (SD = 1.04). A t-test of independent samples revealed that neither of these means reportedby the treatment group differed significantly from the self-reports of comparison group participants (meancomputer use at home, comparison group = 4.06, SD = 1.09; mean number of computers at home, comparisongroup = 2.88, SD = .928).Patterns in attendance among treatment groupBeyond who decides to sign up for our program, we are interested in the profiles of students who continue toattend once they have signed up. At the writing of this paper, attendance data for the treatment group have beencollected for seven weeks of programming. During these 7 weeks, the program staff and students have met 2 daysper week for an hour and half per session. Programming has been interrupted with one holiday and one internalschool-based conflict, for a total of 12 days, or sessions, of programming. Average attendance for those 12sessions was 7 students (max 10, min 2, median 8).Twenty-seven students have attended at least one session in the first 7 weeks of programming. Individualstudents’ attendance ranged from 1 to 7 sessions of programming. In other words, the fewest number of sessionsany student attended was 1, while the greatest number of sessions any student attended was 7. On average, studentsattended 3 days of programming (SD = 2.12). Absenteeism between sessions was common for returning students.In other words, days in attendance did not always occur back-to-back. For the 15 students who attended more than1 session, the average time spent in the program was between 5 and 6 sessions from start to finish (SD = 3).Eighty-three percent of the students with online survey data attended more than one session. For students whocompleted the online survey, the mean total days of programming attended was 3.56 (standard deviation = 2.25,min 1, max 7). For the students who attended more than 1 session and completed the online survey, the spacingof sessions from first attended to last attended ranged from 2 to 12, with mean = 5.69 and standard deviation =3.03. Overall, patterns in attendance for students who completed the online survey do not differ markedly fromthe entire sample of students.To better understand patterns of attendance and how they related to individual factors, we consideredwho stayed in the program and who did not. This framing results in 3 categories of students: those who continueto attend the program, those who do not continue to attend the program, and those who started attending theprogram late. In what follows, we refer to these categories of students as stayers, leavers, and late starters,respectively. To quantify who stayed, left, and started late, we set a session midpoint between sessions 6 and 7.We computed the number of sessions students attended prior to the midpoint (pre-midpoint) and following themidpoint (post-midpoint). Stayers (n = 10) were students who attended sessions pre- and post-midpoint. Latestarters (n = 9) were students with attendance only post-midpoint. Leavers (n = 8) were students who attendedsessions prior to the midpoint only (Figure 2). This distinction allows us to consider the relation betweenindividual factors and attendance, in subsequent analysis, by not only considering total sessions attended, but byalso considering differences in students who are retained in the program and those who are not.CSCL 2017 Proceedings362© ISLSFigure 2. Participant attendance over a 12-session period.Retention in program: Individual factors and attendance among the treatment groupGenderIncluding all 27 participants in the program, even those who did not complete the survey, we considered therelation between gender and retention (Figure 3). More females (18) participated in programming than males (9)overall. A χ2 test of a 2 x 2 contingency table considering differences in leavers and stayers across gender revealedthere was no significant difference in the proportion of females who stayed in the program and males who stayedin the program (χ2 = .06, df = 1, Fisher’s Exact test p = 1.00, not significant).FemaleMale01234Late StartersLeaver5678StayerFigure 3. The number of females and males who stayed in the program, who left the program, and who startedthe program post midpoint.Student goals for participation in program72.2% of students reported more than one goal for their participation in the program. The 4 goals were notcorrelated. As demonstrated in Figure 4, the most highly endorsed goals were “I want to understand how to dostuff” (83% of sample endorsed) and “I want to have fun” (72% of sample endorsed), while “I want to be betterat this than everyone else in the group” was least often endorsed (by only 33% of sample).CSCL 2017 Proceedings363© ISLSI want to have fun.5I want to understand how to do stuff.133I don't want to fail.158I want to be better at this than everyone else in the group.101260% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%not selected as a goalselected as a goalFigure 4. Students’ goals for participation in the program.Mean days in attendanceTo determine whether students’ goals for participation were related to their retention in the program, we ran fourindependent t-tests to compare mean attendance across students’ goals. None of the t-tests indicated statisticallysignificant differences in mean attendance. We note that this may be an issue of power due to our small samplesize. We also point out a practically important difference (despite no statistically significant difference) in meanattendance for students who indicate they want to understand how to do stuff versus those who do not. Studentswho want to understand attend almost 5 days on average, while those who do not want to understand only attendan average of 3 days (Figure 5). Hedges’ g (an effect size measure designed to account for different sample sizes)confirms this is a moderate effect and is .71.5not selected as a goalselected as a goal43210I want to better at thisthan everyone else in thegroup.I don't want to fail.I want to understandhow to do stuffI want to have fun.Figure 5. Mean attendance as a function of students’ self-reported goals for participation in the program.Students’ feelings about the activities and participationStudents were asked to report how they felt about the activities in which they signed up to participate (Table 1).Only 1 of the 3 students who did not report being excited to get started was a leaver, one was a stayer, and onewas a late starter. The leaver and stayer answered, “...a little interested, but okay doing something else.”Table 1. Students’ feelings about the activities in which they signed up to participate.Item ResponseNot very interested, and I don’t want to do it.I’m not sure because I don’t know enough about what I'll be doing.I’m a little interested, but I’m ok with doing something else.I can’t wait to get started!Frequency01214% Selecting0%6%12%82%Students’ feelings toward STEM and participationCSCL 2017 Proceedings364© ISLSWe ran one-way analysis of variance (ANOVA) for the 4 STEM domains assessed with the STEM SemanticsSurvey (science, technology, engineering, and math), with attendance category (leaver, stayer, late starter) as thefactor and domain score as the dependent variable. Attendance category was significantly related to domain scorefor the technology and math domains (technology: F = 3.05, df = 2, p = .08; math: F = 3.58, df = 2, p = .05).According to a Tukey’s post hoc test, late starters (Mean = 5.08, SD = 2.49) had significantly less positive feelingstoward technology than leavers (Mean = 7.00, SD = 0) and stayers (Mean = 6.84, SD = .47). Leavers (Mean =3.60, SD = 3.08) had significantly less positive feelings toward math than stayers (Mean = 6.38, SD = .76) andlate starters (Mean = 5.53, SD = 1.61).Prior experience with technology and attendanceWe asked participants if they had ever tried to build an app before. 67% (12) said they had not, and 33% (6) saidthey had. We also asked them if they had programmed or coded before. 56% (10) said they had not, and 44% (8)said they had. We ran an independent samples t-test with attendance as the dependent variable and whether or notthey had built an app before as the independent variable. Students who had never built an app before attendedsignificantly fewer sessions (mean attendance = 1.67, SD = .52) than those who had built an app before (meanattendance = 4.25, SD = 2.18) (t = 2.82, df = 16, p = .01). There was no difference in attendance as a function ofprior experience programming (mean attendance, no programming = 3.50, SD = 2.46; mean attendance,programming = 3.25, SD = 1.91).Access to technology and attendanceWe asked students how often they used computers at home, at school, at a friend’s house, or somewhere in thecommunity on a scale of 1-5 (never to almost daily). We computed the mean across these items. The amount ofcomputer use at home and the number of computers owned at home was not significantly correlated with thenumber of days students attended programming.Conclusions and implicationsStudents’ feelings about STEM, their goals, and experiences are relevant to their attraction and retention ininformal computer-based education programs. Participants in our program reported liking technology more thanscience. Participants wanted to understand how to “do stuff” and have fun. But they attended less often if theirgoal was to understand and if they had never built an app before. They were less likely to have built an app beforethan their peers who did not enroll in the program. However, participants were just as likely to have access totechnology as were non-participants, and access was not related to their attendance in the program. We attractedmore females than males, but participants were equally likely to leave, stay, or start the program late regardlessof their gender. Overall, participants were excited to participate in the program, and those who were attracted tothe program from the beginning had the most positive feelings about technology.We often design programs with strong theoretical underpinnings without thinking carefully about ourstudents as consumers. Such programs are designed to broaden participation but may fall short by not broadeningattraction. Unfortunately, this means, especially in informal settings, we may be missing the very students suchprograms are in place to reach and impact. As our research continues, the question will be whether or not theirinterests deepen or expand over time. Given their positive attitudes coming into a self-selected program, we willneed to be especially thoughtful about how to best measure changes in the quality or nature of their interests overtime. Tracking emotional and cognitive interests coupled with explicit task meaningfulness descriptions couldhelp preserve program interest and reduce attrition (Hidi and Renninger, 2006). Our findings also seem to suggestcurriculum that is novel in addition to being interesting may be most attractive and engaging for these studentswho already have access to rich extra-curricular afterschool programming.Although retention among females did not differ among males, we attracted twice as many females asmales into the program. We expect this may have something to do with the collaborative nature of the program,which may have appealed to participants who have an affinity for communal goals (Diekman & Steinberg, 2013).Further, students were charged with working in tech start-ups to address a socially relevant problem. As previousresearch has shown that females often have an affinity for social causes (Paulin, Ferguson, Schattke, & Jost, 2014),this may have been an additional factor in attracting female participants to the program.Perhaps our most surprising finding was that students who want to understand “how to do stuff” are lesslikely to be retained. This may have to do with the rigor of the program. However, work avoidance stemmingfrom unexpected increased rigor could negatively impact student engagement in students who want to have funat the same time (Dowson & McInerney, 2001). Future research should address our loss of students with a moremastery orientation, for instance, by interviewing students who do not stay in the program.CSCL 2017 Proceedings365© ISLSOur study is not without limitations. We do not know about the activities that students who do not selectour program enroll in. For instance, competing programs may be attracting males. We expect, given ourknowledge of the setting and programming, that males were more likely involved in sports during the fallsemester, which conflict with our program, but we do not have data to support this possibility. Programmingconflicts are also likely responsible for the negative feelings toward math among leavers. We are aware of a mathtutoring session that conflicts with our program, and students are encouraged to attend if they are doing poorly inmath at school.These findings contribute to our understanding of the complex issues associated with attracting andretaining students in an after-school, STEM-focused computer-supported program for urban, low-SES, Black, orAfrican American, students. The national focus on these programs as on-ramps to the STEM pipeline is unlikelyto diminish any time soon, and significant attention is being paid, quite correctly, to the design of these programs.However, the ultimate effectiveness of these programs is dependent on getting students in the door and keepingthem there, and these findings can help designers to attend to issues of attraction and retention in their curricula.ReferencesBarron, B., Walter, S. E., Martin, C. K., & Schatz, C. (2010). Predictors of creative computing participation and profilesof experience in two Silicon Valley middle schools. Computers & Education, 54(1), 178–189.https://doi.org/10.1016/j.compedu.2009.07.017Bell, P., Lewenstein, B., Shouse, A.W., & Feder, M. (2009). Learning Science in Informal Environments: People,Places, and Pursuits. Washington, DC: The National Academies Press.Christensen, R., Knezek, G., & Tyler-Wood, T. (2014). Student perceptions of Science, Technology, Engineering andMathematics (STEM) content and careers. Computers in Human Behavior, 34, 173–186.https://doi.org/10.1016/j.chb.2014.01.046Diekman, A.B., & Steinberg, M. (2013). Navigating social roles in pursuit of important goals: A communal goalcongruity account of stem pursuits. Social and Personality Psychology Compass, 7(7), 487-501.Dowson, M., & McInerney, D. (2001). Psychological parameters of students’ social and work avoidance goals: Aqualitative investigation. Journal of Educational Psychology, 93(1), 35-42. doi: 1O.1O37//0022-0663.93.1.35Hernandez, P. R., Schultz, P. W., Estrada, M., Woodcock, A., & Chance, R. C. (2013). Sustaining optimal motivation:A longitudinal analysis of interventions to broaden participation of underrepresented students in STEM.Journal of Educational Psychology, 105(1), 89–107. https://doi.org/10.1037/a0029691Hidi, S., & Renninger, K. A. (2006). The Four-Phase Model of Interest Development. Educational Psychologist, 41(2),111–127. https://doi.org/10.1207/s15326985ep4102_4Jeong, H., & Hmelo-Silver, C. E. (2016). Seven Affordances of Computer-Supported Collaborative Learning: How toSupport Collaborative Learning? How Can Technologies Help? Educational Psychologist, 51(2), 247–265.https://doi.org/10.1080/00461520.2016.1158654Judge, S. (2005). The Impact of Computer Technology on Academic Achievement of Young African AmericanChildren. Journal of Research in Childhood Education, 20(2), 91–101.Margolis, J., Ryoo, J. J., Sandoval, C. D. M., Lee, C., Goode, J., & Chapman, G. (2012). Beyond access: broadeningparticipationinhighschoolcomputerscience.ACMInroads,3(4),72.https://doi.org/10.1145/2381083.2381102NationalScienceFoundation(2016).ITESTProgramSolicitation.Retrievedfromhttps://www.nsf.gov/funding/pgm_summ.jsp?pims_id=5467National Science Board (2014). Science and Engineering Indicators 2014. Arlington VA: National Science Foundation.Paulin, M., Ferguson, R.J., Schattke, K., & Jost, N. (2014). Millennials, social media, prosocial emotions, and charitablecauses: The paradox of gender differences. Journal of Nonprofit & Public Sector Marketing. 26. 335-353. doi:10.1080/10495142.2014.965069Weisman, S. A., & Gottfredson, D. C. (2001). Attrition from after school programs: characteristics of students who dropout. Prevention Science: The Official Journal of the Society for Prevention Research, 2(3), 201–205.AcknowledgmentsThis research is based upon work supported by the National Science Foundation under Grant Number (NSF GrantNumber 1433280).CSCL 2017 Proceedings366© ISLS