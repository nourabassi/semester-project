Technology-Mediated Teacher Noticing: A Goal for ClassroomPractice, Tool Design, and Professional DevelopmentJanet Walkoe, University of Maryland, jwalkoe@umd.eduMichelle Wilkerson, University of California, Berkeley, mwilkers@berkeley.eduAndrew Elby, University of Maryland, elby@umd.eduAbstract: We introduce technology-mediated teacher noticing (TMTN): a vision for thedesign and use of technology-mediated tools that takes seriously the need for teachers toattend to, interpret, and respond to their students’ thinking. This vision is situated at theintersection of research on teacher noticing, and on technology to support student thinking.We synthesize that work to highlight specific ways that technology-mediated classroom toolscan focus and stabilize teachers’ attention on valuable aspects of student thinking emphasizedby current reform efforts. We then illustrate TMTN with classroom examples in whichtechnology supported or obstructed teachers' attention to student thinking, and considerimplications for research on technology in teacher practice, professional development, and thedesign of technological tools for K-12 classrooms.ObjectivesEducational technology has exploded over the past few decades, and many tools have been created to helpstudents think deeply about disciplinary concepts. In many cases these tools have been shown to further studentlearning, conceptual understanding, efficacy and affect, and motivation. In short, if used productively within abroader classroom culture of inquiry these tools have the power to transform student learning.Educators often argue that curricular materials are created for teachers as much as for students (e.g.,Ball & Cohen, 1996). Yet this idea has not carried over to discussions of technological tools for classroom use.While some research has looked at how such tools can reveal and support student thinking in a given domain,the primary focus has been the students’ experience. The teacher’s contribution to student learning within suchenvironments is often treated as an afterthought. More research is needed that explores teachers’ role infacilitating student learning while using technologically mediated tools, especially in specific content domains;and more attention is needed in educational technology design to supporting teachers in noticing, attending, andresponding to core disciplinary aspects of students’ thinking.Much work that explores teachers’ use of technology (e.g. Mishra & Koehler, 2006) focuses onteachers’ use, non-use, or competency with technology in general, or their beliefs about how and when to usetechnology. Other work explores how teachers design or modify curricula based on feedback from systems (e.g.Kali, McKenney, & Sagy, 2015). However, this focuses on evaluation—whether students answer correctly—andbackgrounds the substance of student thinking, which can include productive ideas on which teachers can helpstudents build. In contrast, we are interested in exploring how teachers can use technology-mediated tools tonotice new and different aspects of their students’ thinking in ways consistent with reform efforts andstandards—for example, by supporting teachers’ attention to reasoning about mechanism in science (NGSS,2013), or pattern in mathematics (CCSS-M, 2010). In this paper, using classroom data for illustration, we arguethat (i) designers and researchers of educational technology have not foregrounded supporting or studying theteachers’ noticing of substance of student thinking as mediated by technological tools, but (ii) such technologymediated teacher noticing (TMTN) should play a role in teacher professional development, research onclassroom teaching, and the design of technological tools for classroom use.Related workIn mathematics and science instruction, teacher noticing of the disciplinary substance of student thinking iscritical for student learning (Schifter, 1998; Franke, Carpenter, Levi, Fennema, 2001; Carpenter, Fennema,Peterson, Chiang & Loef, 1989). Therefore, both teacher professional development and curricular design haveaimed to support teacher noticing (Sherin & van Es, 2009). However, teacher noticing has yet to influence thedesign, study, and implementation of technological tools in the classroom. Here, we briefly review the literatureon teacher noticing/teacher responsiveness, and on the design and use of technological tools to support studentthinking. Then we investigate the intersection of these two literatures, to situate and inform our notion oftechnology-mediated teacher noticing.CSCL 2017 Proceedings65© ISLSTeacher noticing and responsivenessA growing literature focuses on teachers’ noticing of, attention to, and responses to the substance of studentthinking (Sherin, Jacobs, & Philipp, 2011). In math and science, researchers and professional developersgenerally value noticing/attention that seeks to interpret rather than just evaluate students’ ideas, and that attendsto details of individual students’ ideas rather than just general abstractions of “what the class wasthinking.” However, the seeds of productive disciplinary thinking that teachers can notice and nurture vary bydiscipline, e.g., productive intuitions about motion and causal reasoning in physical science; precursors to theconcept of “variable;” and generalizing patterns from instances in algebra. Partly for this reason, both researchand professional development focused on teacher noticing has generally been discipline- and even subdiscipline-specific (e.g., Star & Strickland, 2008). By contrast, work focused on teachers’ use of technologyexplores teachers’ general use of technology, not attending to the disciplinary context of its use (Voogt, Fisser,Pareja Roblin, Tondeur & van Braak, 2013).Existing tools that focus on student thinking or on teachers’ tracking of studentprogressA number of tools exist that allow teachers to analyze their students’ performance and reflect on curricular andinstructional interventions (Rich & Hannafin, 2009). Dashboards and ambient displays provide visualizations ofstudent progress on activities (Clarke & Dede, 2009; Phillips & Popovic, 2012), and help teachers determinewhere to direct help (Alavi & Dillenbourg, 2012; Börner, Kalz, & Specht, 2011; Slotta, Tissenbaum, & Lui,2013). Some environments use data mining and analysis to lend insight into student competencies and needs(Gobert, Sao Pedro, Raziuddin, & Baker, 2013), or to guide teachers in assessing student knowledge (mCLASS;Amplify, n.d.). Other technology-mediated tools for classroom use offer supports to guide teachers’ attention tostudent learning (Williams, Linn, Ammon & Gearhart, 2004), and provide data on student performance toinform the adaptation of curriculum (Matuk, Linn, & Eylon, 2015). Though useful for tracking student progresstoward correct understandings, these tools do not focus on highlighting the disciplinary substance of individualstudents’ thinking.Other tools, designed with student users in mind, are intended to amplify reasoning and make thinkingvisible to peers and researchers. Interactive galleries and collaborative tools allow students to share and buildupon one another’s work (Scardamalia & Bereiter, 1994). Interactive mathematics environments and scientificmodeling tools provide students with new representational systems and modes of interaction for expressing andexploring ideas (e.g. SimCalc; Geogebra; Boxer; NetLogo; a long tradition of research has modeled studentreasoning with such tools; Williams, Linn, Ammon, & Gearhart, 2004; diSessa 2001; Papert, 1980; Simpson,Noss & Hoyles, 2005). However, the majority of such work has focused on student knowledge and interactions,rather than on teacher practice.Our interest in technology-mediated teacher noticing contributes to this existing work a complementaryview of what counts as “successful use” of such technologies by teachers. For most teacher-directed tools,success is marked by successful implementation or improved student performance on activities. For studentdirected tools, it is deep engagement with discipline-specific content and practices. What we are interested in isactive teacher engagement, within the context of planned classroom activity, to those disciplinary aspects ofstudent thinking that are amplified and made available for observation through the use of technology-mediatedtools.Theoretical framework and driving questionsWe argue there is untapped opportunity for technology to mediate teacher noticing in the classroom.Technology-mediated tools are increasingly a part of classroom practice, and can make student thinking visibleby “...afford[ing] a view of the meaning-making process… a screen on which learners can express theirthinking... the chance to glimpse the traces of their thought” (Noss & Hoyles, 1996, p. 6). Furthermore, the typesof student thinking expressed in these media often reflect those that are emphasized by current educationalreforms (Table 1) but that teachers often do not elicit and build upon. While technology is not a prerequisite forsupporting these types of reasoning, research has shown that certain tools can foreground, stabilize, andhighlight them.CSCL 2017 Proceedings66© ISLSTable 1: Examples of technology-mediated tools that emphasize disciplinary thinking in mathematics andscience.Aspect ofReasoningExample & Related ResearchToolsConnection to Reform EffortsDynamicityStudents notice invariant relationships in a geometricconstruction and work to describe and explain it.(Jones, 2000; Mor et al., 2006)GeogebraCCSS-M “Look for and makeuse of structure”Use of LinkedRepresentationsStudents coordinate information displayed acrossSimCalc,linked tables, graphs, algebraic expressions, and other MiGenrepresentations to confirm/explore their understandingof a relationship.(Smith, diSessa, Roschelle, 1994; Hegedus & Kaput,2003)NCTM “Select, apply, andtranslate among mathematicalrepresentations to solveproblems”Emphasis onMechanismprovided in Evidence & Analysis section below(Blikstein & Wilensky, 2009; Sherin, 2001; Wilensky& Reisman, 2006)NetLogo,ScratchNGSS “Constructingexplanations”Exploration ofComplex SystemsStudents conduct investigations of varyingsystematicity within simulation environments(Hmelo-Silver, Liu, Gray & Jordan, 2014; Jackson,Stratford, Krajcik & Soloway, 1994; Sao Pedro,Gobert, & Betts, 2014)WISE,PhETNGSS “Planning and CarryingOut Investigations”Attending to technology-mediated forms of teacher noticing yields many questions ripe for exploration.For instance, what are features of technology-mediated tools that draw teachers’ attention to specificdisciplinary aspects of student thinking important for a given domain of study? How can teachers learn to lookfor key student thinking practices, such as those outlined in the CCSS-M or NGSS, through the lens oftechnology-mediated student work? What are mechanisms that can be embedded in technology to allow aspectsof student thinking, that otherwise might be hidden, to rise to the forefront?Evidence and analysisHere we present two vignettes that exemplify productive and unproductive instances of TMTN, to illustrate itsrelevance for research, professional development, and technology design. The first episode comes from a wholegroup discussion in a fifth grade science class in an urban rim public school. The school serves a diversity ofstudents with respect to socioeconomic background, ethnicity, and special education status, and the school’sdemographics were roughly represented in the classroom from which these vignettes come. Theclassroom teacher had attended a teacher certification program that was explicitly focused on noticing andresponding to student thinking. Students had worked in small groups to create animations and simulations ofevaporation. They were now sharing and critiquing their work. In the excerpt below, the classroom teacherencourages students to describe specific computational rules they used in their simulation, and what those rulesrepresent about evaporation as a scientific phenomenon. He connects those rules and interpretations toconversations he observed among student groups earlier during the activity.Teacher What do we think guys? What do we think about this, this simulation, thisrepresentation of it? Sheree?Sheree I think it represents when the sun evaporates the water, um the clouds they start tomake new ones because of the water vapor.EdgarI think it represents because the water droplets are going up, and then the cloudsare getting bigger and bigger because all the water's up, then when it gets full it[gestures down].Teacher Ok, and that's the next step if this simulation were to keep going it would probablyshow that.MilesI think it's just like the water droplets are going up, and then it's just gonna getbigger and bigger and then it's gonna like start getting ready to-CSCL 2017 Proceedings67© ISLSAlanI think they're trying to represent that the water vapor forms new clouds, like moreclouds.Teacher I'm even seeing something, I'm trying to remember if this came up in this class orthe other class, like, when there's evaporation, and it goes into the air, does it formits own new clouds, or does it add on to the clouds that are already here? So itseems, from what we see here it seems to be adding on to clouds that are alreadythere. That idea was kind of floating around in this room too.In this excerpt, available functions within the simulation environment such as changing the size of anobject or cloning an object focused both teachers’ and students’ attention on describing potential mechanismswithin the represented scientific system (clouds “get bigger” when “full” with water, versus water vapor“forming” clouds by “making more”). These functions lent a shared language to the activity, and allowed theteacher to highlight and connect different student ideas about mechanism.Our second episode features a small group of students working with the same teacher and tool, thistime earlier during the unit to build their simulation of evaporation. However, this time the constraints of thetool blunted conversations about mechanism, focusing the teachers’ attention on what was possible to representin the simulation rather than students’ ideas about evaporation.RyanTeacherRyanTeacherRyanTeacherLuisThen when it [water droplet] hits it [cloud], the clouds are gonna like get bigger.Oh wait sorry, say that again Ryan?When it hits is, um, it's gonna get biggerWhen it hits the cloud, the cloud should get bigger?Yea. I don't know if we can do thatYea, that might be, so let's think what's uhNo, like when it gets like when it touches the cloud the water droplets like goaway.Teacher So they should disappear?Luis[Nods]Teacher So what commands, or sorry what rules do we have to give to this water droplet tohave it disappear the way you want it to?In this case, the teacher’s preoccupation with which commands were available to use in the softwareimpeded his noticing and drawing out students’ conceptual ideas (clouds “containing” water and droplets being“absorbed” or going away).We emphasize here that what the teacher is attending to is manifested in the moment and through thetechnological media. In the first case, the media help make evident the persistence and development of studentideas over time. In the second, noticing of student thinking is obstructed, in favor of attention to practicalconstraints within the software. In both cases, the teacher must interpret student thinking as mediated by theavailable tools, and choose what aspects of that thinking to elaborate and act upon.Scholarly significanceThe work started in this paper helps shed light on the ways technologically-mediated tools can foreground orbackground student thinking. Moving forward, we will continue to explore cases that help us understand whatfeatures of these tools help expose student ideas to teachers and help teachers make sense of theseideas. Ultimately this insight will help inform the development of professional development, classroom tools,and research methods that can support teaching practice in technology-rich spaces.ReferencesAlavi, H. S., & Dillenbourg, P. (2012). An ambient awareness tool for supporting supervised collaborativeproblem solving. IEEE Transactions on Learning Technologies, 5(3), 264-274.Ball, D. L., & Cohen, D. K. (1996). Reform by the book: What is- Or might be- the role of curriculum materialsin teacher learning and instructional reform? Educational researcher, 25(9), 6-8.CSCL 2017 Proceedings68© ISLSBlikstein, P., & Wilensky, U. (2009). An atom is known by the company it keeps: A constructionist learningenvironment for materials science using Agent-Based Modeling. International Journal of Computersfor Mathematical Learning, 14, 81-119.Börner, D., Kalz, M., & Specht, M. (2011). Thinking outside the box–a vision of ambient learning displays.International Journal of Technology Enhanced Learning, 3(6), 627-642.Carpenter, T.P., Fennema, E., Peterson, P.L., Chiang, C. & Loef, M. (1989). Using children’s mathematicsthinking in classroom teaching: An experimental study. American Educational Research Journal, 26,499-531.Clarke, J., & Dede, C. (2009). Design for scalability: A case study of the River City curriculum. Journal ofScience Education and Technology, 18(4), 353-365.diSessa, A. (2000). Changing minds: Computers, learning, and literacy. Cambridge, MA: MIT Press.Franke, M.L., Carpenter, T.P., Levi, L., Fennema, E. (2001). Capturing teachers’ generative change: A followup study of professional development in mathematics. American Educational Research Journal,38(3), 653- 689.Gobert, J. D., Sao Pedro, M., Raziuddin, J., & Baker, R. S. (2013). From log files to assessment metrics:Measuring students' science inquiry skills using educational data mining. Journal of the LearningSciences, 22(4), 521-563.Hegedus, S., & Kaput, J. (2003). The effect of a SimCalc connected classroom on students’ algebraic thinking.Paper presented at the Psychology in Mathematics Education conference, Honolulu, HI.Hmelo‐Silver, C. E., Liu, L., Gray, S., & Jordan, R. (2015). Using representational tools to learn about complexsystems: A tale of two classrooms. Journal of Research in Science Teaching, 52(1), 6-35.Jackson, S.L., Stratford, S.J., Krajcik, J., & Soloway, E. (1996). Making dynamic modeling accessible to precollege science students. Interactive Learning Environments, 4, 233-257.Jones, K. (2000). Providing a foundation for deductive reasoning: Students' interpretations when using dynamicgeometry software and their evolving mathematical explanations. Educational Studies in Mathematics,44(1), 55-85.Kali, Y., McKenney, S., & Sagy, O. (Ed.). (2015). Teachers as designers of technology enhanced learning.Instructional Science, 43(2), 173-179.Matuk, C. F., Linn, M. C., & Eylon, B. S. (2015). Technology to support teachers using evidence from studentwork to customize technology-enhanced inquiry units. Instructional Science, 43(2), 229-257.Mishra, P., & Koehler, M. (2006). Technological pedagogical content knowledge: A framework for teacherknowledge. The Teachers College Record,108(6), 1017-1054.Mor, Y., Noss, R., Hoyles, C., Kahn, K., & Simpson, G. (2006). Designing to see and share structure in numbersequences. the International Journal for Technology in Mathematics Education, 13(2), 65-78.National Governors Association Center for Best Practices & Council of Chief State School Officers. (2010).Common Core State Standards for Mathematics. Washington, D.C: Authors.National Research Council (NRC), (2013), The next generation science standards, Washington, D.C.: TheNational Academies Press.[NGSS] Lead States. (2013). Next Generation Science Standards: For States, By States. Achieve, Inc.Noss, R., & Hoyles, C. (1996). Windows on mathematical meanings: Learning cultures and computers (Vol.17). Springer Science & Business Media.Papert, S. (1980). Mindstorms: Children, computers, and powerful ideas. New York: Basic Books.Phillips, V., & Popović, Z. (2012). More than child's play: Games have potential learning and assessment tools.Phi Delta Kappan, 94(2), 26-30.Rich,P., & Hannafin, M.J. (2009). Video annotation tools: Technologies to scaffold, structure, and transformteacher reflection. Journal of Teacher Education, 60(1), 52-67. Doi:10.1177/002248710832848.Roschelle, J., Kaput, J., & Stroup, W. (2000). SimCalc: Accelerating students’ engagement with themathematics of change. Innovations in science and mathematics education: Advanced designs fortechnologies of learning, 47-75.Sao Pedro, M.A., Gobert, J.D., & Betts, C.G. (2014). Towards scalable assessment of performance-based skills:Generalizing a detector of systematic science inquiry into a simulation with a complex structure. In theProceedings of the 12th International Conference on Intelligent Tutoring Systems. Honolulu, Hi. (pp.591-600).Scardamalia, M., & Bereiter, C. (1994). Computer support for knowledge-building communities. Journal of theLearning Sciences, 3(3), 265-283.Schifter, D. (1998). Learning mathematics for teaching: From a teachers’ seminar to the classroom. Journal ofMathematics Teacher Education, 1(1), 55-87.CSCL 2017 Proceedings69© ISLSSherin, M., Jacobs, V., & Phillip, R. (2011). Mathematics Teacher Noticing: Seeing Through Teachers’ Eyes.New York, NY: Routledge.Sherin, M. G., & van Es, E. A. (2009). Effects of video club participation on teachers' professional vision.Journal of Teacher Education, 60, 20–37.Simpson, G., Hoyles, C., & Noss, R. (2005). Designing a programming‐based approach for modelling scientificphenomena. Journal of Computer Assisted Learning, 21(2), 143-158.Slotta, J. D., Tissenbaum, M., & Lui, M. (2013, April). Orchestrating of complex inquiry: three roles forlearning analytics in a smart classroom infrastructure. In Proceedings of the Third InternationalConference on Learning Analytics and Knowledge (pp. 270-274). ACM.Smith, J.P., III, diSessa, A.A., & Roschelle, J. (1993/1994). Misconceptions reconceived: A constructivistanalysis of knowledge in transition. Journal of the Learning Sciences, 3, 115-164.Star, J. R., & Strickland, S. K. (2008). Learning to observe: Using video to improve preservice mathematicsteachers' ability to notice. Journal of Mathematics Teacher Education, 11(2), 107–125.Voogt, J., Fisser, P., Pareja Roblin, N., Tondeur, J., & van Braak, J. (2013). Technological pedagogical contentknowledge–a review of the literature.Journal of Computer Assisted Learning, 29(2), 109-121.Wilensky, U., & Reisman, K. (2006). Thinking like a wolf, a sheep, or a firefly: Learning biology throughconstructing and testing computational theories—an embodied modeling approach. Cognition andInstruction, 24(2), 171-209.Williams, M., Linn, M. C., Ammon, P., & Gearhart, M. (2004). Learning to teach inquiry science in atechnology-based environment: A case study. Journal of Science Education and Technology, 13(2),189-206.CSCL 2017 Proceedings70© ISLS