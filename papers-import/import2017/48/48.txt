Individual Versus Shared Design Goals in a Graph ConstructionActivityJonathan Vitale, Lauren Applebaum, and Marcia Linnjonvitale@berkeley.edu, lauren.applebaum@berkeley.edu, mclinn@berkeley.eduUniversity of California, BerkeleyAbstract: Technologies can help foster diverse ideas in collaborative learning activities bytaking advantage of group members’ unique ideas and perspectives. Assigning individualgroup members to specific tasks may promote this diversity. In this paper, we introduce agraphing challenge, in which student pairs construct graphs to represent the motion of anamusement park ride. We assigned pairs to experimental conditions with either individualdesign goals or shared design goals. Analysis revealed that students with individual designgoals demonstrated deeper engagement with one of the design tasks (i.e., to create a “safe”ride), while this goal was relatively neglected when goals were shared. No impact ofcondition was found on posttest learning; however, students demonstrated overall gains.IntroductionIn collaborative learning groups, technologies can elicit a diverse range of ideas by facilitating expression ofindividuals’ unique perspectives. Supporting individual voices within groups enables equity, particularly forstudents from non-dominant cultural backgrounds who may otherwise be reluctant to engage (Rosebery,Ogonowski, Dischino, & Warren, 2010). Moreover, the expression of diverse ideas provides an opportunity forlearning when students reconcile conflicting perspectives (Gijlers & de Jong, 2009). In complex, inquiry-basedlearning activities the process of distinguishing and reconciling conflicting ideas promotes coherentunderstanding (Linn & Eylon, 2011). Therefore, collaborative learning activities can take advantage ofcollaboration by eliciting conflicting beliefs, and then managing their resolution. Yet, if group members beginan activity with similar ideas or if a single member adopts a dominant role, these opportunities are limited. Forexample, Clark, D’Angelo, and Menekse (2009) found that groups manufactured to ensure conflicting ideasbetween students demonstrated greater learning than groups constructed at random. Alternatively, in cases ofintact groups, technology can support more dynamic collaboration by assigning (personalizing) responsibilitiesfor specific students (Kollar, Fischer, Hesse, & Media, 2006). By supporting unique engagement patterns foreach group member, these activities provide opportunities for productive discussion of conflicting ideas. In thispaper, we present a comparison between individualized and shared goals in a collaborative design activity inwhich students construct graphs to represent the motion of an amusement park ride.Goals in design activitiesAccording to the knowledge integration framework (Linn & Eylon, 2011), activities support learning by guidingstudents to elicit ideas, discover new ideas, distinguish between these ideas, and reflect on these ideas todevelop a coherent understanding. Collaborative activities fit well within this framework because they are ableto expose a broad range of student ideas and provide opportunities for distinguishing between potentialconflicts. For this reason, curricula developed within the knowledge integration framework are typicallyintended for small groups of students (Linn & Eylon, 2011). Because learning environments such as the Webbased Inquiry Science Environment (WISE) can assign diverse roles, by name, during knowledge integrationactivities, they represent an opportunity to investigate how collaborative patterns impact learning.In particular, in design projects, where students are expected to generate artifacts creatively, patterns ofcollaboration are likely to have a substantial impact on how artifacts are generated. When materials are limited(e.g., a single computer keyboard), tasks must inevitably be divided among group members. Without externalstructuring, group members negotiate duties according to personal (i.e., “internal”) collaboration scripts abouthow tasks should be divided (Kollar, Fischer, & Slotta, 2007). In some cases, this leads to equitableparticipation, but in other cases participation may be unbalanced. To promote equitable engagement the teacheror software may assign specific responsibilities to each group member (Kollar et al., 2006). A commonapproach is to assign roles, which divide the overall activity into distinct tasks. For example, in an onlinediscussion activity (Cesareni, Cacciamani, & Fujita, 2016) assigned students to roles of “social tutor”,“synthesizer”, “concept mapper” and “skeptic”. While this approach may ensure accountability for each of thegroup members, it may not take advantage of students’ diverse ideas about shared content.CSCL 2017 Proceedings351© ISLSAlternatively, assigning unique priorities or goals within shared tasks is a common practice in businessand engineering design activities to encourage diverse perspectives (Détienne, 2006). In cases where inherenttradeoffs exist in the design, assigning individuals to focus on alternative features may make these tradeoffsmore salient. For example, in this study we assign group members to focus on conflicting “safety” and “thrill”concerns for an amusement park ride that they are designing. By helping students evaluate and resolve conflictscentering around important structural features of their design, we can direct attention to central issues. Incontrast, students may pay attention to superficial characteristics in unguided projects (Hmelo-Silver, Duncan,& Chinn, 2007).Yet, there is risk in “over-scripting” collaboration (Dillenbourg, 2002). If expectations for a task areprescribed in a step-by-step manner, students may miss the opportunity to recognize and evaluate competingideas. Furthermore, if assigned responsibilities are not aligned to students’ preferences or internal collaborationscripts, they may resist external scaffolds (Kollar et al., 2007). As a result, creating productive roles for groupmembers requires attention to students’ actual processes when given specific assignments.Study goals and significanceWe investigate the personalization of design goals within an online inquiry unit conducted in a classroomsetting. The online environment provides us with the opportunity to directly present a design goal to anindividual student, by name. We compare groups who are randomly assigned to either individual or shareddesign goals. Our aim is to investigate whether assignment alters the artifacts that students build and theconcepts they learn. In particular, we study the following two research questions:1. How do individual and shared design goals impact the artifacts of design?2. How do individual and shared design goals impact learning of underlying concepts?By addressing these questions we seek to contribute a new approach to the collaboration scripts literature(Dillenbourg, 2002) in the context of student design projects.MethodsParticipants and proceduresWe performed this study with five participating teachers from two schools. All but one of these teachers hadprior experience running similar online inquiry projects as part of a research study. In spite of their similar priorexperience with collaborative inquiry projects, the teachers differed substantially (by school) on their approachto and acceptance of collaborative activities.In school A (38% White, 31% Asian, 17% Hispanic, 4% Black, 22% Reduced-price lunch, 12% ELL),three teachers participated in this study: A1 (male, 10+ years of experience, 103 students), A2 (female, 2nd year,125 students), and A3 (female, 1st year, 26 students). In each of these teachers’ classrooms, students sat at fourperson lab tables and were expected to engage in collaborative inquiry projects throughout the school year.Students in these classrooms performed all learning activities in dyads.In school B (51% White, 9% Asian, 28% Hispanic, 3% Black, 32% Reduced-price lunch, 7% ELL),two teachers participated in this study: B1 (female, 10+ years of experience, 126 students), and B2 (male, 10+years of experience, 103 students). In both of these teachers’ classrooms students sat in rows of desks facing thefront of the classroom. These teachers both expressed skepticism about collaborative activities (e.g., assumingthey promote off-task activity) and preferred to assign tasks individually. At the teachers’ request, students inthese classrooms performed the first part of the learning activity (“Graphing Stories”) individually, and thenwere grouped in dyads to perform the collaborative challenge activity.In all classes students completed a pretest and posttest individually.MaterialsAll materials were presented in the Web-based Inquiry Science Environment (WISE).Graphing storiesIn this set of activities students construct position vs. time graphs to correspond to simple stories of motion (e.g.,a hike in the woods). See previous work for more details (Vitale, Lai, & Linn, 2015).Amusement park challengeCSCL 2017 Proceedings352© ISLSIn this challenge activity dyads of students are randomly assigned to either shared or individual conditions tocomplete the following (http://wise.berkeley.edu/previewproject.html?projectId=18233):1. Join the team. In this challenge students design an amusement park ride by constructing graphs of position vs.time. In the individual condition, students are uniquely assigned to a single goal, embodied by either the safetyor thrill team (Figure 1). In the shared condition, students read instruction that they will be working together forboth teams. Following this introduction, students are asked either individually or as a group to describe how athrilling and a safe ride would differ from each other.Figure 1. Introduction to design goals in Amusement Park Challenge. In individual condition, each student inthe workgroup pair is assigned to either the “thrill team” or the “safety team” by name. In the shared condition,both students are referred to, by name, next to each of the teams.2. Graphing curves. Like the Graphing Stories curriculum, the primary activity in the Challenge is to constructa graph and observe the corresponding motion on a linked simulation. However, building on Graphing Stories,students are afforded the additional ability to modify the curvature of segments, thereby impacting acceleration.To introduce this new feature, students are asked to construct a single line segment, modify the curvature inboth directions, and observe the impact on the animated ride. Additionally, to emphasize the significance ofacceleration, movement of the head of the rider is accentuated forwards or backwards, based upon theacceleration. For example, in Figure 2, the rider is experiencing negative acceleration (slowing down), and istherefore learning forwards. Individualized roles are not utilized for this step.3. Design each ride. In this step groups design two rides: one that is “thrilling” and one that is “safe”. Thestudents are not given precise criteria, but are expected to follow their own definition of each. Prior toconstructing a graph, students are prompted with a question, “What are you trying to design?”, to which theycould respond by selecting either “a thrill ride” or “a safe ride”. Following selection, students construct a graphwith up to five segments, and then observe the corresponding ride (Figure 2). Following completion of a ride(once the animation was observed), students can press the “New” button to clear the graph. They would againbe prompted to indicate the type of ride. In the personalized condition students are asked to construct each ofthese ride designs individually, although the partner was still available for assistance. In the shared conditionstudents are expected to work on all tasks together.The separate “thrill” and “safe” ride designs are intended to highlight critical relationships in thegraphs, including the link between speed and slope, acceleration and curvature. By manipulating graphs for eachof these design goals students produce contrasting cases, which illustrate these relationships (Schwartz, Chase,Oppezzo, & Chin, 2011).When students feel satisfied with each design they are instructed how to download an image of thecorresponding graphs. On two later pages, one for each design, they upload these graphs for public displayCSCL 2017 Proceedings353© ISLSwithin a chat forum. Students are prompted to describe uploaded images (and their corresponding rides), andthen comment on another groups’ ride.Figure 2. Amusement park challenge. Students plot points and adjust sliders to modify curvature. Upon pressing“Run” a simulation of the ride begins. A corresponding red vertical line displays the current time on the graph.4. Design your best ride. Following their experience exploring designs for “safe” and “thrilling” rides,workgroups are prompted to construct a “best” ride that is both fun and safe. In this case, students couldconstruct up to 10 segments. Students are, once again, prompted to save their favorite ride and upload it on adiscussion board. There is no reference to individual design goals.5. Make a final report. After completing all graphing steps students are prompted to make a recommendationabout how to design rides, with graphs, that are both fun and safe.Pretest-posttest graphing item: “Playing Pool”Although the pretest and posttest consisted of multiple items, we focus on a single item, playing pool (Figure 3),which best aligns with conceptual themes of the Challenge. In this item (Figure 3), students are asked to selectthe graph that best represents a simple story about a pool (billiards) shot. Multiple choice items distinguishstudents’ understanding of the relationship between slope of segments and speed, and between curvature andacceleration. Distractor items featuring “graph-as-picture” representations are also included.Posttest collaboration surveyTo assess students’ understanding of their collaborative strategies we prompted students with the followingopen ended questions at the end of the posttest:1. Describe how you and your partner worked together on the Amusement Park Challenge. Did you eachtake on different roles and responsibilities? If so, describe your role in the group.2. Describe one example of a time during the Amusement Park Challenge where you and your partner hadto make a decision, but each of you had different ideas. How did you make this decision?3. Describe one example of something you would have done differently during the Amusement ParkChallenge if you had been working on your own.CSCL 2017 Proceedings354© ISLSMel placed a ball about one and a halffeet from the edge and hit the ball acrossthe table. The ball went all the way to theend, bounced all the way back, and fellinto the hole in the corner pocket. Theshot took about 3 seconds.Which of the following Position vs. Timegraphs best represents Mel's shot?Graph AGraph BGraph CGraph DGraph EGraph FFigure 3. “Playing Pool” pretest and posttest item. The correct response (Graph D) illustrates a faster speed(steeper slope) on the path to the wall than back to the hole and negative acceleration (decreasing speed).Analysis methodThe pretest-posttest item was scored according to a knowledge integration rubric (scores 1 – 6). This approachhas been used in previous graphing applications (Vitale et al., 2015) to emphasize links between narrativeelements of the item (e.g., the “speed”) and spatial elements (i.e., the slope).Graph artifacts were stored digitally by tracking the position of each vertex and the curvature of thesegment, as given by the value of the corresponding slider. A graph was marked as complete if students ran thecorresponding animation. Using this information, we analyze several features of each graph, including theaverage angle of segments and the number of segments. Additionally, for design each ride data logs indicatewhether a graph was intended to be a “thrill” or “safe” ride (i.e., “type”). We analyze the impact of ride type andcondition on graph features (e.g., average segment angle). To reflect likely covariation of features for “thrill”and “safe” rides made by a single workgroup we use linear mixed effects models with a random intercept forworkgroup, for both continuous and ordinal outcomes. We report on both the statistical significance ofpredictors as well as the standardized regression coefficients or odds-ratio (for ordinal variables).Findings and analysisArtifact designTo get an initial sense of how students perceived the difference between “safe” and “thrill” rides we analyzedstudent descriptions of each type of ride in Join the Team. After processing the 275 responses to removecommon words, we found that for “thrill” rides meaningful, frequent terms included, “fast” (185), “drop(s)”(136), “loop(s)” (124), “upside” (52), “turn(s)” (63), “speed(s)” (64), and “steep” (28). In this case students wereoften considering features of roller coasters that were not relevant to the ride they were designing (e.g. loops);however, words such as “fast” and “speed” were relevant. Very few terms that clearly relate to accelerationemerged, but perhaps include “sharp” (14) and “sudden” (11). Likewise, for safe rides, frequent terms included,“(seat)belt(s)” (151), “bar(s)” (63), “harness(es)” (24), “speed” (15), and “slow” (13). Clearly, studentsinterpreted “safety” in terms of protecting riders from impact, although some did make reference to speed.To compare emphasis on each design goal, we computed a count of the number of complete graphsmade for each type, for each workgroup, and compared these by condition. In the individual condition groupCSCL 2017 Proceedings355© ISLSmembers averaged 3.1 (SD = 2.9) “thrill” graphs and 2.5 (SD = 2.2) “safe” graphs. In the shared conditiongroup members averaged 3.6 (SD = 2.8) “thrill” graphs and 1.9 (SD = 2.0) “safe” graphs. A mixed effectsmodel of graph count, using 222 workgroups, reveals a significant effect of graph type (is safe) [β = -0.31, t = 5.9, p < .001), no main effect of condition (is individual) [β = -0.08, t = -1.2, p = .2], and a significantinteraction of condition and graph type (is safe and individual) [β = 0.16, t = 2.4, p = .02]. The interactionindicates that the proportion of safe rides was higher (but still less than ½ of all ride designs) when design goalswere individual than when they were shared.A higher proportion of safe rides in the individual condition suggests more engagement with the safetask. Another proxy measure of engagement is the complexity of the graphs. To analyze this, we restrictedanalysis to final graphs and categorized complexity by number of segments (0: none, 1: small, 2+: large). Anordinal mixed effects model of complexity, using 209 workgroups with completed graphs, reveals a main effectof graph type (is safe) [odds-ratio = 0.38, z = -2.6. p = .009), a trend towards a main effect of condition (isindividual) [odds-ratio = 0.51, z = -1.7, p = .09], and a significant interaction of condition and graph type [β =3.5, z = 2.3, p = .02]. This indicates while safe rides were likely to be less complex than thrill rides overall, theodds of a more complex safe ride were higher in the individual condition than the shared condition.Figure 4. Examples of final thrill (a) and safe rides (b, c, d), with descriptions. Rides a, b, and c were designedby students in the individual condition, while ride d was designed by a group in the shared condition.Considering students’ expressed emphasis on speed as a distinguishing feature of thrill and safe rides,we evaluated the mean (absolute) angle of segments in students’ final graphs. A mixed effects model of meanangle, using 209 workgroups with completed graphs, reveals a significant effect of graph type (is safe) [β = 0.55, t = -9.2, p < .001), no main effect of condition (is individual) [β = -0.01, t = -0.1, p > .2], and a significantinteraction of condition and graph type (is safe and individual) [β = 0.14, t = 2.0, p = .05]. This indicates thatthat while, overall, “safe” rides had less steep slopes, those in the individual condition made steeper segmentsfor the thrill ride than those in the shared condition.To make sense of these finding we selected examples of final designs from students taught by a singleteacher. We chose teacher A2 because her students demonstrated a high level of enthusiasm (they frequentlyencouraged other students, outside their group, to view their designs), and her large number of students (125)CSCL 2017 Proceedings356© ISLSallowed us to explore a diverse range of artifacts. From these students, we chose four representative examples.The distinguishing features of thrill and safe rides in Figure 4 (a) and (b) are the slope and curvature ofsegments, not the number of segments. Students who produced these graphs were clearly engaged with the task.Figure 4 (c) also demonstrates a valid safe ride, although this workgroup did not take advantage of curvature.We do not know if it reflected less engagement than Figure 4 (b); however, the student authors note that the rideis “really steady”, perhaps referring to the lack of acceleration during most of the ride. On the other hand, Figure4 (d) displays a graph that likely indicates superficial engagement with the task. In contrast to instructions, theride did not progress back and forth at least once. Moreover, the author states that the ride “steadily sped up”,although the actual ride would move at a very slow, constant speed.It may be the case that students in the individual condition produced fewer superficial designs becausethey took more personal ownership of the task, whereas those in the shared condition were more likely to spendtheir combined efforts on the more appealing task of designing a thrilling ride. Another possibility is thatstudents who were assigned to design the safe ride abandoned their role and produced thrilling rides instead.Posttest performanceOverall students’ scores on playing pool rose from pretest (M = 2.7, SD = 1.0) to posttest (M = 3.3, SD = 1.2),significantly [t(431) = 11.0, p < .001]. To investigate the impact of condition on learning, we performed anANCOVA on playing pool posttest scores, with Condition as an independent variable and pretest score as acovariate. This analysis shows a significant impact of pretest score [F(1, 429] = 167.5, p < .001], but no effect ofcondition [F(1, 429] = 0.1, p > .2], indicating that both collaborative conditions were equally effective.To explore whether engagement in the challenge was related to learning we performed an ANCOVAon playing pool posttest scores with number of “safe” graphs produced by the students’ workgroup, controllingfor pretest score. This analysis shows a significant effect of number of safe graphs [F(1, 429) = 26, p < .001].This suggests that students who learned more were more likely to engage in the designing activity. Conversely,since the challenge activity is the only exploration of graph curvature in the instruction, it may be that deeperinvolvement in the design activity promoted better understanding of non-linear graphs. For example, thisstudent illustrates how her experience during instruction informed her response to the playing pool posttest item:I chose d because when we were doing the amusement park ride problem, the graphslooked the same… The only difference between the two [b and d] was the placement oftheir curves, which brought me back to the amusement park ride. I recalled that the cartwent the fastest at the most inverted part of the curves, or the opposite, depending onwhether they curved in or out. I assumed that the two fastest points should be when theball is originally hit, and when it bounces off the wall. Graph d showed that the ball wouldstart off, and slow down as it reached the top, from there, it would bounce off the wall andspeed up for a bit, before slowing down again as it reached 0,0.A lack of difference between conditions may be due to a number of factors. First, although individual goalsproduced a better balance of thrill and safe rides, it may be that designing either type of ride supported learning.In the case where students designing safe rides chose not to manipulate curvature (like Figure 4, c and d) thenlearning was more likely for thrilling rides so an imbalance in trials could result in more experience withcurvature. Furthermore, while individual goals helped to structure collaboration, in many of the groups,collaborative roles emerged spontaneously. In the shared condition 19% of groups indicated that they dividedup “safe” and “thrill” responsibilities. Additionally, 35% of participants indicated that they alternated turns orconstructed alternative roles (e.g. “typer”, “grapher”). Only 6% of students indicated that one group member(themselves or partner), took a dominant role. Thus, spontaneous collaborative strategies may have mimickedthe advantages of the collaborative strategies implemented in the treatment.ImplicationsThis investigation suggests that personalized design goals can help direct engagement to specific instructionalactivities – including those that may be valuable, but less appealing to students. Directing students in theindividual condition to focus on separate goals increased attention to building safe rides. Although students inthe individual condition were more likely to engage in building safe rides, we did not find that additional focuson this task improved performance on the outcome measure. Future work is needed to determine whetherpersonalizing priorities can foster learning by boosting engagement with tasks that are clearly aligned withlearning goals. Future work can also investigate whether an even distribution of task attention could help bothpartners learn or whether gains are more likely for the assigned student.CSCL 2017 Proceedings357© ISLSMore generally, the individualized design goals approach represents a tool by which teachers anddesigners can establish equitable student partnerships during collaborative activities. This stands in contrast to adivision-of-labor strategy in which one student may select a less demanding or gender-stereotyped role. Forexample, in some studies boys take the role of primary computer user, particularly in game-like settings, to thedisadvantage of others (Volman & van Eck, 2001). Rather, by personalizing goals, students are expected toperform tasks that engage in similar conceptual processes. By prompting them to then coordinate between twosets of goals, the students are required to take each other’s contributions seriously. As complex projects becomemore integral in STEM classrooms (NGSS Lead States, 2013), helping students develop both individualresponsibility for a project and sensitivity to their partners’ ideas is essential to ensuring successful experiences.ReferencesCesareni, D., Cacciamani, S., & Fujita, N. (2016). Role taking and knowledge building in a blended universitycourse. International Journal of Computer-Supported Collaborative Learning, 11(1), 9–39.Clark, D., D’Angelo, C., & Menekse, M. (2009). Initial structuring of online discussions to improve learningand argumentation: Incorporating students’ own explanations as seed comments versus an augmentedpreset approach to seeding discussions. Journal of Science Education and Technology, 18(4), 321–333.Détienne, F. (2006). Collaborative design: managing task interdependencies and multiple perspectives.Interacting with Computers, 18(1), 1–20.Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructionaldesign. In P. A. Kirschner (Ed.), Three worlds of CSCL: Can we support CSCL? (pp. 61–91). Heerlen:Open University of the Netherlands.Gijlers, H., & de Jong, T. (2009). Sharing and confronting propositions in collaborative inquiry learning.Cognition and Instruction (Vol. 27).Hmelo-Silver, C. E., Duncan, R. G., & Chinn, C. A. (2007). Scaffolding and achievement in problem-based andinquiry learning: A Response to Kirschner, Sweller, and Clark (2006). Educational Psychologist.Kollar, I., Fischer, F., Hesse, F. W., & Media, K. (2006). Collaboration scripts — a conceptual analysis.Educational Psychology Review, 18(2), 159–185.Kollar, I., Fischer, F., & Slotta, J. D. (2007). Internal and external scripts in computer-supported collaborativeinquiry learning. Learning and Instruction, 17(6), 708–721.Linn, M. C., & Eylon, B.-S. (2011). Science learning and instruction: Taking advantage of technology topromote knowledge integration. New York: Routledge.NGSS Lead States (2013). Next generation science standards: For states, by states. Washington, DC: NationalAcademy Press.Rosebery, A. S., Ogonowski, M., Dischino, M., & Warren, B. (2010). “The coat traps all your body heat”:Heterogeneity as fundamental to learning. Journal of the Learning Sciences, 19(3), 322–357.Schwartz, D. L., Chase, C. C., Oppezzo, M. a., & Chin, D. B. (2011). Practicing versus inventing withcontrasting cases: The effects of telling first on learning and transfer. Journal of Educational Psychology,103(4), 759–775.Vitale, J. M., Lai, K., & Linn, M. C. (2015). Taking advantage of automated assessment of student-constructedgraphs in science. Journal of Research in Science Teaching, 52(10), 1426–1450.Volman, M., & van Eck, E. (2001). Gender equity and information technology in education: The second decade.Review of Educational Research, 71(4), 613–634.CSCL 2017 Proceedings358© ISLS