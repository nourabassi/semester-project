Design Collaborative Formative Assessment for SustainedKnowledge Building Using Idea Thread MapperJingping Chen, University at Albany and University of Electronic Science and Technology of China,chgping@gmail.comJianwei Zhang, University at Albany, jzhang1@albany.eduAbstract: This design-based study investigated collaborative formative assessment forknowledge building in two comparable Grade 6 science classrooms. Students assessed theircollective knowledge progress using the Idea Thread Mapper (ITM)—a timeline-basedcollective discourse mapping tool—and planned for further efforts to address deeper issues.Analysis of students’ online discourse and individual portfolio notes suggests the positiveimpact of the assessment on the community’s knowledge building discourse as reflected instudents’ idea-deepening and idea-elaborating questions, refined explanations, and build-onconnections; and on student scientific understandings as documented in their individualportfolio notes.IntroductionDesigning new assessments in line with evolving conceptions of how people learn is a central challenge in thelearning sciences (Pellegrino, 2014). Research on collaborative learning and knowledge building hasdemonstrated new learning designs and classroom practices to develop deep knowledge and high-ordercompetencies, including knowledge-creating capabilities (Scardamalia & Bereiter, 2006; Stahl, 2006). Thepedagogy of collaborative knowledge building requires new learning assessments to measure both individual andcollective knowledge advances and feedback on students’ inquiry and collaboration as the process unfolds. Thepurpose of this study is to design and examine formative, collaborative assessment in the context of knowledgebuilding communities. In a knowledge building community, members continually advance the state-of-the-artunderstanding of core issues in a focal area(s) through interactive idea input. They build collective knowledge asa social product of their community beyond individual notions and concepts (Scardamalia & Bereiter, 2006). Thecommunity’s collective knowledge is represented through the conceptual artifacts developed and shared by thecommunity members as they engage in idea-transforming discourse. Using collaborative online platforms such asKnowledge Forum, students contribute and build on one another’s ideas over time to address deepening issuesand develop increasingly sophisticated understandings. Deeper challenges are identified as progress is made,leading to sustained cycles of inquiry and progressive discourse (Hakkarainen, 2003; Zhang et al., 2007). Existingassessments primarily focus on individual learning processes and outcomes, and capture very little of thesustained, collaborative knowledge building processes that continually deepen and evolve. Therefore, designingnew assessment for sustained, collaborative knowledge building becomes a critical challenge (Scardamalia et al,2010; van Aalst & Chan, 2007).The current study explores the design of assessment for sustained knowledge building in light of a set ofkey principles deprived from the literature. These include:(a) Student-directed assessment with high-level collective responsibility: Sustained knowledge buildingrequires students to take on collective responsibility for high-level decisions, including setting goals, long rangeplanning, and progress tracking (Scardamalia, 2002). Assessment for knowledge building hence needs to bestudent-directed (van Aalst & Chan, 2007). Student make collective decisions about what should be investigatedand assessed, based on what evidence, and what further actions should be carried out based on the results of theassessment. They are active agents for the internal assessments of their own work instead of passive test-takers inthe external assessments (Scardamalia & Bereiter, 2006).(b) Collaborative assessment of collective knowledge in relation to individual learning: Assessment forknowledge building needs to capture both collective and personal knowledge advancement (Scardamalia et al,2010; van Aalst & Chan, 2007). A community’s progress and practices in collective knowledge advancementsare evident through its trajectories and patterns of knowledge building discourse (e.g. deepening ideas andquestions) and knowledge artifacts generated. Students’ individual knowledge advancements are reflected in theircontributions to the community’s discourse as well as their personal artifacts generated to support their ownlearning and reflection.(c) Formative and transformative assessment to inform sustained idea improvement: Beyond existingassessments that characterize student’ performance and progress in past learning (Mislevy & Haertel, 2006),assessment for knowledge building needs to provide ongoing feedback to support sustained idea improvementICLS 2016 Proceedings647© ISLSand collective engagement (Scardamalia & Bereiter, 2006) and scaffold future learning and inquiry (Schwartz &Arena, 2013; Shepard, 2000). The collection and use of assessment information becomes an integral part of theongoing learning process (Pellegrino, 2014).(d) Technology-supported assessment using analytic tools: Assessment for knowledge building based onongoing discourse and student artifacts requires technology support to analyze rich data and provide easilyinterpretable results and visualizations. Various analytic tools have been developed to capture cognitive and socialdynamics of collaborative learning and knowledge building using sematic, lexical, and social network analysis(Scardamalia et al., 2010; Zhang et al., 2009). However, these new assessment and analysis tools mostly remainas research tools; they are often too complicated for students to use and interpret (Zhang & Chen, 2012).Research by van Aalst, Chan and colleagues (Lee, Chan, & van Aalst, 2006; van Aalst & Chan, 2007)showed the positive impact of student-directed, formative assessment on collaborative knowledge building. Intheir research students created e-portfolios to identify productive examples of knowledge building contributionsand discourse episodes. However, with the lack of effective means to making collective knowledge progressvisible in current online discourse environments (Zhang, 2009), it is cognitively challenging for students tomonitor and assess collective knowledge progress based on distributed discourse in long-term inquiry. Guidedby the above-mentioned principles, this research tests a design of collaborative formative assessment forknowledge building supported by a timeline-based collective discourse mapping tool: the Idea Thread Mapper(ITM) (Chen, Zhang, & Lee, 2013). ITM interoperates with Knowledge Forum (Scardamalia & Bereiter, 2006)and potentially other collaborative learning platforms. In these online environments, student ideas are presentedin distributed postings (e.g. notes) and responses (build-ons) in extended online discourse. To help studentsmonitor what is going on in the discourse and interpret the collective focuses and progress, ITM incorporatesconceptual threads of inquiry--“idea threads” (Zhang et al., 2007)--as a larger, emergent unit of ideas in onlinediscourse. ITM allows students to create idea threads through selecting certain discourse contributions (notes) forvarious focal objects of inquiry. Each idea thread is composed of a sequence of discourse entries (possibly severalbuild-on trees) contributed by a subset of the members of a community to address a shared problem or conceptualtopic. The collective knowledge of the community in a whole inquiry-based initiative is further represented asclusters of idea threads that address interrelated problems. With the authors and build-on connections identified,the idea threads are displayed on a timeline as an “idea thread map” (left side of Figure 1). The progress in eachidea thread is further made transparent by students through co-authoring a “Journey of Thinking” synthesis thatincludes three sections: We want to understand, We used to think…and we now understand…, We need to do more(right side of Figure 1). Idea threads and thread-based syntheses are co-editable by members of the community,with each version recorded for later review. New analytics tools in ITM support auto-clustering of notes based onthread topics and analysis of discourse contribution types (e.g. questioning, explaining) in each idea thread tosupport student reflection.Figure 1. A map of idea threads (left) and a “Journey of Thinking” synthesis (right) created by one ofthe Grade 6 classrooms in this research studying biodiversity. Each colored stripe represents an idea threadextending from the first till the last note contributed addressing a shared focal problem. Each square represents anote. A dotted vertical line shows notes shared between different threads discussing interrelated issues. The“Journey of Thinking” page (right) shows students’ co-authored reflection on what we need to understand, “bigideas” learned, and what we need to do in the next step.ICLS 2016 Proceedings648© ISLSExisting research suggests that ITM can support collective meta-discourse and reflection among students:to review ongoing discourse contributions to formulate shared focuses and goals of inquiry, monitor how ideashave been advanced in unfolding lines of inquiry, synthesize insights, idea connections and deeper actions to betaken by community members (Zhang et al., 2015). The current research further extends the ITM-aided discoursereview into a systematic design of collaborative assessment to leverage sustained knowledge building. In light ofthe related literature (Scardamalia et al., 2010; van Aalst & Chan, 2007; Zhang et al., 2009), the collaborativeassessment design focuses on three essential aspects of knowledge building: collective knowledge, evidencedthrough sustained and progressive discourse contributions to advancing various lines of work in the community;social dynamics of collaboration, evidenced through the active participation, idea connection, and distributedengagement of the members; and student individual understanding, revealed through their personal reflection onwhat they have learned. Students reflectively assess each aspect of knowledge building focusing on threequestions underpinning formative assessment (Pellegrino, 2014; William & Thompson, 2007): (a) to define wherewe need to go; (b) to reflect on where we are now; and (c) to reflect on how we will go there by making productivemoves.To be specific, in this study students used ITM to review their discourse to identify collective themes andgoals of knowledge building on the basis of the diverse range of questions and interests represented in theirdiscourse and work. They also synthesized the “big ideas” learned and gaps using ITM’s Journey of Thinkingfeature. To assess their social dynamics, they reviewed their participation in each idea thread and build-onconnections as reflected in the social network graphs. As an extension of the collaborative assessment, eachstudent further self-assessed his/her individual knowledge development through writing portfolio notes thatsummarize what has been learned from the whole community’s work. By examining the idea thread maps, socialnetwork graphs, and portfolio notes, students identified strengths and advances of their work as well as weak areasand potential connections to be addressed in future inquiry. Based on discussions of these findings, theyconstructed plans to deepen their collective inquiry, refine collaboration, and increase personal contribution.This design-based research was conducted to test and refine the above assessment design in twoelementary classrooms. The process of the assessment, including the role of the teacher, was analyzed using videoanalysis and reported in Chen (2015). The current paper focuses on the role of the assessment in sustainingknowledge building. Our research question asks: In what ways does the collaborative, formative assessmentsupport collaborative deepening moves in the community’s online discourse and advancement of student personalunderstanding?MethodClassroom contextsThis study was conducted in two comparable Grade 6 classrooms at Zongbei Elementary School in Chengdu,China. The two classrooms had been implementing knowledge building pedagogy using Knowledge Forum(Scardamalia & Bereiter, 2006) for two years. Students in each classroom (39 students in class A, and 42 in B)studied two science units—energy and biodiversity—over a four-month period. The two classrooms were taughtby the same science teacher in cooperation with an ICT (Information and Communications Technologies) teacherwho supported the online discussions.Research designThis design-based study (Collins, Joseph, & Bielaczyc, 2004) adopted a two-phase, time-lag design. In phase/Unit1 focusing on energy, only class A conducted ITM-aided collaborative assessment; in phase/Unit 2 focusing onbiodiversity, the assessment was refined and extended to both classrooms. The impact of collaborative assessmentin the knowledge building practice was examined by comparing Class A to B in phase 1 and comparing Class B’performance between the two phases.The inquiry in each unit lasted for eight weeks. Each week they had four 40-minute lessons, typicallytwo focusing on face-to-face activities and two for online discussions. The assessment was first implemented inWeek 4. The community engaged in the following activities to assess its collective knowledge advancement:(a) Setting focus: The community members reviewed their ongoing discussions to identify what theyneed to understand, represented as shared, high-interest themes of inquiry. The students first generated a “themelist” in their notebooks, and then proposed their themes to the community. Through a whole class discussion thecommunity reviewed the themes and their connections, and co-created a list of shared themes of inquiry, as theassessment focus.(b) Collecting evidence: Based on the shared focal themes of inquiry, the students formed into groupseach of which used ITM to identify important Knowledge Forum notes for each focal theme of inquiry, as an ideaICLS 2016 Proceedings649© ISLSthread. The idea threads were further co-refined through group discussions to remove the unrelated notes, addmore notes, highlight key notes. Through reviewing the notes in each idea thread, each group co-authored a“Journey of Thinking” synthesis to highlight the important ideas and questions.(c) Generating feedback: With the map of idea threads projected on a screen, the communitycollaboratively interpreted the processes and progress of collective knowledge advancement, using intensivediscourse contributions, connections, highlighted notes, and “Journey of Thinking” syntheses in the different ideathreads as indicators of collective advancements. Through the collective review, students identified importantinsights gained as well as gaps and challenges to be addressed in each line of inquiry and connections to be builtacross the inquiry themes.(d) Planning: Based on the feedback, the community then made two types of plans to deepen theirknowledge building work: in groups they made plans for deeper inquiry in their focal idea threads, and as a wholeclass they generated plans and suggestions for their whole inquiry initiative to guide the work of all members.Extending the reflection on collective knowledge, the community reflected on their ways of collaborationwith the social network analysis tool that shows who had read and who had built onto whose notes. Throughinterpreting the social network graphs, they reflected on possible ways to improve their participation and socialconnections. Informed by the collaborative assessment, each student further wrote a portfolio note to reflect onwhat he/she had learned about the various inquiry themes of the community and how they would better contributeto the collective knowledge work and improve their own learning.Guided by the collaborative and individual plans, students conducted further inquiry for two more weeks.Near the end of the unit, the students conducted another round of assessment to update their idea threads (e.g.adding new Knowledge Forum notes), revisit the idea thread maps, and update their individual portfolio notes.The assessment design was refined based on its implementation and data analysis in Unit 1. The major changeswere to create a more connected and smooth flow of the assessment activities, help students understand thepurposes of the activities through discussions, and integrated the assessment information (e.g. social networkgraphs and ITM maps).Data sources and analysesThe data sources included online discourse, personal portfolio notes, social network data of the online discussions,and the graphical and textual representations on ITM including idea threads, idea thread maps, and Journey ofThinking syntheses.Content analysis (Chi, 1997) was conducted to gauge the quality of the knowledge building discoursebefore and after the assessment. Knowledge building discourse is characterized by progressive moves to identifydeepening problems and develop increasingly sophisticated explanations (Hakkarainen, 2003; Scardamalia &Bereiter, 2006; van Aalst, 2009). Based on our prior studies (Zhang et al., 2007; 2009), our coding scheme firstidentified initial notes that posted questions, and classified the questions as basic fact-seeking questions (e.g.what) vs. deeper explanation-seeking questions (why and how); idea-initiating wonderments vs. idea-deepeningquestions and idea-clarifying questions. We then coded student build-on notes to examine students’ interactiveinput based on theorizing and explaining (T), using evidence (E), referencing sources (R), connecting andintegrating (C), and designing and applying (D). Theorizing/explaining included five sub-categories: intuitiveexplanations (T1i), alternative explanations (T1a), refined explanations (T1r), clarifying explanations (T1c), andsuggestions (T1s) (see the coding scheme at http://tccl.rit.albany.edu/papers/Coding-scheme.pdf). The density ofthe build-on interaction (i.e. who had built on whose notes) was further analyzed using social network analysis.Students’ individual portfolio notes were coded by two independent coders through content analysisfocusing on the scope of knowledge, depth of understanding, and connectedness of ideas. To examine the scopeof student personal understanding, each portfolio note was coded based on the list of the themes covered by thecommunity’s online discussions. Student ideas related to each theme were coded for depth of understanding usingtwo well tested four-point scales (Zhang et al., 2007; 2009): scientific sophistication (1=pre-scientific, 2=hybrid,3=basically scientific, to 4= scientific) and epistemic complexity (1=unelaborated facts, 2=elaborated facts,3=unelaborated explanations, and 4=elaborated explanations). Student ideas related to each theme were furthercoded based on connected/coherent vs. unconnected/scattered. A satisfactory inter-rater reliability was achieved:Cohen’s Kappa = .84 for the coding of themes, .83 for scientificness, .82 for complexity, and .89 for ideaconnectedness.ResultsICLS 2016 Proceedings650© ISLSContent analyses of the knowledge building discourseTo investigate the role of the collaborative formative assessment in sustaining collaborative knowledge building,our analyses examined the changes in the knowledge building discourse before and after the assessment betweenthe two classrooms based on questions raised and build-on moves to generate and improve ideas.Questioning moves in the online discourseTable 1 reports the distribution of the different types of questions in the online discourse of the classroom A andB before and after the assessment activities. In Unit 1 for the energy study, only class A implemented theassessment design. In Unit 2 for the biodiversity study, both classrooms implemented a refined version of theassessment design.Table 1: The frequencies and percentages of different types of questions raised in the discourse of the twocommunities before and after the assessment in the two units of study.Class AUnit 1(ITM assessment)Class BUnit 1(no ITM assessment)Class AUnit 2(refined ITMassessment)Class BUnit 2 (refined ITMassessment)BeforeAfterBefore class A’sassessmentAfter class A’sassessmentBeforeAfterBeforeAfterFactseeking30Explanationseeking4Ideainitiating5Ideadeepening3Ideaclarifying366.67%8.89%11.11%6.67%6.67%28%3252.46%5520%23.28%3312%34.92%01040%711.48%2312%1524.59%726.32%15.79%0%10.53%36.84%251437645.45%25.45%5.45%12.73%10.91%310.34%2858.33%515.63%827.59%612.5%618.73%310.34%918.75%515.63%931.03%24.17%825%310.34%36.25%825%*Note. The percentages of some contribution types add up to over 100% because each note may be coded formultiple categories.In Unit 1 before the assessment, fact-seeking questions (e.g. what, how many) dominated the discoursein both classrooms (66.67% for A and 52.46% for B), with very few higher-level questions such as explanationseeking questions. A Chi-Square test shows no significant difference between the two classes (p > .05). Afterclass A’s assessment, class A generated more explanation-seeking (20%) and idea-deepening questions (40%) toexplain reasons, relationships, specific mechanisms while class B generated more idea-clarifying questions(36.84%) and fact-seeking questions (26.32%) to search for and clarify information (χ2 (12) = 132.76, p < .05).In the Unit 2, raising factual questions was the dominant pattern of discourse in both classes before theassessment (45.45% for A and 58.33% for B). After the assessment, both classroom had a drop in factual questionsand an increase in explanation-seeking and idea-deepening questions that are essential to sustained, progressivediscourse for knowledge building.Patterns of build-on notesThe network density of who had built on whose notes increased over time for each classroom in each unit ofstudy. In Unit 1, a greater increase in the density was observed in class A (15.38%) after its assessment than inclassroom B (10.19%) that did not use the ITM-aided assessment. In Unit 2 when both classrooms conducted arefined version of the ITM-aided assessment, both classes had a higher increase in the density (Class A: 17.29%;Class B: 18.54%).Figure 1 shows the patterns of the build-on notes to generate and improve ideas in the online discoursebefore and after the assessment in the two classrooms. In Unit 1, before the assessment of class A, a majority ofstudents’ build-on notes in both classes contributed intuitive explanations based on personal experience (58.11%ICLS 2016 Proceedings651© ISLSfor A and 41.58% for B) and referred to sources of information from readings (24.32% for A and 29.21% for B).After the assessment, class A contributed less intuitive explanations (decreased from 58.11% to 36%) and morerefined/sophisticated explanations (increased from 5.41% to 20%). In contrast, class B brought in even moreintuitive explanations (increased from 41.58% to 62%) with few notes contributing refined explanations (4.95%).In Unit 2, before the assessment a majority of students’ build-on notes in both classes were also intuitiveexplanations (55.46% for class A and 46% for class B), followed by referencing sources of information (26.05%for class A and 34% for class B). After the assessment students in both classes contributed less intuitiveexplanations (38.98% for class A and 35.71% for class B) and referencing sources (16.95% for A and 22.32% forB). The percentage of refined/sophisticated explanations increased for both class A (from 8.4% to 12.71%) andB (from 2.67% to 16.07%). The changes after the ITM-aided assessment in Unit 2 in both classrooms areconsistent with the changes observed in Unit 1 for class A after its implementation of the assessment.Figure 2. Patterns of the build-on notes before and after the assessment in the two classes in the two units:energy (left) and biodiversity (right).Content analysis of individual portfolio notesTable 2 reports the content analysis of student individual portfolio notes based on the themes of inquiry covered,depth of understanding about each theme as gauged based on the sum of two ratings, scientificness (1-4) andepistemic complexity (1-4), and percentage of inquiry themes with connected and coherent ideas.Table 2: Evaluation of Personal Knowledge Advances Summarized in Student Portfolio NotesClass AUnit 1:EnergyUnit 2:BiodiversityThemescoveredM (SD)Depth ofunderstandingM (SD)4.83 (1.84)5.4 (1.89)5.11(1.57)6.6 (1.44)Class BConnectednessof ideasM (SD)9.34%(18.22%)28.31%(26.70%)ThemescoveredM (SD)Depth ofunderstandingM (SD)4.26(2.11)4.74 (1.76)5.41(1.97)5.26 (1.7)Connectednessof ideasM (SD)13.24 %(22.53%)25.80%(27.99%)Focusing on each of the three indicators, a two-way repeated measure ANOVA was conducted tocompare the quality of the portfolio notes from the two classrooms in the two units of study. A significantbetween-class difference was found in depth of understanding (F(1, 34) = 11.44, p < .05) with class Aoutperforming B. The between-unit difference is significant in each of the three indicators, for the number ofinquiry themes covered (F(1,34) = 7.3, p < .05), for the depth of understanding (F(1, 34) = 23.49, p < .05), andfor connectedness of ideas F(1, 34) = 18.67, p < .05. The refinement of the collaborative assessment in Unit 2 ledto improved results.ICLS 2016 Proceedings652© ISLSDiscussionThis study tested a collaborative, formative assessment for knowledge building, which focuses on three majorconstructs: collective knowledge advancement, social dynamics, and individual understanding. Students playedan active and collaborative role in each step of the formative assessment supported by their teacher: to identifyshared focuses and deepening goals of inquiry as their discourse evolved; to collect and interpret evidence of ideacontributions, advancement, and collaboration; and to generate feedback and guidance about how to address theirdeeper needs and gaps of knowledge through further inquiry. The ITM tool served to represent their collectivefocuses of inquiry, make the collective progress in various lines of inquiry transparent for collective review, andsupport student efforts to reflect on their Journey of Thinking in terms of where they were going, where they werenow, and what deeper efforts were needed. As the results indicated, this collaborative, formative assessmentplayed an important, positive role to improve students’ collective, progressive discourse as well as individualunderstandings. Specifically, engaging in the collaborative formative assessment using ITM helped students toengage in deeper knowledge building discourse through generating more explanation-seeking and idea-deepeningquestions. The ITM-aided assessment on idea progress in each line of inquiry, including summarizing focalproblems, “big ideas” learned and deeper issues, served to catalyze student intentional efforts of progressivequestioning. In response to the deepening questions and ideas from their peers, students’ build-on notescontributed more refined and sophisticated explanations after the formative assessment.The positive association between the assessment and the enhanced discourse quality should largely beattributed to the purposeful design of the collaborative formative assessment: to enhance student monitoring ofcollective knowledge and generate ongoing feedback to guide sustained idea improvement (Zhang et al., 2009,Zhang et al., 2013). Through the assessment aided by ITM’s visualization and analytic tools, students made moreinformed reflection on which lines of ideas needed to be improved through what deeper actions and contributions.Small groups then planned on how to further advance each idea thread, and the class, as a whole, discussedcollective efforts to improve the whole inquiry. Supported by the collaborative reflection, individual studentsmade informed decisions about how to connect their individual interest, strength and resources with thecommunity’s needs.The results also revealed a positive role played by the ITM-aided collaborative assessment to enhancestudents’ personal knowledge gains as they advanced their collective knowledge. Class A with the collaborativeformative assessment in Unit 1 demonstrated deeper understandings in student portfolio notes than class B.Significant improvements were observed from Unit 1 to 2. In Unit 2 that implemented a refined design of theassessment, students’ portfolio notes addressed a broader range of inquiry themes that were explained using morescientific, complex, and connected ideas. The assessment helped students to have a reflective awareness of theimportant inquiry themes and idea advancements across their community’s knowledge space, understanddiscourse contributions and connections in a temporal context, and connect ideas to generate coherentunderstandings. These results suggest that the refinement of the assessment in Unit 2 to support a more coherentflow of the assessment activities and integrated view of the assessment information helped to increase theeffectiveness of the assessment. Of course, this two-phase research design cannot rule out the possible impact ofthe content topics (e.g. energy vs. biodiversity) on the complexity of student portfolio texts, although both topicsare open-ended and relevant to student interest.In conclusion, this research tested a collaborative formative assessment for knowledge buildingcommunities, with ITM mapping out the community’s online discourse as unfolding conceptual trajectories ofinquiry. In line with existing research on student-directed, technology-supported assessment for knowledgebuilding (van Aalst, J., & Chan, 2007), this study found a positive role of the assessment in enhancing theprogressive discourse of the community with deepening questions and refined explanations while supportingindividual efforts to generate deeper and connected understandings. A condition to increase the effectiveness ofsuch assessment is to integrate the assessment process coherently with the knowledge building process withoutcausing much additional work among students. We are conducting research to refine the design of this assessmentto integrate the activities and assessment information with an easy flow, supported by automated analyses in ITMthat can assist students to cluster discourse contributions based on inquiry topics and review discoursecontributions based on different types. Further research also needs to test this assessment design in otherclassroom contexts and content areas to elaborate the design and examine its impacts.ReferencesChen, J. (2015). Formative assessment for collaborative knowledge building in Chinese elementary scienceclassrooms. Doctoral dissertation submitted to the University at Albany. Retrieved from ProQuestDissertations and Theses (Accession Order No. AAT 3722030).ICLS 2016 Proceedings653© ISLSChen, M.-H., Zhang, J. & Lee, J. (2013). Making collective progress visible for sustained knowledge building. InN. Rummel, M., Kapur, M. Nathan, & S. Puntambekar (Eds.), To See the World and a Grain of Sand:Learning across Levels of Space, Time, and Scale: CSCL 2013 Conference Proceedings Volume1 (pp.81-88). Madison, WI: International Society of the Learning Sciences.Chi, M. T. H. (1997). Quantifying qualitative analysis of verbal data: A practical guide. Journal of the LearningSciences, 6, 271–315.Collins, A., Joseph, D. & Bielaczyc, K. (2004). Design research: Theoretical and methodological issues. Journalof the Learning Sciences, 13(1), 15–42.Hakkarainen, K. (2003). Progressive inquiry in a computer-supported biology class. Journal of Research inScience Teaching, 40(10), 1072–1088. doi:10.1002/tea.10121Lee, E.Y.C., Chan, C.K.K, & van Aalst, J. (2006). Students assessing their own collaborative knowledge building.International Journal for Computer-Supported Collaborative Learning, 1, 277-307.Mislevy, R. J., & Haertel, G. D. (2006). Implications of evidence-centred design for educational testing.Educational Measurement: Issues and Practice, 25(4), 6-20.Pellegrino, J. (2014). A learning sciences perspective on the design and use of assessment in education. In K.Sawyer (Ed.), Cambridge Handbook of the Learning Sciences (2nd edition) (pp. 262-282). New York,NY: Cambridge University Press.Sadler, R. (1989). Formative assessment and the design of instructional systems. Instructional Science, 18, 119–144.Scardamalia, M., & Bereiter, C. (2006). Knowledge building: Theory, pedagogy, and technology. In R. K. Sawyer(Ed.), Cambridge handbook of the learning sciences (pp. 97-115). New York, NY: Cambridge UniversityPress.Scardamalia, M., & Bereiter, C. (2010). A Brief History of Knowledge Building. Canadian Journal of Learningand Technology/La Revue Canadienne de l’Apprentissage et de la Technologie [online], 36(1). Retrievedfrom http://www.cjlt.ca/index.php/cjlt/article/view/574/276Shepard, L. A. (2000). The Role of Assessment in a Learning Culture. Educational Researcher, 29(7), 4–14.Stahl, G. (2006). Group cognition. Cambridge, MA: MIT Press.van Aalst, J. (2009). Distinguishing knowledge sharing, knowledge construction, and knowledge creationdiscourses. International Journal of Computer-Supported Collaborative Learning, 4(3), 259-287.van Aalst, J., & Chan, C. K. K. (2007). Student directed assessment of knowledge building using electronicportfolios in Knowledge Forum. Journal of the Learning Sciences, 16, 175–220.Wiliam, D. & Thompson, M. (2007). Integrating assessment with instruction: What will it take to make it work?In C.A. Dwyer (Ed.) The future of assessment: Shaping teaching and learning. Mahwah, N.J.: LawrenceErlbaum Associates.Zhang, J., & Chen, J. (2012). Building knowledge through the cyber space. In: Z. Yan (Ed.), Encyclopedia ofcyber behavior (pp. 383-393). Hershey PA: IGI Global. (I, R)Zhang, J., Chen, M.-H., Tao, D., Lee, J. Sun, Y., & Judson, D. (2015). Fostering sustained knowledge buildingthrough metadiscourse aided by the Idea Thread Mapper. In O. Lindwall & S. Ludvigsen (Eds.),Exploring the material conditions of learning: Proceedings of the 11th International Conference onComputer Supported Collaborative Learning (Vol. 1, pp. 166-173). Gothenburg, Sweden: InternationalSociety of the Learning Sciences.Zhang, J., Scardamalia, M., Lamon, M., Messina, R., & Reeve, R. (2007). Socio-cognitive dynamics ofknowledge building in the work of nine- and ten-year-olds. Educational Technology Research andDevelopment, 55(2), 117–145.Zhang, J., Scardamalia, M., Reeve, R., & Messina, R. (2009). Designs for collective cognitive responsibility inknowledge building communities. Journal of the Learning Sciences, 18(1), 7–44.AcknowledgmentsThis research was sponsored by the National Science Foundation (IIS #1122573, IIS #1441479). We would liketo thank Dr. Heidi Andrade and Dr. Alandeom Oliveira for their advisory input. We owe special thanks to theparticipating teachers and students for their classroom work enabling this research; and to the members of ourteam who contributed to the design and development of Idea Thread Mapper.ICLS 2016 Proceedings654© ISLS