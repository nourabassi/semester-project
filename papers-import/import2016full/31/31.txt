Opportunities to Learn Through Design:Mapping Design Experiences to Teacher LearningEmily Horton, Jahneille Cunningham, Louis M. Gomez, and Kimberley Gomez,eshorton@gmail.com, jah.cunningham5@gmail.com, louismgomez@gmail.com, kpg1321@gmail.comUniversity of California, Los Angeles, CAKatherine Rodela, Washington State University Vancouver, katherine.c.rodela@gmail.comAbstract: This paper examines the ways in which specific design experiences lead to certaintypes of learning. We engaged thirteen community college instructors in iterative designthrough Plan-Do-Study-Act (PDSA) cycles to design and develop new developmentalmathematics lessons. In this study, as in most design-partnerships, teachers touch only someaspects of the design process. In the work reported here, we make explicit the varying ways inwhich instructors took part in PDSA cycles and examine the types of knowledge generated bytheir participation. We use Edelson (2002) as a lens to categorize learning into three types:domain, design framework, and design methodology. Results indicate that instructors do notneed to be involved in every aspect of design to learn. Our findings highlight the role timeplays on engagement and learning in design. Implications for design efforts, to the extent theyare focused on learning, are discussed.IntroductionIncreasingly, education practitioners, policy makers, and researchers recognize that teaching quality is key tostudent achievement (Darling-Hammond & Richardson, 2009). The link between high-quality professionaldevelopment and student outcomes is sound (Borko, 2004; Desimone, 2009); however, only recently haveresearchers become concerned with deciphering the underlying, and often messy, links between professionaldevelopment conditions, what and how teachers learn, and transformation of classroom practices (Borko, 2004;Clarke & Hollingsworth, 2002). This study seeks to contribute to this growing body of literature, probing howteacher engagement in design can foster meaningful learning and promote changes in classroom practice.A number of studies point to design as a site for teacher learning (Gomez et al, 2015; Koehler &Mishra, 2005; Voogt, 2015). Design is the systematic development of an educational innovation (e.g: curricularmaterial, technology) to support some aspect of student learning (Edelson, 2002; Joseph, 2004). Edelson (2002)conjectures that if one participates in design processes, s/he will have many opportunities to learn. Mostcommonly, however, teachers, less often the engines driving the design effort (Penuel, Fishman, Yamaguchi &Gallagher, 2007), participate in only some elements of design. Thus, to better understand what teachers canlearn as they engage in design, we must understand how specific design experiences lead to certain types ofprofessional learning. Although the current literature is sparse, we posit that it would be fruitful to probeopportunities to learn in specific aspects of the design experience.We report results from a two-year study, where we take up this question. We engaged 13 communitycollege instructors in Plan-Do-Study-Act (PDSA) cycles (Langley et al., 2009), our design methodology guidingthe iterative design of developmental mathematics lessons. We make explicit the varying ways in whichinstructors, who are critical to the design effort but do not drive the design process, took part in PDSA cycles,and examine the types of knowledge generated by their participation.Community college developmental mathematics classrooms are important sites for learning by design.Efforts to increase the quality of teaching are gravely needed. Yet this problem receives relatively little attention(Boylan, 2002; Stigler, Givvin & Thompson, 2010). Each year, over thirteen million students enroll incommunity colleges across the U.S. For 59% of these students, the dream of graduation is quickly shatteredwhen they are placed into developmental, or remedial, mathematics courses (Bailey, Jeong, & Cho, 2010). Witha 30% success rate (Levin & Calcagno, 2007), developmental mathematics have been called the “graveyard ofdreams and aspirations” (Merseth, 2011). Students are often doomed to retake courses, resulting in prolongedenrollment, increased debt, and in many cases, eventual dropout (Stigler, Givvin & Thompson, 2010). A coreassumption of this paper is that professional development could figure largely in the reform of developmentalmathematics. As such, we seek to examine ways in which developmental mathematics instructors learn throughengagement in design as a means to improve instructional practices, and in turn, student outcomes.ICLS 2016 Proceedings226© ISLSDesign as professional developmentStudies that explore the potential of design for professional learning suggest that the elements of design key tolearning include: situating learning in practice (Joseph, 2004); active inquiry into the problem (Koehler &Mishra, 2005; Kolodner et al., 2003), sustained and organized engagement (Collins, 1992; Koehler & Mishra,2005), and collaboration (Voogt, 2015), as they align with key characteristics of effective professionaldevelopment (Borko, 2004; Desimone, 2009; Little, 1990). Active and situated learning opportunities allowteachers to integrate new knowledge with existing knowledge (Davis & Krajcik, 2005), resulting in meaningfuland authentic learning (Greeno, 1998). Using cyclical attempts to improve the intervention, designers learn mostin their moments of failure. When one aspect of the design does not work, designers must reason through theways different design elements work together, considering how change to one area of design may impactanother (Collins, 1992). This decision-making process, requiring exploration of nuanced relationships betweenthe tool, students, and local context (Koehler & Mishra, 2005; Krajcik et al, 1998), provides designers withimportant opportunities to learn (Edelson, 2002). Disciplined inquiry, coupled with the collaborative nature ofdesign, provides a venue for instructors to encounter distributed knowledge as they take part in purposefuldiscourse with collaborators from diverse backgrounds. Such collaboration can be transformative as it allowsdesigners to gain increased awareness of their own practices and beliefs (Koehler & Mishra, 2005).Design is sustained over time and organized, another important characteristic that supports learning.The use of cyclical testing to develop optimal design solutions (Collins, 1992; Koehler & Mishra, 2005;Kolodner et al., 2003) naturally extends participation in design over time. There is a growing consensus thatprofessional development that is sustained over longer periods of time presents increased opportunities forteachers to assimilate new knowledge into practice (Desimone, 2009). Studies have shown that when not givenenough time in professional learning, teachers often do not retain what they learn and evidence little change inclassroom practice (Coburn, 2004). Other scholars suggest that extended duration is not enough, and that timemust be organized into structured activities, with purpose, to produce effective change (Garet, Porter, Desimone,Birman & Yoon, 2001). Adherence to a specific a design methodology provides this organization, guiding thoseparticipating in design through design activities (Collins, 1992).In this study, we ask, what is the relationship between kinds of design contact and specificopportunities to learn? The guiding hypothesis of this paper is that amount of time instructors spend in designmay have consequences for the quality of their engagement in design activities and professional learninggenerated. We follow Edelson (2002) to explore three types of learning: 1) domain learning, which refers toincreased knowledge about the design setting, such as increased understanding of the language and literacyneeds of developmental mathematics students; 2) design framework learning, or an instructor’s increasedunderstanding of the design ideas involved in the design solution (in this case, mathematics, language andliteracy tools, problem situation, and pedagogy in the new lesson); and 3) design methodology learning, whichindicates an instructor’s increased understanding of the design procedures, or in this study, PDSA cycles.MethodsThis study focuses on the collaborative design of 12 new developmental mathematics lessons. Our design goalswere to contextualize lessons and reduce language barriers. Contextualization, or the integration of academicand occupational curricula, engages students in real-life, authentic problems resulting in more meaningfullearning, making it easier to internalize, understand, transfer, and retain (Herod, 2002).Participants. We examined data from 13 instructors from 6 community colleges across the U.S., whoparticipated in lesson testing. Instructors volunteered to participate, and received a small honorarium for theirwork. Instructors engaged in design in varying ways (see Table 1); this allowed us to examine the ways in whichspecific design activities generate learning. We will detail this involvement in the next section.PDSA Cycles. We used Plan Do Study and Act (PDSA) cycles to guide the developmental arc of thedesign work. An Improvement Science tool, PDSAs are characterized by quick iterative learning, fast failure,and rapid refinement (Langley et al., 2009). Instructors touch the PDSA cycles in the following ways. Ourcycles began with a few instructors teaching the same lesson. “PLAN” occurs as instructors prepare to enact thelesson. “DO” occurs as instructors conduct a test by enacting the lessons. Within two days of enacting a lesson,instructors participated in either a follow-up semi-structured, open-ended interview (Seidman, 2006) or a surveyaimed to gain insight into instructor experience teaching the lesson and recommendations for refinements.“STUDY” includes instructor’s participation in these interviews and surveys. We then collected and analyzeddata from lesson enactments, summarized results, and made quick revisions to the lesson before a new cycle ofinstructors tested the same lesson. “ACT” occurs as faculty, along with the design team, work out the plan forthe next testing cycle. These cycles continued until all participants taught the lesson. Halfway through the PDSAcycles, we made intermediate refinements to the lesson based on more extensive data analysis. At the end ofICLS 2016 Proceedings227© ISLStesting, six of the thirteen participants attended a two-day design workshop to make long-term changes to thelessons. Participation in this meeting falls under “ACT”1. The use of PDSA cycles allowed the design team tomanage design revisions efficiently, as team members decided when and how design changes should beaddressed. PDSAs recognize that straightforward design changes could be implemented immediately whilemore complex changes were put aside for later revisions. Data resulting from instructor engagement in PDSAsinclude: 51 instructor interviews, 52 instructor surveys, artifact design changes (documented changes within andacross lessons), and ethnographic field notes of the 2-day instructor design meeting.Table 1: Instructor Engagement in PDSAsFrank: designed 4 lessons, enacted 9 lessons,9 interviews, 9 surveys, design meetingCatherine: enacted 7 lessons, 6interviews, 5 surveys, ½ design meetingKelly: enacted 2 lessons, 2interviews, 2 surveysNate: designed 8 lessons, enacted 8 lessons, 4interviews, 4 surveys, design meetingMaria: enacted 3 lessons, 3 interviews,3 surveys, design meetingTed: enacted 2 lessons, 2interviews, 2 surveysKyle: enacted 9 lessons, 9 interviews, 9surveys, design meetingNatalie: enacted 3 lessons, 3interviews, 3 surveysKristen: enacted 2 lessons, 1interviews, 2 surveysHenry: enacted 9 lessons, 9 interviews, 9surveys, design meetingNancy: enacted 3 lessons, 2 interviews,1 surveysQuincy: enacted 3 lessons,2 surveysDana: enacted 1 lesson,1 survey, 1 interviewData Analysis. We analyzed design workshop ethnographic field notes, transcribed interviews,interview notes, survey responses, and artifact design changes. We coded instances of professional growth usingClarke and Hollingsworth’s (2002) Interconnected Model of Professional Growth (IMPG). In accordance withthe model, we coded for changes in: 1) knowledge, belief, or attitudes; 2) classroom practice; 3) salientoutcomes; and 4) use of new materials. This allowed us to identify instances of change and determine wherelearning occurred. In the second cycle of coding, Edelson’s (2002) framework guided our coding for three typesof learning: domain learning, design framework, and design methodology. This allowed us to understand thetypes of instructor learning generated by design participation.Table 2: Duration and EngagementTable 3: Duration and LearningHigh Design Time Group (HDT)HDT ParticipantsNate 106Frank 79.5Kyle 39.5Henry 39.5Maria 26.5Catherine 23High Design Time Group (HDT)HDT ParticipantsNate 106Frank 79.5Kyle 39.5Henry 39.5Maria 26.5Catherine 23High Engagement ScoresCatherine 5Frank 4.69Henry 4.67Low Engagement ScoresNate 4.42Maria 4.21Kyle 3.56ICLS 2016 ProceedingsLess Learning ScoreHenry / Maria 6Catherine / Kyle 4Low Design Time Group (LDT)Low Design Time Group (LDT)LDT ParticipantsNatalie 10.5Nancy 8.5Ted 7Kelly 7Quincy 4Kristen 4Dana 3.5More Learning ScoresNate 28Frank 20LDT ParticipantsNatalie 10.5Nancy 8.5Ted 7Kelly 7Quincy 4Kristen 4Dana 3.5High Engagement ScoresNatalie 4Nancy 5Ted 5Kelly 5Low Engagement ScoresQuincy 2.83Kristen 2.25Dana 3228More Learning ScoresTed 3Natalie / Quincy 1Kristen 1Less Learning ScoresNancy / Kelly/ Dana 0© ISLSGiven the variation in instructor involvement in PDSA cycles, we developed a scoring system tostratify participants into groups based on their number of hours engaged in design activities, quality ofengagement, and learning generated by participation in design. First, we calculated participants’ total hoursspent in design work (including lesson enactment) and performed a median split to separate the top and bottom50% in regards to total time spent on design (duration ranges from 3.5-106 hours). Within each ‘design time’category, we performed a sub-split to compare instructors on the basis of quality engagement (high or low) (seeTable 2). The authors gave each participant an engagement score using a Likert scale (low engagement=1 andhigh engagement=5) based on his or her willingness to give feedback on classroom experiences and providedesign revisions in each design opportunity (engagement scores range from 1-5). The authors scoredengagement individually (interrater reliability is 84%), and inconsistent scores were averaged. We then created asecond system using the initial ‘design time’ median split to perform a sub-split on the basis of learning (high orlow) (see Table 3). Learning scores take into account the number of instances of teacher change and the kinds oflearning generated (domain, design framework, and design methodology), and range from 0-28. The goal was toexamine the following relationships: 1) the relationship between design time and level of engagement, and 2)the relationship between design time and learning. Given that research supports the learning potential forsustained, meaningful professional development (Garet, Porter, Desimone, Birman & Yoon, 2001), we predictedthat we would find a positive relationship between design time and engagement and instructor learning.FindingsWe used qualitative methods to uncover the ways in which engaging in key elements of design might lead tolearning. Our findings are limited by the small sample size that rendered inferential testing less optimal forexamining the relationship between design time and engagement and learning. Our intention was not toestablish correlation or cause, but rather to initially characterize the broad outlines of phenomena that mightconnect design experience to professional growth.The results of this study suggest the relationship between design time, design engagement, and teacherlearning are more complex than predicted. That is, an increase in design time was not always associated with anincrease in engagement or learning. Our findings in the High Design Time (HDT) group do suggest, however,that a relationship exists between duration of engagement and types of learning when instructors engage in atleast 20 hours of design work, consistent with Desimone (2009). Our findings support Edelson’s (2002)perspective; ten out of thirteen instructors showed evidence of professional learning in at least one of threecategories of learning: design domain, design framework, and design methodology. In what follows, wedescribe in more detail the relationship between duration and engagement and duration and instructor learning.Duration and engagementThe results of our analysis found the relationship between amount of time spent on design and level ofengagement to be unclear. Some instructors received engagement scores (ranging from 0-5) comparable to theirdesign time (ranging from 3.5-106 hours). For example, all three instructors who participated in less than fivehours of design work showed a low level of engagement (≤3). However, in most cases, the scores wereunpredictable. For example, three Low Design Time (LDT) instructors earned the maximum engagement scoreof 5, outscoring most of their HDT counterparts. The results of the level of engagement surprised us forparticular instructors even within design time groups. Catherine, who only spent 23 hours on design work, wasthe most engaged instructor in the HDT group with a score of 5. Nate, who participated in lesson design andspent the most time in design activities (106 hours), received only the fourth highest engagement score (4.42).Duration and learningOur findings indicate that increased duration of engagement in design activities is linked to increased and variedtypes of learning. Learning scores range from 0-28. The HDT instructors (duration ranging from 23-106 hours),and four of seven LDT instructors (duration ranging from 3.5-10.5 hours) showed evidence of domain learning.All six of the HDT instructors, but only one of the seven LDT instructors showed evidence of design frameworklearning. Only one HDT instructor of the thirteen total participants showed increased understanding of PDSAcycles, our design methodology. In all cases, the High Design Time (learning scores range from 4-28) instructorslearned more than their Low Design Time counterparts (learning scores range from 0-3).High Design Time (HDT) groupOur findings in the HDT group suggest that a relationship between time spent in design and learning may exist,but another variable may be at play. The HDT instructors were the only instructors in the study to participate inICLS 2016 Proceedings229© ISLS“ACT” activities, which engaged instructors in making design decisions with researchers to refine the lessons.In the HDT group a relationship between time spent in design and learning clearly exists, as we predicted.Instructors in this group participated in 23-106 hours of design work, and instructor learning scores range from4-28. Instructors Frank and Nate, who co-designed the initial lesson drafts with researchers, participated in > 75hours of design work and evidenced the highest learning scores (≥20). The other four instructors in the HDTgroup engaged in only 20-40 hours of design work and evidenced lower learning scores (≤6). While it seemsthat increased duration leads to increased learning, there is some unexpected variation within the “low-learning”group. Kyle had the highest number of design hours (39.5 hours) within the “low-learning group” yet had thelowest learning score (4), while Maria participated in only 26.5 hours of design, but generated a learning scoreof 6. Interestingly, Maria, like Kyle, had low a score of engagement, suggesting that engagement may not relateto instructor learning. It is important to note that while learning scores vary based on the number of occurrences,all instructors in the HDT group showed instances of learning about the domain and design framework, whileonly one evidenced learning about the design methodology. In what follows, we provide examples of thespecific types of learning generated in the High Design Time group.Learning about the Design Domain. All six HDT instructors exhibited increased domain knowledge.For example, throughout nine lesson enactments, Henry learned about the interactions between the local settingand the Comprehension and Synthesis2 (CaS) Chart (see Figure 1), a language and literacy tool critical to ourdesign. He showed a change in his beliefs about the usefulness of the CaS chart for his students, which resultedin a shift in his instructional practices, and in turn, student outcomes. Following the first lesson, Henry said: “...Ilike it,think it’s useful…fits my feeling of how we should approach information mathematically. It will helpstudents figure out what they’re doing before they put a number on it.” (Henry Interview, 1st enactment).However, his students did not necessarily agree: “There is some distrust over the system whether this [CaSchart] is going to be beneficial to students. Students are unsure about how to complete the CaS chart. Theyespecially struggle with Column C” (Henry Interview, 1st enactment).Figure 1. The CaS Chart.Figure 2. Kyle’s Adapted CaS Chart.However, by the ninth lesson enactment, Henry gained insight into the usefulness of the CaS chart for hisstudents, resulting in a shift in instructional practice: “I talk about the CaS as a tool for helping them understandreading…separate thinking into small parts, and start to organize a strategy for calculating...Thinking through astrategy before calculating is something I’ve added to the discussion about the CaS chart.” (Henry Interview, 9thenactment). Henry evidenced the impact of this change on student learning, reflecting on his enactment of theCaS Chart with a new class:Students gave decent reviews of the Cas Chart...reporting verbally that it was worth the timeto talk things out and sort information. One student specifically said that this [CaS Chart]matched the way she likes to think…Both classes…recognized the value of Column C…They were thinking about how they might approach the problem before they dive into it. Wehad…positive vibes from the class as they were discussing what they've found in that thirdcolumn.” (Henry Interview, 9th enactment)It is important to note that while this data evidences what domain learning looks like, other examples of designdomain learning do not evidence the impact of instructor learning on student outcomes, as this example does.Learning about the Design Framework. All six HDT instructors learned about the design framework.In this example, Kyle learned about the core ideas behind creating language and literacy supports. After his firstenactment of the CaS chart, Kyle reflects: “Having the two columns filled in with examples was helpful asacquiring the tool and material at the same time isn’t good. I don’t think the CaS chart was useful this timeICLS 2016 Proceedings230© ISLSbecause of the scaffolding. It might become useful in the future when they do it on their own.” (Kyle Interview,1st enactment). Following the second enactment, Kyle re-evaluates his belief that scaffolding is useful: “Youshould get rid of the scaffolding. It’s still not useful. You should introduce the CaS chart in a short lesson on it’sown.” (Kyle Interview, 2nd enactment). In the first two lesson enactments, Kyle builds understanding of how thedesign of CaS chart (i.e: scaffolding) impacts students. Following this cycle of testing, Kyle reflects withinstructors and researchers about the purpose and formatting of the CaS chart, “Column C seems superfluous bythe time Column A and B are completed. The directions instruct students to complete column A then B then C,but it is more cyclical. Students should know that it is an iterative process.” (Kyle, Instructor Design Meeting)Kyle developed a new version of the CaS chart, adapting it to fit his students’ needs (see Figure 2). He hascontinued to use this adapted version of the CaS chart in his classes, and is presenting his adapted version of theCaS chart at a practitioner’s conference this year.Learning about Design Methodology. Only Maria, a HDT instructor, showed evidence of increasedunderstanding of PDSA cycles. While PDSAs guided and documented design activities, instructors did not usethem directly. Maria became familiar with PDSAs through her participation in design activities, includinginterviews, surveys, and participation in the in-person meeting. As a result of this familiarity with PDSAs, Mariais presenting PDSA as a tool for curriculum development to colleagues, and has sought additional consultationwith the research team to gain a better understanding of this design methodology. Although it is unlikely thatMaria would have gained familiarity with PDSAs without engagement in this work, without Maria’s subsequentpresentation as a external prompt, increased duration would not likely result in design methodology learning.Low Design Time (LDT) groupThe relationship between duration and learning is unclear in the LDT group. Instructors in this groupparticipated in 3.5-10.5 hours of design work, with learning scores ranging from 0-3. Two of the four instructorswith the most design time (7-10 hours) were also in the “high learning” group, but Nancy, who spent the secondhighest amount of time in design (8.5 hours), and Kelly (7 hours) do not evidence learning at all. In contrast,Quincy, who only engaged in four hours of design, evidenced one instance of learning. In the LDT group, fourof seven instructors evidenced learning; three increased design domain knowledge, but only one, Ted, evidencedlearning about both design domain and design framework. In this example, Ted builds his understanding abouthow the underlying design ideas of the Double-Entry Journal (DEJ), a language and literacy tool, interact withthe time allotment for his class as he engages in a post-enactment survey and interview. This is an importantexample because it provides evidence that engaging in “STUDY” activities may lead to learning.Before the interview, Ted completed a survey providing feedback on the lesson, in which he wrote:“You may want to consider using the DEJ with a shorter lesson.” (Ted Survey, 1st enactment). During theinterview, Ted discusses two different ways to save time while still including the DEJ:It’s just a lot of reading. It might be helpful for students to see a copy of the DEJ uponcompletion of the reading so that they would not have to go back and reread the introductoryinstructions…the task [DEJ] is out of context. I think it would have more meaning if they hadit in the context of the lesson…Then question six...You could use the DEJ there. In the [leftcolumn of the DEJ] say ‘Yes’ or ‘No’ and ‘Why’, in the [right column of the DEJ] havestudents use statistics to back up [the left column]. You could take most questions and turn itinto a DEJ. (Ted Interview, 1st enactment)Through DEJ enactment and reflection in the interview, essential components of PDSAs, instructor Ted learnedhow to reach a design solution that would address students’ needs, rather than simply eliminate the DEJ. Thetwo ideas he presented in the interview, displaying the chart for students after the reading and embedding thechart in existing mathematics questions are evidence of Ted’s learning about the DEJ’s importance.Ted spent the median number of hours (7) engaged in design work in the LDT group, but received thehighest learning score (3). Why did Ted stand out amongst his colleagues, as other instructors with similardesign time and engagement scores did not exhibit any learning at all? Nancy and Kelly, who spent 8.5 and 7hours on design, respectively, received learning scores of zero, but like Ted, received the highest engagementscore possible. This suggests that either engagement is unrelated to learning for these instructors, or that Nancyand Kelly learned in ways that we could not capture using the Edelson (2002) model.DiscussionVery commonly, instructors involved in design-partnerships only engage in some elements of design. We haveoffered some granular, though very preliminary, evidence of how engagement in specific elements of designICLS 2016 Proceedings231© ISLScontributes to certain types of learning. This work helps us understand the role of time in design experiences.The relationship between learning and time spent in design activities seems clear for instructors whoparticipated in more than 20 hours of design work, but this relationship is less apparent for the LDT group.Further, the relationship between duration and engagement remains unclear. It is possible that some instructorslearned information that was not captured in our current analysis. The relationship between engagement andlearning might also have impacted our findings. That is, instructors who were not as engaged during designmeetings or phone interviews may not have vocalized their learning. Future research should examine moreexplicitly the relationship between engagement and learning.In our analysis of instructor learning an unexpected category of learning emerged: pedagogical designcapacity (PDC), an instructor’s ability to recognize and employ resources to adapt existing, or develop new,instructional materials (Brown & Edelson, 2003). In this work, five of the thirteen instructors (and, in the HDTgroup, five out of six) adapted lessons to better support their students’ needs (Barab & Luehmann, 2003).Adaptations included changes to the language and literacy tools embedded in the lessons (as evidenced inKyle’s example above), creating additional mathematics questions, developing and integrating examples inareas where students struggle, and developing new problem contexts. As it became clear that the timeinstructors spent in design work played a role in kinds of learning, we began to see that PDC is consequential,resulting from the confluence of increased understanding of the design domain and design framework. Of thefive instructors who evidenced increased PDC, none evidenced learning about design methodology; thus, we donot believe that this is a critical category of learning in the development of PDC. Although PDC is indicative ofcertain types of learning, we argue that it is, in itself, an important type of learning generated from design, asadaption of curricular materials to align with local needs is critical for effective implementation (Barab &Luehmann, 2003). It is important to note that all instructors who evidenced PDC engaged in “ACT” designactivities, while the others (with the exception of 1 (Maria)) did not. While this may be a significant factor indeveloping towards PDC, more work must be done to better understand this relationship. While this studyevidences increased PDC in instructors, it does not shed light on the alignment of adaptations to designers’intentions; future work is necessary to understand how to support instructors in adapting materials to meet theirneeds while maintaining integrity of the design solution (Davis, Beyer, Forbes, & Stevens, 2011).Our findings highlight the opportunities for learning provided by design. Importantly, these resultssuggest that participation in design work can take on different forms; teachers do not necessarily need to beinvolved in every aspect of the design process to learn from the experience. Instructors in this work differed induration and forms in which they were involved with PDSA cycles. In general, our findings suggest thatinstructors who spent more time in design experienced more learning. Yet, four of the seven instructors whospent less than 10.5 hours in design showed evidence of learning, suggesting that even a short period of designactivity can present a learning opportunity. However, more work, which systematically assigns instructors tospecific PDSA activities, keeping duration the same, must be undertaken to better understand the relationshipbetween PDSA activities and learning. For example, the 6 instructors who participated in “ACT” activities werealso in the High Design Time group. All instructors participated in “PLAN”, “DO”, and “STUDY” activities,however, increased participation in these activities also increased overall duration spent in design activities.With the exception of Ted, who evidenced immediate learning as a result of participation in a “STUDY”activity, our data is insufficient to parse how engagement in specific PDSA activities generate learning.This work has important implications for future design efforts, especially in models concerned withprofessional learning, that engage teachers in some, and not all, elements of design. We argue that it is critical,as we did with PDSA cycles, to keep track of instructor duration, the ways in which instructors touch design,and quality of engagement. The use of PDSA cycles allowed us to trace the evolution of both the lessons andparticipants. With each iteration, informed by the instructors, the PDSA cycles captured design problems andpotential solutions. Thus, we were able to simultaneously gain insight into the lessons themselves, as well as thepeople who were enacting them. We believe that embedding these practices in design work provide a rich wayof talking about the kinds of learning generated from design.Endnotes(1) All 13 instructors participated in “PLAN”, “STUDY”, and “DO” activities, but only the six instructors at the designmeeting participated in “ACT” activities. We did not collect data on “PLAN” activities.(2) The CaS chart is a tool the researchers developed to support student comprehension in mathematics word problems.ReferencesBailey T., Jeong D. W., Cho S. W. (2010). Referral, enrollment, and completion in developmental educationsequences in community colleges. Economics of Education Review, 29(2), 255-270.ICLS 2016 Proceedings232© ISLSBarab, S. A., & Luehmann, A. L. (2003). Building sustainable science curriculum: Acknowledging andaccommodating local adaptation. Science Education, 87(4), 454-467.Borko H. (2004). Professional development and teacher learning: Mapping the terrain. Educational Researcher,33(8), 3-15.Boylan H. R. (2002). What works: Research-based best practices in developmental education. Boone, NC:Continuous Quality Improvement Network, National Center for Developmental Education,Appalachian State University.Brown, M., & Edelson, D. (2003). Teaching as design: Can we better understand the ways in which teachers usematerials so we can better design materials to support their changes in practice. Design Brief. Evanston,IL: Center for Learning Technologies in Urban Schools.Clarke D., Hollingsworth H. (2002). Elaborating a model of teacher professional growth. Teaching and TeacherEducation, 18(8), 947-967.Coburn, C. E. (2004). Beyond decoupling: Rethinking the relationship between the institutional environmentand the classroom. Sociology of Education, 77(3), 211-244.Collins, A. (1992). Toward a design science of education (pp. 15-22). Springer Berlin Heidelberg.Darling-Hammond, L. & Richardson, N. (2009). Research review/teacher learning: What matters. Educationalleadership, 66(5), 46-53.Davis, E. A., & Krajcik, J. S. (2005). Designing educative curriculum materials to promote teacher learning.Educational researcher, 34(3), 3-14.Desimone L. M. (2009). Improving impact studies of teachers’ professional development: Toward betterconceptualizations and measures. Educational Researcher, 38(3), 181-199.Edelson D. C.(2002). Design research: What we learn when we engage in design. The Journal of the LearningSciences, 11(1), 105-121.Garet, M. S., Porter, A. C., Desimone, L., Birman, B. F., & Yoon, K. S. (2001). What makes professionaldevelopment effective? Results from a national sample of teachers. American educational researchjournal, 38(4), 915-945.Gomez, K., Gomez, L. M., Rodela, K. C., Horton, E. S., Cunningham, J., & Ambrocio, R. (2015). EmbeddingLanguage Support in Developmental Mathematics Lessons Exploring the Value of Design asProfessional Development for Community College Mathematics Instructors. Journal of TeacherEducation, 0022487115602127.Greeno J. G. (1998). The situativity of knowing, learning, and research. American Psychologist, 53(1), 5-26.Herod, L. (2002). Adult learning from theory to practice. Retrieved March, 2, 2009.Joseph, D. (2004). The practice of design-based research: Uncovering the interplay between design, research,and the real-world context. Educational Psychologist, 39(4), 235-242.Koehler M. J., Mishra P. (2005). Teachers learning technology by design. Journal of Computing in TeacherEducation, 21(3), 94-102.Kolodner, J. L., Camp, P. J., Crismond, D., Fasse, B., Gray, J., Holbrook, J., & Ryan, M. (2003). Problem-basedlearning meets case-based reasoning in the middle-school science classroom: Putting learning bydesign (tm) into practice. The journal of the learning sciences, 12(4), 495-547.Langley G. J., Moen R., Nolan K., Nolan T., Nomran C., Provost L. (2009). Using the model for improvement.The improvement guide: A practical approach to enhancing organizational performance.Levin H., Calcagno J. C. (2007). Remediation in the community college: An evaluator’s perspective. New York,NY: Community College Research Center, Teachers College, Columbia University.Little J.(1990). The persistence of privacy: Autonomy and initiative in teachers’ professional relations. TheTeachers College Record, 91(4), 509-536.Merseth K. K. (2011). Update: Report on innovations in developmental mathematics—Moving mathematicalgraveyards. Journal of Developmental Education, 34(3), 32-33.Penuel W. R., Fishman B. J., Yamaguchi R., Gallagher L. P. (2007). What makes professional developmenteffective? Strategies that foster curriculum implementation. American Educational Research Journal,44(4), 921-958.Seidman I.(2006). Interviewing as qualitative research: A guide for researchers in education and the socialsciences. New York, NY: Teachers College Press.Stigler, J. W., Givvin, K. B., & Thompson, B. J. (2010). What community college developmental mathematicsstudents understand about mathematics. MathAMATYC Educator, 1(3), 4-16.Voogt J., Laferrière T., Breuleux A., Itow R. C., Hickey D. T., McKenney S. (2015).Collaborative design as aform of professional development. Instructional Science,43(2), 259-282.ICLS 2016 Proceedings233© ISLS