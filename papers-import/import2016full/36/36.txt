Joint Idea-Building in Online Collaborative Group DiscussionsYann Shiou Ong, The Pennsylvania State University, yannshiou@psu.eduMarcela Borge, The Pennsylvania State University, mborge@psu.eduAbstract: This paper defines the construct of joint idea-building in collaborative learningsituations, and proposes a hierarchy of sophistication levels of joint idea-building activity basedon the frequency of idea-building moves and the pervasiveness of extended idea-buildingmoves. Criteria for the sophistication levels are informed by qualitative analysis of sampledcollaborative online group discussions among college students tasked with discussing theirresponses to course-related questions. Our findings will be used to revise our existingassessment rubric for evaluating the sophistication level of joint idea-building activity in thecontext of online group discussions, as well as inform future work for improving the validity ofour rubric.Keywords: joint idea-building, assessment rubric, collaborative learning, online discussionsIntroductionCollaborative learning is a common theme among various research areas, including social, cognitive,developmental and educational psychology, the learning sciences, instructional design, and computer-supportedcollaborative learning (O’Donnell & Hmelo-Silver, 2013). One of the main group processes studied incollaborative learning is knowledge co-construction (Webb & Palincsar, 1996). Through collaboration, learnersco-construct knowledge they did not have prior to the collaboration (Damon & Phelps, 1989).In our previous study (Borge, Ong, & Rosé, 2015), we designed a rubric to evaluate the quality ofcollaborative processes in online group discussions of course-related questions. We encountered the challenge ofdefining the construct of joint idea-building, our conceptualization of knowledge co-construction, in a way thatcould help us distinguish between high and low performing collaborative groups. We consider the activity of jointidea-building as the extent to which learners act upon ideas introduced to the group by elaborating or extendingthese initial ideas. We examined the literature as a means to guide the development of communication codingframeworks and assessment tools to provide needed support for students. In doing so, we have found that existingliterature provides limited elaboration of what joint idea-building activity looks like concretely. Much work hasbeen done on other conceptualizations of knowledge co-construction, such as knowledge building (Scardamalia& Bereiter, 2006; Zhang, Scardamalia, Reeve, & Messina, 2009) and transactivity (Joshi & Rosé, 2007;Weinberger & Fischer, 2006), which we will discuss. However, after careful deliberation, we consider bothconstructs different than joint idea-building.This paper aims to contribute to the existing literature and existing methods for evaluating collaborativeactivity by providing a detailed description of the joint idea-building construct. This includes a proposed hierarchyof sophistication levels of joint idea-building activity based on the frequency of idea-building moves and thepervasiveness of extended idea-building moves. The criteria defining the levels of sophistication are identifiedthrough qualitative analysis of a sample of six teams’ (dyads and triads) online group discussions that are part ofan online undergraduate level course. Our findings from the empirical data will be used to revise our existingrubric for evaluating joint idea-building activity as well as inform future work for improving the validity of ourrubric.Related work and ideasDifferent conceptualizations of knowledge co-constructionThere are two prominent conceptualizations of knowledge co-construction in the literature, knowledge buildingand transactivity. According to Scardamalia and Bereiter (2003), knowledge building emphasizes the productionand advancement of public knowledge among a community of knowledge builders. Thus, the building of ideas,from the perspective of the knowledge-building framework, is at the level of the community, where the goal is toadvance the knowledge of the community. On the other hand, transactivity focuses on how individual learners actupon each other’s ideas at the level of turns of discussion and how they execute their collective reasoning processes(Berkowitz & Gibbs, 1983; Teasley, 1997). As Joshi & Rosé (2007) explain, transactivity combines the notion ofidea extension and elaboration with aspects of argumentation and knowledge negotiation.ICLS 2016 Proceedings266© ISLSBoth of these perspectives on knowledge co-construction differ from our conceptualization of joint ideabuilding. Our conceptualization of joint idea-building is at the level of an episode nested in a discussion within asmall group. A conceptual goal of these discussions is for learners to foster deeper understanding of ideas prior tocritiquing by developing and building the ideas jointly. An idea can be built through: (1) elaboration, such asproviding details, using analogies and examples, or highlighting pros and cons; or (2) extension, such asconnecting the idea to other ideas, generating a related idea, generalizing the idea, or synthesizing ideas.Challenges in defining and evaluating the sophistication of joint idea-building activityOur approach to evaluating the quality of joint idea-building arose from an attempt to help groups reflect onimportant markers of collaborative activity in order to improve upon them over time. For this reason, we neededa way to help collaborative learners recognize key aspects of high quality collaboration and assess the level ofsophistication that their team exhibited around these aspects. To identify important processes, we used the existingliterature to create a list of important behavioral markers, of which joint idea-building is one (Borge et al., 2015).We then had to unpack each of these markers into a scale of less and more sophisticated processes so that studentscould compare their existing processes to desired processes. Though we managed to reach a high level of interrater reliability with our assessment rubric, we still faced conceptual challenges in determining what counts as anidea-building move. Two questions that were difficult for us to resolve were: (1) should an idea-building episodeinclude moves associated with knowledge negotiation, such as challenges to an idea and supports for the idea inresponse to the challenges; and (2) should questions posed by learners be counted as an idea-building move?We acknowledge that more sophisticated collective cognition requires both idea-building (as part ofinformation synthesis) and knowledge negotiation to co-occur (Stahl, 2006). However, we perceive idea-buildingas distinct from knowledge negotiation (Borge et al., 2015). Information synthesis is a collective, cognitive activitywhereby group members work to share, collect, make sense of, and connect individual information into a cohesive,collective whole. On the other hand, knowledge negotiation is a collective cognitive activity associated withdecision-making where alternative ideas are presented, acknowledged, and evaluated by the group (Borge et al.,2015).Though these two collective cognitive activities can overlap in time, we argue that they should beevaluated independently from each other because it is important to examine the extent to which an idea isunderstood and developed by a team before the team begins to make decisions about it. We support this positionwith existing findings related to group processes: that how teams synthesize ideas from multiple members canaffect the quality of collective decision-making processes (Borge & Carroll, 2014), that in the presence ofcompeting ideas, teams have a tendency to reject or ignore ideas, even crucial ideas, because they fail to monitorand regulate activity to ensure that ideas are explored (Barron, 2003), that diverse ideas are essential to innovativethinking but only to the extent that these ideas are considered, explored, and synthesized by the group (West,2007), and that tendencies to pick ideas without the development of shared understanding and equal considerationcan lead to problems with interpretation, decision-making, learning, and performance outcomes (Barron, 2003;Borge & Carroll, 2014; Carroll, Borge, & Shih, 2013). Thus, while not every idea may need to be built upon,given what we know about group processes, it is likely that higher quality collaborative processes ensue whenthere is evidence that groups take time to extend and explore at least some ideas before moving on to a competingidea. Such behaviors may be indicative of a group’s desire to understand alternative perspectives rather thansimply debate them; this is a quality Stahl (2006) argues as necessary for high quality collaboration. Followingthis logic, we maintain that a question can act as a prompt to extend an idea-building episode (Berkowitz & Gibbs,1983), thus it could count as an idea-building move. However, questions that center on introducing a competingidea, i.e., “Yes, but have you considered that idea X might be better?”, are conceptualized as knowledgenegotiation moves and therefore not counted as idea-building.In our existing assessment rubric, the sophistication of a team’s joint idea-building activity is evaluatedon a score of “1” (least sophisticated) to “5” (most sophisticated) (Borge et al., 2015). The scores are based ontwo markers: frequency of idea-building moves and the pervasiveness of extended idea-building moves.Frequency of idea-building moves is categorized as: extended idea-building (five or more idea-building movesfollowing an initial idea for a discussion topic), limited idea-building (one to four idea-building moves followingan initial idea), and no idea-building (no idea-building moves following an initial idea). A score of “5” means adiscussion includes at least two episodes of extended idea-building; a score of “4” means a discussion has oneepisode of extended idea-building; a score of “3” includes at least two episodes of limited idea-building; a scoreof “2” includes one episode of limited idea-building; a score of “1” means no idea-building occurred in thediscussion. Criteria for the number of idea-building moves (measure for frequency of idea-building moves) andnumber of episodes (measure for pervasiveness of extended idea-building moves) were determined based on theinstructor’s estimate of reasonable expectations from an average performing team (assumed to receive a score ofICLS 2016 Proceedings267© ISLS“3”) and a high performing group (assumed to receive a score of “5”). For example, each member in a team oftwo or three members can reasonably be expected to contribute one or two idea-building moves, thus defining thecriteria for an average performing team.Many colleagues have rightly criticized our current approach, as we too recognize it may not be valid.However, our current measures provide us with a starting point from which to iteratively develop better ways ofhelping students and instructors make sense of and improve collective thinking processes. To iteratively improvethe rubric, we are interested in empirically determining the abovementioned criteria based on empirical evidencefrom our existing data, which is the basis for the study reported in this paper.Study aim and research questionsThe broader aim of this study is to contribute to the existing literature by unpacking what joint idea-buildingactivity looks like and providing descriptions of more and less sophisticated forms of this activity. Our findingswill also be used to inform the criteria used to assess joint idea-building in our existing assessment rubric. Ouraims lead to the research question: to what extent is the definition of sophistication levels of joint idea-buildingactivity in our existing rubric aligned with empirical findings from sampled online group discussions?MethodsContext and data sampleThe study reported in this paper is the third iteration of a broader study by Borge et al. (2015). Participants in ourstudy are students of a 16-week university level introductory online course on information sciences andtechnology. Students were introduced to concepts and research in disciplines including security and risk analysis,human computer interaction, emerging technologies, effects of technology on society, and informatics. Groupdiscussion activities contributed 25% of students’ total grade, as development of collaborative reasoning practiceswas a course learning outcome. Students were required to complete five online group discussion activitiesthroughout the course. Each activity required students to individually complete a pre-discussion activity afterreviewing the discussion session materials (e.g., chapters from the course required text or supplementarymaterials). They then participated in an online group discussion with assigned team members (in dyads or triads)on a professional collaborative workspace with chat and document sharing features. Each discussion lastedapproximately 45 minutes. The discussions were assessed using our existing rubric for collaborative discussionquality, which is based on the core capacities of information synthesis and knowledge negotiation; joint ideabuilding is an aspect of information synthesis (Borge et al., 2015).The pre-discussion activity is designed to deepen students’ thinking about their required course readings.The activity consists five questions labeled as topics in our analysis: (Topic A) what part or concept in the readingwas most difficult to understand and why?; (Topic B) what is one interesting argument about a concept in thereading made by the author and its implications for individuals and society?; (Topic C) what is the most importantconcept you have read and why?; (Topic D) which concepts discussed in the reading are most likely to impactyour work, and how can they be applied to your current or future job?; and (Topic E) if you could ask the authorone question regarding the reading, what would it be?. Students could decide the reading questions they wish todiscuss during their online group discussions. They could also discuss other related topics of interest.For our analysis, we sampled six teams’ online discussions from discussion session three. Thesediscussions take the form of time-stamped posts identified by individual users who made the post. We selectedsession three because this session has the largest variation in idea-building scores, based on our existing rubric.This ensures we have examples of teams with varied performance and more likely varied patterns of idea-building.The six teams were sampled based on their joint idea-building score on the existing rubric: Teams 4 and 14 scored“3”; Teams 11 and 13 scored “4”; Teams 2 and 12 scored “5”. Furthermore, the sample comprises a mix of dyadsand triads: Teams 2, 13 and 14 are dyads; Teams 4, 11, and 12 are triads.Data analysisIdentifying idea-building episodes and movesIn establishing our existing assessment rubric, the research team held extensive discussions to reach agreementon how to determine the “boundary” of an idea-building episode and what is an appropriate unit of analysis foran idea-building move. The team agreed that idea-building episodes exist within the discussion of a topic. A topicis typically introduced to the team discussion by a member stating or suggesting which reading question to discuss(e.g., “Let’s start with question two.” or “Shall we go with question three first?” A topic ends when a memberpushes for the team to discuss another question (e.g., “let’s move on to the next question”) or a new topic isICLS 2016 Proceedings268© ISLSintroduced (e.g., “Ok, question four”). Several idea-building episodes may exist within a topic. An idea-buildingepisode begins when a member puts forward an initial idea within a topic that is a response to the reading question.For example, a member’s response “The most difficult concept for me was the task-artifact cycle” is an initialidea to Topic A (what part or concept in the reading was most difficult to understand and why?). A differentresponse to Topic A, “I found the messy desktop part most difficult” signals the start of a different idea-buildingepisode within Topic A. An idea-building episode ends when the idea ceases to be built and a new topic isintroduced. Exceptions are made when a subsequent post within the boundary of the new topic builds on an ideain a previous topic due to a time lag in making the posts (indicated by identical time-stamps or short timedifferences between time-stamps). Following the convention of conversation analysis, we define the unit ofanalysis as a turn made by a student (Sacks, Schegloff, & Jefferson, 1974). A student’s turn begins when shemakes a new post and ends when another student makes a post. Thus, an idea-building move can comprise a singlepost or multiple concurrent posts by the same student.Coding for idea-building movesWe coded for four main moves in our sampled discussion sessions. Initiating a topic (Topic) refers to a movewhere a main discussion topic is introduced, typically by stating a reading question or any question of interest.Putting forward an initial idea (Idea) is a move where an idea is put forward by a member in response to a TopicInitial ideas are not counted as idea-building moves, but they initiate the opportunity for idea-building. Ideabuilding moves begin when the team adds on to an initial idea. These moves are described as follows. Adding toan idea (Add) is when a member adds to an existing idea or parts of it by elaborating or extending it. Questioning(Qn) refers to posing a question in relation to a previously introduced idea to seek further ideas or information. Itexcludes clarifications that do not seek to elicit further ideas. If a move includes both adding to an idea andquestioning, the code is assigned based on the more significant move. For instance, if a student gives an examplerelated to a previous idea (Add) and asks the team for their thoughts about the example (Qn), the move is codedas Qn since his question is potentially more significant in extending the idea-building episode. We identify suchmoves using a micro-coding framework with substantial inter-rater reliability, kappa = 0.74, p < 0.001.In addition, we wanted to identify when ideas evolve during an episode, as students may build on ideasrelated to an initial idea rather than focusing on the initial idea itself. Thus, branch ideas are indicated in thefollowing situations: (1) ideas based off a previous idea, Idea 1, are labeled as Idea 1.1, Idea 1.2, etc.; and (2)initial responses to a question, Qn1 that seeks further ideas about Idea 1, are labeled as Idea 1.1., Idea 1.2, etc.Labeling for further branching of ideas is possible (Idea 1.1.1, Idea 1.1.2, etc.). Branch ideas count towards ideabuilding moves of the main, initial idea. For example, Idea 1.1 and Idea 1.2 are both part of idea-building movesfor Idea 1.The six sampled discussion sessions were coded independently by the first author and a studentresearcher. Both coders have experience evaluating the teams using the existing assessment rubric, and haveparticipated in the aforementioned research team discussions about the idea-building construct. The coders met todiscuss their independent codes to resolve any differences in the codes and arrive at a consensus set of codes,including where significant deviation from the main idea occurs and the labels of branch ideas should be used.Statistical analysis of idea-building episodesTo answer our research question, we turn to the relevant descriptive statistics of the idea-building episodes thatserve as measures of the two markers for joint idea-building activity in our existing rubric. Specifically, we areinterested in the average number of idea-building moves per episode, which defines the categories for extendedidea-building and limited idea-building, and serves as a measure for the frequency of idea-building moves. Anidea-building episode comprises an initial idea and the additional idea-building moves following it. If an initialidea is not followed by other idea-building moves, then no idea-building occurs and it is not an idea-buildingepisode. Non idea-building episodes were excluded from the statistics since we are interested in the averagenumber of idea-building moves among episodes demonstrating idea-building activity. We also want to find theaverage number of episodes meeting the criteria for extended idea-building (to define a score of “5”) and forlimited idea-building (to define a score of “3”), which is a measure for the pervasiveness of extended idea-buildingmoves. These statistics will be compared with the criteria for the sophistication levels of joint idea-buildingactivity in our existing rubric.Visualizations of idea-building episodesA free online mind mapping tool WiseMapping Version 3.0.2 (2014) was used to generate visual representationsof the idea-building episodes based on each group’s discussion topics. Individual idea-building moves (Add, Qn,ICLS 2016 Proceedings269© ISLSor branch ideas) are represented as blocks connected to an initial idea (Idea). All initial ideas are connected to atopic (Topic). The colors of the blocks represent individual students who made the move.FindingsDescriptive statistics of idea-building episodesAmong the six sampled group discussions, a total of 25 topics were discussed (excluding the discussion of onetopic which only comprises knowledge negotiation activity). These topics resulted in a total of 55 initial ideas, 35of which developed into idea-building episodes. Eighteen initial ideas were not built upon, while two ideas ledonly to knowledge negotiation activity. On average, each team discussed 4.2 topics and put forward 9.2 initialideas, which resulted in 5.8 idea-building episodes. The average number of moves per episode is 4.2 (standarddeviation = 3.1). We propose an episode with above average number of moves i.e. five or more moves can beconsidered an extended idea-building episode. The differences between extended idea-building, limited ideabuilding, and no idea-building episodes based on the frequency of idea-building moves are visually representedin Table 1 using examples from the sampled discussions.Table 1: Definitions and visualizations of idea-building episodes based on frequency of idea-building moves.Discussion of Topic D includes three initial ideas, each with different frequencies of idea-building moves. Idea 3demonstrates an extended idea-building episode, where an initial idea is built extensively over seven moves,including Qn and Add moves, and branch ideas (Idea 3.1 and Idea 3.2). Idea 1 shows a limited idea-buildingepisode, where an initial idea is built over two Add moves. Idea 2 is an example of no idea-building.Frequency ofIdea-buildingMovesDescriptionExtended ideabuilding(Idea 3)An initial idea isbuilt over anextended numberof moves (five ormore moves)An initial idea isbuilt over severalmoves (one to fourmoves).Limited ideabuilding(Idea 1)No ideabuilding(Idea 2)Visualization of Idea-building Episodes in a TopicNote: Each block represents an idea-building move. Blocks of thesame color represent moves made by the same member.Initial ideas areshared but notbuilt.To exemplify the difference between an extended idea-building episode and a limited idea-buildingepisode, shown in the visualization in Table 1, we present an excerpt from Team 11’s discussion on Topic D aboutthe impact of a concept on the members’ work.MemberMessage ContentChloe:Which concepts discussed in the reading are mostlikely to impact your work? How can you apply theconcept in your current or future job?Topic DChloe:The concept that I believe has already impacted myjob is HCI in general. Especially the Task-Artifactconcept. When I click on something on my desktop Iexpect it to open said object, just as I would expectand elevator door to open when I push the elevatorbutton.Idea 1ICLS 2016 ProceedingsMove270© ISLSDaniel:The evolution of HCI has a huge impact on my work.It might not fundamentally change what I do everyday, but how I do it and the timeliness of it are bothimpacted by it.Idea 2Daniel:I agree Chloe. How can any work not be impacted byHCI is some way?Idea 1: AddChloe:I honestly cannot say I have an answer to thatquestion. I admit my job would suck without it andpretty much all everyday activities that involvetechnology.Idea 1: AddBrandon:For me the area the concept that will impact me is theutilization of HCI to assist in social media & networkanalysisChloe:Elaborate on this for me if you can Brandon.Idea 3: QnBrandon:I think as I observed through every lesson there needsto be an even balance between technology and theusers, hence smart-watches allow an excellentbalance.Idea 3: AddIdea 3Chloe:I'm not sold on smartwatches at all.Idea 3.1Daniel:I love my smartwatch.Idea 3.2Chloe:Mostly because they don't provide me with anythingthat my other devices cannot. However it has beenrumored that Apple is working on developing anApple car. If the Apple watch could be used as remotestart then I could see a need. In fact if any watch hadthat option I could see a need.Idea 3.1: AddDaniel:It allows me to "check" my phone without me thenfinding myself in a rabbit hole.Idea 3.2: AddBrandon:I think HCI will cater [to] certain preferences andobservations that the desired user wants and assists intheir needs for social media.Idea 3: AddOf the three ideas presented by the members, Idea 3 is the one the team builds upon most extensivelythrough a variety of moves. The team members request for further elaboration of the idea (Idea 3: Qn), providemore details and connect it to a real-life example (Idea 3: Add), share their personal opinions (Idea 3.1 and Idea3.2), provide rationale for their opinions (Idea 3.1: Add and Idea 3.2: Add), then return to the original idea bysynthesizing their perspectives (Idea 3: Add). In contrast, Idea 1 is extended to a limited extent by membersgeneralizing the idea through a rhetorical question (Daniel’s Idea 1: Add move) and extending the idea to otheraspects of life (Chloe’s Idea 1: Add move).To determine the number of extended idea-building episodes (based on our proposed five or more ideabuilding turns) we can expect from a team demonstrating fairly sophisticated joint idea-building activity (i.e.teams with score of “4” or “5”), we consider the average number of extended idea-building episodes among thesampled discussions, which is 1.8 episodes. In contrast, the average number of limited idea-building episodes(based on our proposed one to four idea-building turns) is 4.0 episodes. Hence, we suggest that sophisticated jointidea-building activity (score of “5”) comprises at least three extended idea-building episodes (higher than theaverage number of extended idea-building episodes), that is, five or more idea-building moves in at least threeepisodes. An average level of sophistication in joint idea-building activity (score of “3”) comprises at least fourlimited idea-building episodes, that is, one to four idea-building moves in at least four episodes.ICLS 2016 Proceedings271© ISLSDiscussionOur group is working to develop concrete ways of evaluating collaborative activity in order to help studentsdevelop more sophisticated collective thinking processes. We also want to find ways to articulate learning theoryand empirical findings into usable learning objects, such as assessments, that students and instructors can use toguide their socio-metacognitive development. This poses challenges for unpacking abstract constructs such asjoint idea-building. Our existing rubric served as a starting point to evaluate joint idea-building, but we wanted todraw on real student collaborative activity to further inform our conceptualizations. Specifically, we wanted tocompare the logically reasoned quantification of markers we currently use to determine sophistication of jointidea-building to actual quantification of those markers in real student activity.Based on our findings, we observe that the criteria for number of moves defining an extended ideabuilding episode and a limited idea-building episode in our existing rubric concur with the empirical findings fromthe sampled discussions. However, the number of idea-building episodes expected for the levels in the existingrubric is lower than what students actually produced in the sampled discussions. Hence, we propose the followingrevisions to the criteria for joint idea-building scores in our existing rubric (revisions in bold): A score of “5”means a discussion includes at least three episodes of extended idea-building (five or more idea-building moves);a score of “4” means a discussion has one to two episodes of extended idea-building; a score of “3” includes atleast four episodes of limited idea-building (one to four idea-building moves); a score of “2” includes one tothree episodes of limited idea-building; a score of “1” means no idea-building occurred in the discussion.Our work is always limited by the number of teams that can be evaluated. We recognize that the sixteams we microanalyzed may not be representative of the population as a whole. However, we believe that thedepth of our analysis can contribute to new ways of thinking about communication patterns and can inform largerquantitative studies, especially those working to develop automated methods for assessing collaboration quality.Our findings serve as anchors for future work, evaluation, and discussion of collaboration quality.Conclusions and implicationsIn this paper, we conceptualized the notion of joint idea-building as being defined by two markers, frequency ofidea-building moves and the pervasiveness of extended idea-building moves. Our findings from actual studentonline discussions provided evidence to inform modifications to our existing rubric for joint idea-building, andalso suggest directions for future work.In view of the proposed modifications to our existing rubric, a follow-up study is necessary to look athow the revised rubric impacts the sophistication of joint idea-building activity in future online group discussions.We are mindful about how the revision may affect students’ behavior, especially since our current instructionalpractice includes providing students with the same rubric as a means to help them evaluate and reflect on theirown processes. While we want to modify students’ cognitive behavior towards more sophisticated joint ideabuilding, we also want to avoid students gaming the system by staging their discussions to achieve the maximumscore with minimum performance, such as stopping their idea-building activity once the required number of ideabuilding moves are met as per the requirements stipulated in the rubric.Our initial analysis of students’ existing idea-building episodes suggest the existence of other potentiallyimportant markers, such as the extent to which members engage in multiple turn-taking to build on an idea, andthe number of initial ideas put forward for a discussion topic. To improve the validity of our rubric, future workwill examine the extent to which our existing markers sufficiently capture the full range of idea-buildingsophistication, and whether other markers should be included. There is also a need for future work to qualitativelyanalyze the products of joint idea-building activity and evaluate the depth and richness of the ideas generated andsynthesized, so as to determine whether the markers we have identified are related to the sophistication of theproducts of joint idea-building activity.In order to support students to engage in more sophisticated joint idea-building activity, there is a needfor future work to investigate the conditions that lead to more sophisticated idea-building activity. One possiblecondition is the type of discussion activity questions. Are there some questions that lend themselves to moresophisticated idea-building than others? Another possible condition is strategies for managing the discussions.Will focusing on a few topics instead of discussing all topics lead to more sophisticated idea-building? What aboutdiscussing one initial idea for a topic before moving on to another initial idea versus putting forward all initialideas then selecting one to build on? Understanding of such conditions can help instructors make informedmodifications to the discussion activity to promote more sophisticated joint idea-building activity amongcollaborative teams.Through sustained work in these highlighted directions, we will continue to unpack the notion of ideabuilding, refine our existing conceptualization, and revise the cognitive tools we provide in our CSCL technologiesto articulate theory as a means to help students develop socio-metacognitive expertise.ICLS 2016 Proceedings272© ISLSReferencesBarron, B. (2003). When smart groups fail. Journal of the Learning Sciences, 12(3), 307–359.Berkowitz, M. W., & Gibbs, J. C. (1983). Measuring the developmental features of moral discussion. MerrillPalmer Quarterly, 29(4), 399–410.Borge, M., & Carroll, J. M. (2014). Verbal Equity, Cognitive Specialization, and Performance. In Proceedings ofthe 18th International Conference on Supporting Group Work - GROUP (pp. 215–225).Borge, M., Ong, Y., & Rosé, C. (2015). Design models to Support the Development of High QualityCollaborative Reasoning in Online Settings. To be included in the proceedings of the InternationalConference of Computer Supported Collaborative Learning (CSCL) 2015.Carroll, J. M., Borge, M., & Shih, S.-I. (2013). Cognitive artifacts as a window on design. Journal of VisualLanguages & Computing, 24(4), 248–261.Damon, W., & Phelps, E. (1989). Critical distinctions among three approaches to peer education. InternationalJournal of Educational Research, 13(1), 9–19.Joshi, M., & Rosé, C. (2007). Using transactivity in conversation for summarization of educational dialogue. InProceedings of the Speech and Language Technology in Education (SLaTE) Workshop 2007 (pp. 53–56).Farmington, PA. Retrieved from http://www.isca-speech.org/archive_open/slate_2007/sle7_053.htmlO’Donnell, A. M., & Hmelo-Silver, C. E. (2013). What is collaborative learning?: An overview. In C. E. HmeloSilver, C. A. Chinn, C. K. K. Chan, & A. M. O’Donnell (Eds.), The international handbook of collaborativelearning (pp. 1–16). New York, NY: Routledge.Sacks, H., Schegloff, E. A., & Jefferson, G. (1974). A simplest systematics for the organization of turn-taking forconversation. Language, 50(4), 696–735.Scardamalia, M., & Bereiter, C. (2003). Knowledge building. In Encyclopedia of Education. (2nd ed., pp. 1370–1373). Macmillan Reference.Scardamalia, M., & Bereiter, C. (2006). Knowledge building: Theory, pedagogy, and technology. In R. K. Sawyer(Ed.), The cambridge handbook of the learning sciences (pp. 97–115). New York: Cambridge UniversityPress.Stahl, G. (2006). Group cognition: Computer support for building collaborative knowledge. Cambridge, MA:MIT Press.Teasley, S. D. (1997). Talking about reasoning: How important is the peer in peer collaboration? In L. B. Resnick,R. Salijo, C. Pontecorvo, & B. Burge (Eds.), Discourse, tools, and reasoning: Essays on situated cognition(pp. 361–383). Berlin: Springer.Webb, N., & Palincsar, A. (1996). Group processes in the classroom. In D. C. Berliner & R. C. Calfee (Eds.),Handbook of Educational Psychology (3rd ed., pp. 841– 873). New York, NY: Macmillan.Weinberger, A., & Fischer, F. (2006). A framework to analyze argumentative knowledge construction incomputer-supported collaborative learning. Computers and Education, 46(1), 71–95.West, G. P. (2007). Collective cognition: When entrepreneurial teams, not individuals, make decisions.Entrepreneurship: Theory and Practice, 31(1), 77–102.WiseMapping. (2014). Retrieved from https://app.wisemapping.com/c/maps/Zhang, J., Scardamalia, M., Reeve, R., & Messina, R. (2009). Designs for collective cognitive responsiiblity inknowledge building communities. Journal of the Learning Sciences, 18, 7–44.AcknowledgmentsWe would like to thank our undergraduate research assistant, Emily Hanson, for her contributions to this project,as well as other members of the research team for their constructive feedback on this paper. We would also liketo thank the participating students for allowing us to examine their interactions. This project was supported by theNational Science Foundation (IIS-1319445).ICLS 2016 Proceedings273© ISLS