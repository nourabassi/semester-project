‘Re-mediating’ LearningKemi Jona, Lauren Penney, and Reed Stevenskjona@northwestern.edu, Lauren.Penney@u.northwestern.edu, Reed-Stevens@northwestern.eduNorthwestern University, School of Education and Social PolicyAbstract: Building on our own and others’ research about productive features of non-schoollearning environments, we describe a new experimental infrastructure for the organization andmediation of learning called FUSE. Activity in FUSE is mediated by a website and supportedby an adult facilitator (typically a teacher, librarian, or other youth educator). Based onemerging research from the more than 4000 young people that have participated in FUSE in30+ schools, libraries, and summer camps in the Chicago area, we have begun to characterizehow the affordances of the FUSE website are supporting a shift in the material organization oflearning in the in-school classrooms in which it is implemented. We describe how FUSE ‘remediates’ learning by providing individualized learning pathways, dynamic arrangements forlearning, alternative forms of ‘assessment’, new roles for the teacher, and a rethinking of howcurriculum materials are produced.Keywords: technology, interest-driven learning, design, STEM, STEAMIntroductionIn this paper we describe a new experimental infrastructure (cf. Stevens, 2007) for the organization andmediation of learning. This infrastructure provides a coherent system of learning, ‘teaching’, and assessmentthat leaves behind the ways in which current education systems of teaching, testing, and curricula discourageinterest, foster maladaptive motivational patterns (Dweck, 1986), and sort young people out of further academicpursuits (particularly more challenging scientific and technical fields – Seymour & Hewitt, 1997; Ames &Archer, 1988; Margolis & Fisher, 2002). First, we review some of the intrinsic challenges to transformingschool-based learning practices with technology. We then describe how our new infrastructure, called FUSE,‘re-mediates’ learning by providing individualized learning pathways, alternative forms of ‘assessment’, newroles for the teacher, and a rethinking of how curriculum materials are produced.Intrinsic barriers to transforming the organization of learning with technologyThe material organization of learning in traditional Western schooling has remained largely unchanged, despitenumerous attempts at reform (Becker, 1972; Varenne & McDermott, 1998; Cuban & Tyack, 1995).Technologies that have been introduced into classrooms have largely acted to reinforce rather than transformtraditional structures and routines. A technology that is illustrative of the kind used widely in schools tomaintain rather than transform the material organization of learning is the electronic whiteboard. Nominallyintended to provide the teacher with an interactive computer display at the front of the room, this technology hasfor the most part simply provided teachers with an electronic method for displaying material to the whole class,replacing previous technologies of the overhead projector, chalkboard, and whiteboard. The electronicwhiteboard changed neither the roles of teacher and student nor the organization of learning in the classroom.Introducing technologies such as laptops and (more recently) tablets into schools has been heralded byboth vendors and school leaders as a vehicle for transforming the traditional organization of classroom learning.Yet these technologies have largely failed to dislodge the teacher from directing learning from the front of theclassroom; failed to break students free from lockstep progression through static curricula irrespective of actuallearning outcomes; and, ultimately, failed to shift the initiative and ownership of learning from teacher tostudents. A promising exception are new blended learning models (Horn & Staker, 2014).Collins & Halverson (2009, 2010) document the long history of innovative technologies that havefailed to dislodge the industrial age structure of mass education. They identify a number of tensions betweenentrenched practices of schooling and the affordances provided by technology. These include:• Uniform learning vs. customization. Current educational practices are based on a “mass productionnotion of uniform learning.” These practices include sorting students into age-based (rather thanexpertise-based) levels and administering common assessments. Even though these assessments arebased on a notion that all students should learn the same thing in the same period of time, the systemCSCL 2015 Proceedings348© ISLS••permits students to progress from one grade level to the next on the basis of only the most minimalmastery (i.e., anything but a failing grade allows one to move to the next class or grade).Teacher as expert vs. diverse knowledge sources. Despite widespread acknowledgement that we arenow in an era of exploding knowledge production and instantaneous access, modern schooling is stilllargely based on the concept that knowledge is fixed and that a teacher’s primary role is to present whatis known to his or her students. This notion places teachers in the once-reasonable but now impracticalposition of all-knowing experts whose job is to pass on their expertise to students (who can now lookup anything on their mobile phones faster than a teacher can respond).Standardized assessment vs. specialization. The high stakes assessments currently in dominant userequire that every student learn the same things at the same time, yet technology now affordsalternative forms of performance-based assessments such as video games and simulations (Hilton &Honey, 2011). Reputation-based measures of expertise grounded in communities of interest or practiceare now typical in affinity groups including, for example, open source coding communities.The traditional organization of classroom learning has been ossified and reinforced by layers ofbureaucratic and administrative constraints. It is practically impossible for individual teachers to significantlychange the material organization of learning in their classrooms, even if many secretly wish to and recognizehow poorly the current system serves their students. Could a thoughtfully designed program, supported bytechnology, provide the requisite infrastructure to help teachers make a shift that many have long sought?FUSE StudiosWe are beginning to see evidence that such a shift is indeed possible. Building on our own and others’ researchabout productive features of non-school learning environments (Bevan, Bell, Stevens, & Razfar, 2012; NRC,2009; Barron, 2006; Stevens, 2000; Stevens, Satwicz, & McCarthy, 2008; Davis & Fox, 1999; Ito et al, 2013;Gee, 2007a, 2007b; Squire, 2003, 2011), we have created FUSE—a learning environment organized around aset of challenge sequences that ‘level up’ the way video games do. Some of our challenge sequences aresoftware-based, including 3D design, digital music editing, app development, etc. For others that requirephysical materials, inexpensive, pre-packaged kits are provided (e.g., LEDs, breadboards, e-textiles, etc.).The organization of learning in FUSE is mediated by the FUSE website and supported by an adultfacilitator (typically a teacher, librarian, or other youth educator). Currently, more than 4000 young people haveparticipated in FUSE Studios, exploring over 20 challenge sequences in 30+ schools, libraries, and summercamps in the Chicago area. Based on these experiences, we have begun to characterize how the affordances ofthe FUSE website are supporting a shift in the material organization of learning in those in-school classrooms inwhich it is implemented. (For an overview of FUSE, see http://www.fusestudio.net/program-design.)Customization through choiceYouth participants have significant choice in FUSE Studios, a dramatic difference from their experiences inschooling. Participants choose whether to work alone or with others; they choose which challenge sequencesthey will explore; and they choose how long to work on a challenge sequence and when to move to another.Figure 1. Left: An in-school FUSE Studio (color boxes indicate which challenges are being pursued); Right:Challenge popularity across the school year (each row is a different challenge, darker color and larger sizeindicate more participants).Figures 1 & 2 depict the various arrangements and groupings for learning that emerge organicallywithin a typical in-school FUSE Studio. Upon entering the room, students log on to their account on the FUSECSCL 2015 Proceedings349© ISLSwebsite and select a challenge to work on – either continuing a previously started challenge or starting a newone. Often the teacher need say nothing to his or her students – they immediately transition to productiveengagement.In order to provide an interest-driven, free choice infrastructure for learning, by definition there mustbe a wide range of challenges available for participants to choose from (see Figure 1 right, and Figure 2). Thewebsite scaffolds participant engagement and provides a participant’s first layer of support while engaged with achallenge. Each challenge in a sequence has its own resource page consisting of short “how to” videos with tipson getting started, and answers to the most frequently asked questions. Participants each have their own uniquelogin, allowing the website to track their progression through different challenge sequences. Participants canupload files, pictures, videos, and other artifacts to their online account to “save” multiple iterations of theirwork-in-progress. Completing levels unlocks higher levels in the same challenge sequence; just like in videogames, participants must finish level one before moving on to level two. To complete a challenge level theymust upload a final “completion artifact” (the self-documentation of level completion is discussed further in the‘assessment’ section below). Similar to a Facebook feed, our site provides information about which challengespeers are engaged in and allows for sharing of completion artifacts. Clicking on a fellow participant’s namehighlights their profile showing what other challenges they have completed and thus the areas with which theymight be able to help another participant.Figure 2. Examples of the diversity of material organizations for learning that occur in FUSE Studios.Participants dynamically arrange and rearrange collaborative groupings and individual activity with bothmaterial and online resources. Challenges illustrated here include (clockwise from upper left): Dream Home,Laser Defender, LED Lights, and Selfie Sticker.The FUSE website structures and supports a participant-driven organization of learning. Eachparticipant creates a customized rather than uniform learning experience by choosing the challenges that interesthim or her, by working individually or with one or more peers, and by stopping and restarting challengesequences at will. By indicating the leveling up progression for each challenge sequence, the website alsoprovides clearly demarcated pathways to deepening expertise that each participant can choose to follow basedon their own interest in doing so.The FUSE web site logs participant activity and completed challenges allowing us to track whichchallenges participants are choosing and not choosing, and what levels they are completing or abandoning. FromCSCL 2015 Proceedings350© ISLSthis web data, we generate ‘activity maps’ (Figure 3, below). Our analysis of these activity maps has revealed anumber of distinct patterns of participant engagement. For example, the participant whose activity is representedon the left in Figure 3 simultaneously worked on a variety of challenge sequences before pursuing Selfie Stickerexclusively (green dots, top right) at the end of the school year (the time period depicted in the map). In contrast,the participant whose activity is represented on the right in Figure 3 shows a much more focused pattern ofengagement. This participant sticks with one challenge sequence at a time, generally pursuing that sequencethrough the final level. These are just two of a growing set of identifiable engagement patterns we are observingin the data. The design of FUSE, supported by the website, not only facilitates this diversity in the organizationof learning, but also illustrates the significant variation in preferred approaches to learning that a thoughtfullydesigned and technology supported program can enable. These activity maps stand in stark contrast to theteacher-controlled, uniform pace and progression of lessons that is the hallmark of traditional schooling.Figure 3. Activity maps from two 6th grade participants in the same classroom across one school year. Each rowlists a different challenge sequence (also represented with different color dots), while each column represents adate that the studio was in session. Larger dot size denotes leveling up to more difficult levels in each sequence.Dynamic and flexible learning arrangementsPrior work (Stevens, Satwicz, & McCarthy, 2008) and our ongoing observations of FUSE have providedevidence that when youth participants are in the room together, they will be drawn to get involved with eachother’s challenge work. The differentiated levels of participation with particular challenge sequences that evolvenaturally under this model over time multiply the possible sources of ideas, hints, help, and feedback in theroom beyond those provided by teachers or other mentors. FUSE builds on Cole’s (2009) work on the FifthDimension, a long-standing, successful after-school program, where peer-to-peer mentoring is ubiquitous.There, as in FUSE Studios, peers have differentiated experience; some are oldtimers and some are newcomers(cf. Lave & Wenger, 1991). This stands in stark juxtaposition to traditional schooling where everyone learns thesame thing at the same time and pace.The FUSE program design, with support from the FUSE website, enables more dynamic and flexiblearrangements of participants in the room—arrangements which are mediated by the participants themselves andnot the teacher (a few of these many arrangements are illustrated in Figures 1 & 2 above). One particularexample in a 5th grade classroom highlights the nature of these arrangements and how they evolve organicallybased on differentiated experience and expertise. Our Solar Roller challenge sequence invites participants tobuild a solar-powered car that can travel a target distance with and without a light source using a provided kit ofmaterials including gears, photovoltaic panels, capacitors, etc. When this challenge sequence was launchedpartway through the school year, it attracted the interest of many participants who wanted to try it.Unfortunately, because only one kit of materials was available in each classroom, participation was reduced toone “user” at a time. In one classroom, we observed several boys agreeing to collaborate as a group so theycould all try it together (Figure 4). At first, all boys tried designing a vehicle independently, however, Arjunsoon took leadership and combined the ideas into one vehicle. All of them suggested ideas for building theroller, and when testing time came, they each took ownership for different aspects of the testing. For example,John had a fancy watch and used it to track the roller’s time to reach the goal distance, until they found astopwatch and he started using it instead. Arjun seemed to have the most success with the light used to make thevehicle move, so he took that responsibility. Ian noticed the light cord kept getting stuck on the table, causingthe light to stop powering their vehicle, so he took responsibility for keeping the cord clear of obstacles (seeCSCL 2015 Proceedings351© ISLSFigure 4). As their design and testing progressed, they all found meaningful ways to contribute to the group.This group even pooled their money, purchased a similar kit of materials from another website, and brought it toschool to use in additional experimentation and development that went beyond the challenge sequence on theFUSE website. This group worked on this challenge together multiple times over the course of three months.While there were five members of this group, not all members participated at all times; occasionally one andoften all of them would take a break from this challenge to work on a different challenge.This example highlights one of the many ways participants dynamically and flexibly positionedthemselves in productive learning arrangements. This group worked cooperatively on their car design, whileeach boy filled a different role during testing that helped their team move efficiently towards their goal. Theseroles emerged dynamically as they worked together and developed expertise in different aspects of their vehicletesting. They themselves decided when to pursue this challenge and when to work on a different challengesequence. Other arrangements of independent and collaborative work are shown in Figures 1 and 2.Figure 4. A dynamic grouping of participants testing out their Solar Roller car.Alternative forms of ‘assessment’Another difference from school is that FUSE participants are never graded and they self-document theircompletion of challenges, which unlocks subsequent challenge levels in a sequence. Our approach to assessmentseeks to balance the need to recognize participants’ achievements in a fair way (i.e. that they have been activeparticipants in completing a challenge) with the concern of not wanting students to fall back into the learnedhelplessness with respect to self-assessment and achievement recognition that is so common in schooling(Dweck, 1986). We accomplish this using a combination of careful challenge design and a documentation andendorsement process.Figure 5. Participants self-documenting success on a challenge (Just Bead It, left; Spaghetti Structures, right).Our alternative to standardized assessment involves designing challenges that have a clear criterion ofsuccess: a light either goes on or it doesn’t, a robot navigates to the finish line or not. We want a participant’ssuccess at achieving the challenge to be obvious both to the participant and to others in the room. Once aparticipant has succeeded at a challenge, they self-document their success by capturing and posting a photo orvideo of it on our site, or by uploading a digital artifact (3D design, mobile app code, etc.). The image on theCSCL 2015 Proceedings352© ISLSright in Figure 5 below shows a group of girls documenting their completion of a Spaghetti Structureschallenge. What is especially striking is that they are in the picture with their artifact-an indication of pride andownership in their work that is rarely seen when students complete a math worksheet.By shifting the ownership of ‘assessment’ away from the teacher and to the participants themselves, wemake a move toward investing participants in the quality of their own artifacts, towards a sense of pride ofaccomplishment. In fact, we have observed numerous occasions where participants have gone well beyond therequirements of completing a challenge and have become deeply invested in an artifact they are creating. Onegirl spent nearly 12 weeks refining the design of her earrings for the first level of the jewelry design challenge.She could have easily gone on to complete the remaining levels and numerous other challenge sequences in thattime, but she chose instead to invest in producing something that met her own standards and personal goals.Changing the role of the teacherIn FUSE, adults play a facilitative or coaching role, rather than delivering direct instruction and coordinatinggrading and assessment. This arrangement is driven by both theoretical and practical considerations. Practicallyspeaking, the diversity of challenges makes it unreasonable to expect a teacher or other facilitator to be expert atsuch a broad range of topics, tools, and skill sets. We have found, however, that this realization has beenliberating rather than intimidating for teachers. It seems that the very diversity of challenges has forced therecognition that a priori mastery of all challenges is impractical. Freed from the traditional role of being the allknowing expert, teachers have embraced their new role in FUSE as a coach and fellow problem-solver.Participants often become more expert at certain challenges or technologies (e.g. the 3D printer) than theteacher. We have observed numerous examples of the teacher referring questions to one or more of theparticipants who have become recognized in the room for their deeper expertise.Reconceptualizing production of ‘curriculum’Our approach to designing activities in the form of challenges and sequences is very different from traditionalcurricular design approaches (e.g., Wiggins & McTighe, 1998). The traditional approach begins with a set ofdisciplinary knowledge standards and then projects those standards into an organized set of curricular activitiesand formal assessment instruments and media; traditional curricula are built as standardized packages that aresignificantly monolithic, minimally revisable, expensive, and largely indifferent to individual student interests.Our design approach is fundamentally modular and evolutionary, in which challenges are dynamically created,positioned, repositioned, revised, and discarded in relation to other challenges that precede them that haveproven successful. The crucible of participant engagement, as measured by persistence in working to achievechallenges, has been and will remain central to our design approach. A similar logic organizes our approach todesigning distinct sequences; we design new sequences if we find we are not engaging a segment of the youthpopulation. For example, in response to a desire to better engage female participants, we introduced a jewelrydesign challenge using a 3D printer. This challenge sequence markedly increased the percentage of femaleparticipants engaging in 3D design challenges and remains among our most popular challenge sequences.We use the data from our website to determine which challenges appear to be sticking points forparticipants. How they are sticking points cannot be determined from the analytics; we use the analytics data toguide us to where to look in our field data (i.e., video recordings) to determine how and why challenges areproblematic. Challenges may be uninteresting, have instructions that are hard to follow, lack sufficientscaffolding, or increase the level of difficulty from prior challenges too quickly. We then revise challenges andsequences on the basis of what we find from field observations. For example, in our Robot Obstacle Coursesequence, we saw a drop-off in engagement after level 2. In-room observations and interviews revealed that theintroduction of a required sensor was too big a step between levels 2 and 3. In response, we inserted a new level3 so participants could understand how the sensor worked before requiring them to integrate the sensor into acomplex program (now moved to level 4). We regard this approach as a generative way to use a learninganalytics perspective without falling into the naïve view that analytics data alone can provide meaningful andspecific guidance for design iteration (Stevens, 2013). For that, we need to look ‘beyond the interface’ directlyat participant activity. The design based research (Design-Based Research Collective, 2003) approach weemploy is a significantly new one, in that iteration is rapid and informed in a very direct way by participantexperiences; iterations are initiated not by tests of sequestered disciplinary knowledge but by evidence ofongoing, interest-driven participation and engagement in challenge sequences.CSCL 2015 Proceedings353© ISLSConclusionsTo instantiate FUSE as an alternative infrastructure for learning, and to do so in a scalable manner, requires thatour website help mediate and structure participant activity and learning. This paper highlighted a number ofspecific functions served by the FUSE website in doing so:• Enabling personalized choices based on interests. Participants use the website to explore availablechallenge sequences and to select those that interest them.• Providing pathways to deeper expertise. Initial challenge levels are relatively easy, but increase indifficulty. The leveling up sequence is communicated by the website and provides participants with aclear indication of where they can go next if they choose.• Enabling dynamic arrangements for learning. FUSE enables more dynamic and flexiblearrangements of participants in the room—arrangements that are mediated by the participantsthemselves and not the teacher.• Redefining the role of the teacher. By shifting the primary content expertise and scaffolding burdenaway from the teacher, the website transforms his or her role to that of facilitator and guide, allowing afocus on process coaching and nurturing peer learning interactions.• Documenting learning outcomes. The website also shifts the ‘assessment’ burden away from theteacher and to the individual participants by having them upload evidence of their completedchallenges.• Supporting peer collaboration. By disseminating information about which challenges peers arecurrently working on or have already completed, the website facilitates a rich set of peer collaborationand helping behaviors.• Capturing user data to support iterative refinement of challenges. Analyzing patterns of participantengagement with the set of FUSE challenges provides an important lens into which challenges areappealing, to whom, and which may need refinement.• Providing a research platform. Finally, by mediating learning activity on the website, we are able tostudy young people’s interest-driven learning, problem solving, and collaboration activity at scale andwith a level of granularity that would not be otherwise possible.These shifts in the material organization of learning in school are often initially intimidating to theteachers who facilitate FUSE in their classrooms. However, with time, teachers begin to embrace these shiftsand, in interviews, have indicated that they are using some of these elements in their “regular” classes as well.One grade 7-8 science teacher commented:Students enter the program with little to no background knowledge and quickly startdeveloping skills in computer-aided design, electronics, and robotics. The enthusiasmstudents feel when they accomplish levels is contagious and because of the program'sthoughtful design, students feel safe and secure with continuing to try new challenges thatthey previously thought too difficult. Students are instantly hooked and love progressingthrough the challenges, which are academically rigorous, but also insanely fun, exciting andteen-focused.As we have highlighted here, the FUSE website is an essential element in the successfulimplementation of FUSE Studios. It provides both a tool for scaling up to a growing number of implementationsites as well as a research tool for studying learning in an interest-driven context. Most critically, the websitedemonstrates that technology, when thoughtfully designed and implemented, can in fact “re-mediate” learningin ways that productively transform rather than reinforce the practices of current education systems.ReferencesAmes, C., & Archer, J. (1988). Achievement goals in the classroom: Students’ learning strategies andmotivation processes. Journal of Educational Psychology, 80(3), 260-267.Barron, B. (2006). Interest and self-sustained learning as catalysts of development: A learning ecologyperspective. Human Development, 49(4), 193-224.Becker, H. S. (1972). A school is a lousy place to learn anything in. American Behavioral Scientist, 16(1), 85105.CSCL 2015 Proceedings354© ISLSBevan, B., Bell, P., Stevens, R., & Razfar, A. (2012). LOST opportunities: Learning in out of school time. NewYork: Springer.Cole, M. (2009). Designing, implementing, sustaining and evaluating ideocultures for learning anddevelopment; The case study of the Fifth Dimension. Cambridge: Cambridge University Press.Collins, A., & Halverson, R. (2009). Rethinking education in the age of technology: The digital revolution andschooling in America. Teachers College Press.Collins, A., & Halverson, R. (2010). The second educational revolution: Rethinking education in the age oftechnology. Journal of computer assisted learning, 26(1), 18-27.Cuban, L., & Tyack, D. (1995). Tinkering toward utopia: A century of public school reform. Nation.Cambridge, MA: Harvard University Press.Davis, C.A., & Fox, J. (1999). Evaluating Environmental Arrangement as Setting Events: Review andImplications for Measurement. Journal of Behavioral Education, 9(2), 77-96.Design-Based Research Collective. (2003). Design-based research: An emerging paradigm for educationalinquiry. Educational Researcher, 32(1), 5-8.Dweck, C. S. (1986). Motivational processes affecting learning. American Psychologist, 40(10), 1040-1048.Gee, J. P. (2007a). What video games have to teach us about literacy and learning (2nd ed.). New York:Palgrave/Macmillan.Gee, J. P. (2007b). Good Video Games and Good Learning: New Literacies and Digital Epistemologies. NewYork: Peter Lang Publishing.Hilton, M., & Honey, M. A. (Eds.). (2011). Learning science through computer games and simulations.National Academies Press.Horn, M. & Staker, H. (2014). Blended: Using Disruptive Innovation to Improve Schools. San Francisco: JoseyBass.Lave, J., & Wenger, E. (1991). Situated Learning: Legitimate peripheral participation. Cambridge: Universityof Cambridge PressMargolis, J., & Fisher, A. (2002). Unlocking the clubhouse: women in computing. Cambridge, MA: The MITPress.National Research Council. (2009). Learning science in informal environments: People, places and pursuits. P.Bell, B. Lewenstein, A.W. Shouse, & M.A. Feder (Eds.). Washington DC: The National AcademyPress.Seymour, E., & Hewitt, N. M. (1997). Talking about leaving: Why undergraduates leave the sciences. Boulder,CO: Westview Press.Squire, K. D. (2003). Video games in education. International Journal of Intelligent Games & Simulation, 2(1).Squire, K. (2011). Video Games and Learning: Teaching and Participatory Culture in the Digital Age. TeachersCollege Press.Stevens, R. (2007). Capturing ideas in digital things: The Traces digital annotation medium. In R. Goldman, B.Barron, R. Pea, & S.J. Derry (Eds.). Video Research in the Learning Sciences. New York: Routledge.Stevens, R. (2000). Who counts what as math: Emergent and assigned mathematical problems in a project-basedclassroom. In J. Boaler (Ed.), Multiple perspectives on Mathematics Teaching and Learning. NewYork: Elsivier.Stevens, R. (2013). Big Data, Interaction Analysis, and Everything in Between. Presentation at the Games,Learning and Society Conference, Madison, WI.Stevens, R., Satwicz, T., & McCarthy, L. (2008). In game, In room, In world: Reconnecting video game play tothe rest of kids’ lives. In K. Salen (Ed.), The Ecology of Games. Cambridge, MA: MIT Press.Varenne, H., & McDermott, R. (1998). Successful failure: The school America builds. Boulder, CO: WestviewPress.Wiggins, G. & McTighe, J. (1998). Understanding by design. Alexandria, VA: Association of Supervision andCurriculum Development.AcknowledgmentsFUSE is generously supported by grants from the MacArthur Foundation, Hive Chicago and from the NationalScience Foundation under grants DRL-1348800 and DRL-1433724. However, any opinions, findings,conclusions, and/or recommendations are those of the investigators and do not necessarily reflect the views ofthe funders. Special thanks to the FUSE team: Maggie Waldron, Henry Mann, Colin Sheaff, Anne Stevens,Sachin Pradhan, and Amy Pratt.CSCL 2015 Proceedings355© ISLS