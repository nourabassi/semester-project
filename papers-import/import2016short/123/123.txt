Let Your Data Tell a Story: Disciplinary Expert Feedback LocatesEngaging in Argumentation in a Holistic System of PracticesElizabeth M. Walsh, San Jose State University, elizabeth.walsh@sjsu.eduVeronica C. McGowan, University of Washington, vmcgowan@uw.eduAbstract: Trends in science education promote engagement in authentic knowledge in practiceto tackle personally consequential science problems. To better understand what authenticpractice looks like in a classroom, we examine interactions between scientists and students ona social media platform during two pilot enactments of a project-based curriculum focusing onthe ecological impacts of climate change. Scientists provided feedback to students oninfographics meant to communicate to an audience about climate change. We conceptualize thefeedback and student work as boundary objects co-created by students and scientists, andanalyze the structure and content of the scientists' feedback. We found that in feedback on aparticular practice scientists encouraged students to participate systemically in practices insteadof isolating one practice. Engaging with scientists around established scientific texts and datasets provided students with a platform for developing expertise in other important scientificpractices during argument construction.IntroductionThe Framework for K-12 Science Education and the Next Generation Science Standards were the first scienceeducation policy documents in the United States to position scientific practice on equal footing with sciencecontent knowledge through a three dimensional science learning model that partnered specific studentperformance expectations with related disciplinary core ideas, practices, and crosscutting concepts (NRC, 2012;NGSS Lead States, 2013). This practice turn in science education shifts focus away from knowledge accumulationto its application in context, with the intention of making visible to learners the performative aspects of research.In response to Next Generation curriculum structures, designed curricula should be oriented towards developingstudents’ disciplinary practice knowledge in addition to content knowledge, and central to our understanding ofthis knowledge base is the inherent social, holistic, and systemic nature of science knowledge construction.However, more research is needed to understand what disciplinary practice knowledge looks like in diversecontexts, and how to equitably support implementation at scale. This study investigated how a curriculum designthat partnered high school biology students with related disciplinary experts helped cultivate disciplinary practiceknowledge through engagement in a holistic system of science-related practices during the shared construction ofan evidence-based classroom artifact, an infographic, intended to communicate the research and implications ofclimate change on ecosystems.We leverage social practice theory, specifically the lens of legitimate peripheral participation (Lave &Wenger, 1991) to understand how students became engaged in a system of disciplinary practices as theyconstructed evidence-based arguments to communicate the ecological impacts of climate change in partnershipwith disciplinary experts. Through the process of legitimate peripheral participation, individuals learn with othersand develop expertise by observing and increasingly participating on the edge of a community of practice as theydevelop the shared discourse and practices of a given community (Lave & Wenger, 1991; Engle & Conant, 2002).The curriculum design in this study leveraged everyday technologies to situate high school biologystudent on the boundary of related disciplinary communities of practice by partnering them with scientists as theydeveloped a scientific artifact, the infographic. We analyze the infographic as a boundary object, which Star &Griesemer (1989) define as “objects which are both plastic enough to adapt to local needs and the constraints ofthe several parties employing them yet robust enough to maintain a common identity across sites.” Here, theinfographic helped scientists and students navigate disciplinary discourse around climate change argumentation,evidence, and communication and situated students on the boundary of a related community of practice in whichexperts modeled the rich system of disciplinary practice involved in crafting and communicating scientificarguments from professional data and evidence. Here, the infographic and the shared data set as boundary objects(Akkerman & Bakker, 2011; Star & Greisemer, 1989; Wenger, 1999) that mediated and scaffolded scientificdiscourse between learners and disciplinary experts.MethodsThis study draws on data from a larger curriculum development project to create year-long courses in LifeSciences and English Language Arts. Design principles included giving students opportunities to engage inICLS 2016 Proceedings866© ISLSauthentic scientific problems, to utilize scientific practices such as performing fieldwork, analyzing and usingcomputer models, and writing scientific texts. The curriculum used a social media platform that connectedstudents to each other, and also to disciplinary experts. Both courses were created using a design-based researchapproach in which individual modules were designed, implemented, and revised based on findings. This studyexamines the student-scientist interactions that occurred in the first two six-week pilot enactments of a module onthe Ecological Impacts of Climate Change in the Life Science course. The first pilot implementation (11 students)occurred from March - April, 2011 at Shale High School, an alternative school in a rural town outside of a majorcity. We conducted our second pilot study of the climate change curriculum from Oct-Dec 2011 in two 9th gradeclassrooms (40 students) at Quartz High School, an alternative school in an upper-middle class suburb of a majorcity. In the climate change enactments, 14 disciplinary experts reviewed student work, interacted with studentsvia Skype, and visited the classroom.Analysis targeted the interactions between scientists and students that occurred during the two pilotenactments, including written feedback scientists gave students on their infographic drafts (5 from Pilot 1, 17from Pilot 2, provided on the social media platform) and scientists’ questions and feedback on student’s finalpresentations (Pilot 2 only, in person). Documents containing student work and scientist feedback and transcriptsof scientist-student interactions were analyzed using the mixed-methods software Dedoose. Assertions weregenerated based on emergent themes and we searched the data corpus for disconfirming evidence (Erickson,1986).FindingsIn the feedback from the scientists, the construction of successful arguments and communication artifacts wasdeeply entwined with other scientific practices and scientists modeled ways in which they would approach aproblem or improve the argument or communication. While scientists reference all practices included in theNGSS, below we discuss in detail the practices of asking questions, designing and conducting investigations,constructing explanations and communicating information.1. Wondering, speculating and asking questions. Scientists’ open-ended questions allowed them to engage withstudent work by using the evidence students provided as a starting point for further investigation. In doing so,they revealed their own problem-solving processes. For example, in one instance a scientist responds to a studentgroup’s work on sea level rise and the monk seal by considering other climate parameters that could be affectingthe monk seal:I wonder if rainfall plays a major role in the Monk seal life . . . for instance – do they only goto the breading[sic] ground during the dry season or the wet season? If you can figure that out– then you might be able to argue that a change in climate can lead to a change in rain patternsand that might have some sort of impact on the seal life cycle?In this excerpt, the scientist is pursuing a line of thought that would supplement and fortify the students’ initialargument about the impact of climate change on monk seals by providing a second line of evidence about impacts.She “wonders” if changes in rainfall could potentially have consequences for the monk seal’s mating. This is anopen-ended, speculative question in that it is not a question that the scientist knows the answer to a priori. Instead,she models what her own practice would be in theorizing about relevant variables and interactions, offering ahypothesis that she encourages the students to “figure out” if it is supported or not by available evidence. If it issupported, the scientist suggests that having multiple lines of evidence would improve the argument. As opposedto a standard view of scientists as sources of information, through wondering or speculating questions, scientistsdid not supply any new “facts” or evidence, instead demonstrating how they would approach thinking throughpossible relevant interactions and evaluating whether or not they supported a particular argument. This exampledemonstrates the connection between two key practices in the Next Generation Science Standards: askingscientific questions and developing arguments from evidence. Asking these questions was a necessary step indeveloping rigorous, convincing arguments because it is how one obtains evidence and considers alternate oradditional contingencies.In many instances, scientists asked questions that were open-ended, but that it can be reasonably assumedthe scientist already knew the answer to, either in full or in part. These were coded as “probing questions” andwere the most common question type. These kinds of questions also modeled scientific questioning practice, andsupported argumentation as through these kinds of questions, scientists processes of building arguments byhighlighting the need for more evidence, more explanation or clearer logic.ICLS 2016 Proceedings867© ISLS2. Scientific explanation in argumentation. The infographic assignment required students to both explain thescientific evidence and use it in an argument about how climate change might affect ecosystems. In feedback tostudents, scientists critiqued the explanations for completeness and correctness, offered supplementaryinformation that supported student explanations, and made suggestions about how to improve coherence betweenthe text and graphics for explanations.Scientists’ comments included supplemental factual information that expanded student explanations. Forexample, one student group proposed that the Canada Lynx and snowshoe hare would not be able to shift theirrange north because they already live at high latitudes. The scientist giving feedback added in a comment: “Inaddition, the area north of the lynx’s range is mostly tundra and lynx are found mostly in forest.” This statementprovides new information that both supports the student’s argument but also builds out their explanation ofconstraints on range shifts. By providing this just-in-time content, scientists provided input aimed to help studentscreate more thorough and conceptually accurate explanations.Scientists also pointed out places that students could improve their argument by incorporating morescientific explanations. For example, in one instance a scientist encouraged a student to investigate and explainthe impacts on plant growth in more detail:You might want to help the reader make the connection between climate change and plantgrowth by explaining some ways climate change might affect plants – what are some thingsplants need that might be changing?In this instance, the scientist specifically gears the student to consider what would be helpful for “the reader”—thus, this scientist is concerned with explanations needed to communicate the student’s argument. Scientists alsonoted when the text and graphics didn’t align, specifically when explanations of figures and graphs were missing.Scientists’ feedback centered on the importance of not only including data but explaining it well in order to clearlycommunicate to an outside audience.3. Designing and carrying out investigations. In the unit, students designed and carried out an investigation intothe effect of changing climate parameters (e.g. temperature, water) on Wisconsin Fast Plants, a fast-growingbrassica species and conducted fieldwork on phenology through a citizen science effort. While students reportedthat they enjoyed both activities, students rarely utilized the data they collected themselves through theseinvestigations on their infographic. Rather than using their own data, they instead pulled from established datasets, such as the climate model results discussed above. This deviates from a common inquiry model in scienceclassrooms in which students carry out their own investigations through physical manipulation. Instead of usingtheir own results, students engaged in an investigation more similar to data mining, in which individuals queryexisting data to answer questions. This is an authentic practice in climate science, as much work is conducted asanalysis of large, shared data. The feedback scientists provided on this kind of investigation overlapped withfeedback on data analysis, use and interpretation, and there were no instances in which scientists gave specificfeedback on how to carry out empirical investigations or collect data.4. Obtaining and communicating information. The infographic assignment provided students with the opportunityto employ multiple modalities in construction of their argument. This is congruent with common scientificcommunication practices in which both visual elements (e.g. graphs, tables, pictures) and text are used. Onescientist noted the authenticity of the infographic product as similar to scientific poster presentations. She usedthe idea of a story to frame the construction of a poster (or infographic) and positioned the student’s work as partof a real scientific practice and also provides insight into how a scientist might think about constructing a posterthat tells a “story”. A “story” provides a different connotation than an “argument” or “infographic.” The scientistsuggests adding visual elements that would also help tell the story: “You could even draw an arrow between thefacts and analysis or put a box around them so that it’s very clear that they’re connected.” This feedback highlightsthe role that design has on its success as a communication tool.Many scientists made comments about the appropriateness of visual elements, the placement andarrangement of the elements, and suggested new visual elements to include to improve either the ability of theinfographic to communicate to a particular audience, or the validity of the argument. For example, scientistsevaluated whether or not visual elements actually provided support for the argument. Referencing the inclusionof a map of Florida sea level rise in an infographic about polar bears, one scientist asked: “Are changes in Floridarelevant to polar bears?” suggesting that the visual element might not be the most appropriate. In some cases,scientists made comments about visual elements they thought would be appealing or helpful to readers from acommunication standpoint.ICLS 2016 Proceedings868© ISLSConclusions and implicationsDisciplinary practice knowledge is a broad and diverse arrangement of knowledge and practices that take manyforms in professional, community and learning settings. The findings from our study suggest that scientists’ viewsand communication of their own practices align with the integrative three dimensionality of the NGSS. Bymodeling their own questioning and learning processes, scientists encouraged students to craft and interrogatetheir arguments by employing a suite of related practices. For the scientists, providing feedback on students’arguments and communication necessarily involved critique on the interrelated web of scientific knowledgeconstruction practices. Multiple practices can and did occur in the same act-- developing an explanation was apart of argument construction, and using models required data analysis. The boundaries between the practices aremore fluid than the rigid list of eight in the NGSS might suggest.The practice of modeling through literary inscription (Latour & Woolgar, 1986) was also intimately tiedto argumentation and communication of data, and professional data sets served as useful boundary objects thatenabled students and experts to mutually construct climate change related arguments across classroom andprofessional boundaries. During the climate change unit, students generated their own climate-change related datathrough classroom phenology experiments, in addition to data mining publicly available professional climatechange data sets. However, in this case the student-generated data was not robust enough to serve as a boundaryobject across contexts as students rarely leveraged their own data to support or communicate evidence for theecological impacts of climate change on their infographics. Although the scientists were aware of the studentgenerated data, they also never requested or added to student-generated data pieces. In contrast, publicly availableprofessional data sets proved to be robust boundary objects that mediated disciplinary discourse between studentsand scientists, and were easily leveraged to communicate the ecological impacts of climate change to diverseaudiences. The adaptability of these professional data sets across contexts enabled the scientists to effectivelymodel disciplinary ways of knowing for students.Boundary objects, such as common data sets, are commonly used in professional science context toconnect related communities of practice, to provide diverse lenses and expertise around existing knowledge basesand to engage related practitioners in sense-making practices around bounded pieces of evidence. Our researchsuggests that social networking technologies and disciplinary data sets can effectively position students aslegitimate peripheral participants on the boundaries of related disciplinary communities of practice. As Wenger(1999) noted, innovative learning can happen on the boundaries of these communities in ways that enable studentsto maintain their existing identities regarding climate change perspective, while robust boundary objects can allowthem to work in partnership with disciplinary experts to construct evidence-based stories of the ecological impactsof climate change that engage students in holistic learning as described by NGSS.ReferencesAkkerman, S. F., & Bakker, A. (2011). Boundary crossing and boundary objects. Review of educational research,81(2), 132-169.Engle, R. A., & Conant, F. R. (2002). Guiding principles for fostering productive disciplinary engagement:Explaining an emergent argument in a community of learners classroom. Cognition and Instruction,20(4), 399-483.Latour, B., & Woolgar, S. (1986). Laboratory life: The construction of scientific facts. Princeton, N.J: PrincetonUniversity Press.Lave, J., & Wenger, E. (1991). Situated learning: Legitimate peripheral participation. Cambridge UniversityPress.National Research Council (Ed.). (1996). National science education standards. National Academy Press.Star, S. L., & Griesemer, J. R. (1989). Institutional ecology, translations' and boundary objects: Amateurs andprofessionals in Berkeley's Museum of Vertebrate Zoology, 1907-39. Social studies of science, 19(3),387-420.Wenger, E. (1999). Communities of practice: Learning, meaning, and identity. Cambridge University Press.AcknowledgmentsThis research was supported by a grant from the Bill & Melinda Gates Foundation to PI Dr. Philip Bell. Wewould like to thank Dr. Bell for his guidance and leadership on this project, as well as Dr. Blakely Tsurusaki, andthe Educurious research & design team and staff for their invaluable intellectual and logistical support. We thankthe student and scientist participants.ICLS 2016 Proceedings869© ISLS