Design Considerations for Capturing Computational ThinkingPractices in High School Students’ Electronic Textile PortfoliosDebora Lui, University of Pennsylvania, deblui@upenn.eduGayithri Jayathirtha, University of Pennsylvania, gayithri@gse.upenn.edu,Deborah A. Fields, Utah State University, deborah.fields@usu.eduMia Shaw, University of Pennsylvania, mshaw12@gse.upenn.eduYasmin Kafai, University of Pennsylvania, kafai@upenn.eduAbstract: Assessing computational thinking in making has proven a challenge, in partbecause student creations are innately diverse and unique. In this paper we consider portfoliosas a way to document and assess students’ learning processes in the context of designingelectronic textile (e-textile) projects. We describe students’ use of portfolios at the end of anintroductory computing course, Exploring Computer Science, during which 33 studentscreated a series of electronic textile (e-textile) projects as part of a new curricular unit. Ouranalysis not only illuminates the capability of portfolios to capture computational practicesand certain concepts, but also reveals students’ lack of effective use of non-textual evidence intheir narrations. We consider the affordances and limitations of portfolios for supportingstudent reflection and metacognition of their own learning as well improvements that could bemade to scaffold students’ communication and use of visual evidence in more effective ways.IntroductionAssessing student learning in computationally-rich maker activities has been a challenge for practitioners andresearchers alike. While early discussion about educational making assumed the creation of an artifact coulddemonstrate the acquisition of skills, content and even a ‘maker mindset’ (Honey & Kanter, 2013; Dougherty,2013), continued spread of these activities into formal educational settings has made researchers interested innot only asking what students learn, but also how to appropriately assess learning (e.g., Papavlasopoulou,Giannakos, & Jaccheri, 2017). Recent efforts in this arena include the development of traditional evaluativetools such as written tests or surveys (e.g., Litts, Kafai, Lui, Walker & Widman, 2017; Chu et al., 2015) andmore novel approaches such as hands-on engineering performance tasks and eye tracking (e.g. Davis, Schneider& Blikstein, 2017). However, these assessments do not capture the process of making or the kinds of learningthat students gain while working through mistakes, errors, and changes in their project. For this we turn toportfolios.Portfolios have long been used as an assessment tool in disciplines such as art, design, writing andmore recently in STEM fields (Chang et al., 2015; Býrgýn & Adnan, 2007). Not only can portfolios providemore holistic measures of learning, capturing process and growth over time (Paulson, Paulson & Meyer, 1991),they can also be situated within students’ everyday work and context (Býrgýn & Adnan, 2007). Withincomputer science education portfolios have recently gained more traction through the newly launched AdvancedPlacement Computer Science Principles (AP CSP) course (College Board, 2017), where they havesupplemented the standard multiple-choice exam. Beyond assessment, however, portfolios can be powerfullearning tools in and of themselves, allowing students to reflect upon their own experiences and regulate theirown pathways of learning—in other words, develop metacognition skills, something that can support moreequitable learning (Darling-Hammond, 2008). However, though portfolios are acknowledged as a powerfulchannel for both assessment and reflection within a wide range of established disciplines, less is known abouthow well they are able to capture and support student learning of computational thinking, or skills involved in“solving problems, designing systems, and understanding human behavior, by drawing on the conceptsfundamental to computer science” (Wing, 2006, p. 33), such as abstractions, iterations, and algorithms.In this paper, we report on a study focused on the design and implementation of a portfolio assignmentthat aims to capture students’ computational thinking. We worked with a high school computer scienceinstructor teaching electronic textiles where students sew and program sewable microcontrollers, actuators, andsensors attached to fabric based artifacts such as clothing and toys (Buechley, Eisenberg, Catchen, & Crockett,2008). Based on previous research looking at the effectiveness of teacher-designed portfolios in capturingstudents’ processes of working with electronic textiles (Lui, et al., under review), we designed a portfolioassignment that was given to (and adapted by) the high school teacher for the purpose of capturing his students’learning, practices and reflections. Students were provided prompts regarding content and media use, with aspecific focus on capturing students’ computational thinking practices (Brennan & Resnick, 2012) includingICLS 2018 Proceedings721© ISLSrevision and iteration as well as debugging and troubleshooting, and concepts including coding, circuitry,design, and crafting (Kafai, Fields, & Searle, 2014). Analyzing the text, images and videos of the students’portfolios, we addressed two research questions: (1) How did this portfolio implementation support students indocumenting and sharing their processes of making a computational artifact? (2) What are the affordances of theportfolios for revealing students’ computational thinking and concepts learned? In our discussion, we addressaffordances and challenges of using portfolios and report on recommendations which include more definedscaffolds, as well as models of effective computational communication. We also discuss avenues for futureresearch in these areas.BackgroundThough portfolios have been used across many disciplines and fields for assessment, their actual formats andcontents vary widely, providing different models for measuring and supporting computational thinking. In artand design, the predominant form promotes the curation of one’s best projects over time, allowing a ‘showcase’of overall competency and skill (Býrgýn & Adnan, 2007). STEM portfolios tend to follow another formatderived from writing (Williams, 2002), which focuses more on continuous documentation of students’ learningand growth (Paulson et al., 1991), sometimes through progression of just a single project (Chang et al., 2015).These ‘process-folios’ often focus on collection of different kinds of in-progress evidence compiled over astudent’s trajectory. This includes a range of often non-textual forms such as initial prototype ideas forengineering projects (Eris, 2007), code throughout the development process (Higgs & Sabin, 2005), or photos ofprojects in process (Chang et al., 2015). Rather than merely presenting their artifacts, students provide textualexplanations for this evidence, whether explanatory captions and annotations (Býrgýn & Adnan, 2007),articulation of underlying concepts (Phelps, LaPorte and Mahood, 1997), or narrations of growth and learning(Paulson et al., 1991). For this reason, these types of portfolios highlight the actual aspects of creation andreasoning around production that are normally hidden when only relying on final products as a form ofassessment (Chang et al., 2015).Little is known about how well portfolios are able to capture novice students’ computational thinkingthrough the creation of an artifact, digital or not. As highlighted by Brennan and Resnick (2012), opportunitiesfor youth to describe their experiences while creating computational artifacts can provide a window into theirunderstanding of their computational thinking skills, something that can encompass knowledge of particularconcepts, practices, and perspectives. Much of this depends on students’ communicative abilities, a skill that isnot often stressed in the context of computer science, let alone other STEM fields (Michael, 2000; Williams,2002). In CS education, this is not just a factor of knowing the “vocabulary of computing” (Grover, Cooper &Pea, 2014), but also being able to use these terms in context, something that has been proven to foster “deepercomputational learning” and nurture students’ abilities to think about “computational ideas more effectively” (p.58). This lack of emphasis on communication in computational contexts seems especially problematic,considering that it has recently been highlighted as a key computational practice within the AP CSP (CollegeBoard, 2017). There, it is described as a student’s ability to report on one’s own computational choices andjustifications, well as describe the results or behaviors of computational artifacts (p. 10). Notably, the way thatstudents are expected to accomplish this includes leveraging “accurate and precise language, notations, orvisualizations” (p. 10)— in other words, focusing on both text and images. However, as noted by Williams(2002), expecting that students can effectively communicate about technical issues without assistance is notpractical; not only does this require more careful scaffolding, but also actually defining what ‘counts’ aseffective communication within this realm and explicitly sharing this with students.The difficulty of using portfolios to promote student communication about computation washighlighted within a previous study (Lui et al., under review), where we also analyzed the use of a teacherdesigned portfolio assignment for assessing computational thinking. There, students created portfolios to reflecttheir process of making an electronic-textile sign. The format of that portfolio was based primarily on the fourestablished domains of e-textiles work: design—the planning of the aesthetics of a project, circuitry—thecreation of electrical connections between components, coding—the programming of students’ projects, andcrafting—the physical sewing and construction of the project. Students were asked to describe their experienceswithin each of these domains, with recommendations to discuss challenges and include non-textual evidencesuch as photographs, diagrams, and code excerpts. While this portfolio format was successful at capturing thegeneral nature of students’ processes and practices in making their artifacts, it was not as successful in capturingthe actual details of these experiences or the students’ understanding of underlying computational concepts,whether in coding or circuitry. Furthermore, students’ use of images and code as evidence varied greatly; moststudents primarily used them as a part of their aesthetics, offering little explanation or contextualization. Basedon these findings as well as research on how process-folios can be structured, we designed a portfolioICLS 2018 Proceedings722© ISLSassignment to address these potential weaknesses in capturing students’ computational thinking. This includedan initial focus on computational practices rather than concepts and requiring the use of non-textual processevidence such as photos and diagrams. Our goals were to look at how well the portfolios were able to capturestudents’ experiences and reflections for the purposes of student learning as well as assessment.MethodsContext and participantsThe Exploring Computer Science (ECS) initiative comprises a one-year introductory high school computingcurriculum with a two-year professional development sequence (Margolis & Goode, 2016) to increase diversity.We co-developed an e-textiles curricular unit (Fields, Kafai, Nakajima & Goode, 2017) that takes place overeight weeks and consists of a series of four projects, with the final project incorporating a handmade humansensor created from two aluminum foil conductive patches that when squeezed generate a range of data.In this study we focus on one high school teacher’s implementation of portfolios in the e-textiles unitduring Spring 2017. An experienced ECS teacher and leader, Ben taught at an independent charter high schoollocated in the suburbs of a large metropolitan city on the U.S. West Coast. He had many years of experienceteaching ECS and one prior year of teaching the e-textile unit in his class. His class included 35 students, 16girls and 19 boys, mostly from 9th grade (14-15 years old) as students were encouraged to take ECS in their firstyear of high school. The school enrolls about 4,600 students: 4% African American, 18% Asian, 10% Filipino,40% Hispanic or Latino, 25% White, 1% two or more races, and 2% race not reported. Fifty-four percent of thestudents come from socioeconomically disadvantaged families.Design of portfolio assignmentThe portfolio assignment was designed to capture students’ descriptions of their final projects and discussions oftheir process, through the use of both textual (written) and non-textual (photos, diagrams, code) evidence.Refining the format of the assignment to accommodate his needs, Ben provided a Google Slides template forstudents, which included the following prompts: 1) Describe their final human sensor project (in a video orusing pictures and text, one slide); 2) Discuss their process for making the human sensor project, including theirinitial design and any revisions made, and at least one challenge that they dealt with (in written form, twoslides), (see Figure 1 for example) and 3) Reflect on their experience and identity as a computer scientist acrossthe entire e-textiles unit (in written form, one slide).For both of the written sections, students were required to provide non-textual evidence for theirlearning whether drawings of their designs, circuit diagrams, code snippets, or excerpts and photos from theirengineering design notebooks and journals. Some of these journal prompts included questions about their designprocesses such as “What were some modifications you had to make in your design?” and occasionally theteacher would prompt students to take a picture of their projects so that they could track changes. Students onlyhad a few days at the end of the unit to work on their portfolios, partly by design (because of the need to limitthe unit to a certain number of weeks in line with the other ECS units) and partly by necessity (because it wasthe end of the school year and priority was placed on finishing projects). During these days in Ben’s class, moststudents chose to focus their time on putting finishing touches on their human sensor projects and therefore,worked on their portfolios at home. This means that we have little observational data to draw on regarding howstudents put their portfolios together.Data collection and analysisAt the end of the class, we collected the digital portfolios from 33 students (two students did not turn inportfolios), which consisted of a combination of text, photos, and videos embedded in Google Slidepresentations. Data from the broader study included weekly observations of classes documented in field notes,short interviews with six students (including a brief question on their thoughts about the portfolios), and pre/postinterviews with the teacher (also including some reflection on the portfolios). The portfolios themselves werethe focus of analysis, though we also triangulated some of the findings with the teacher post-interview. Acrossthe portfolios, we analyzed the two written sections of the portfolios, which included: discussion of process andreflections on learning.Within each of these sections we analyzed: 1) Computational practices—The process-related activitiesreferenced, whether revising their projects—making changes to their design based on interest or requirements,or dealing with challenges—diagnosing and solving problems. These draw from existing research oncomputational practices that identify being incremental and iterative, and debugging and testing as key activitieswhen creating computational artifacts (Brennan & Resnick, 2012). We also looked for if students referencedICLS 2018 Proceedings723© ISLSadditional practices (e.g., planning their projects, remixing); 2) Computational concepts—The e-textiles domainsreferenced (e.g., design, circuitry, coding, crafting), and level of detail included, such as allusions to related subconcepts (e.g., polarity, conditionals, mechanics of sewing). Given the interdisciplinary nature of e-textiles,multiple concepts often emerged in the sections; 3) Language—The level of detail and specificity included intheir narration. We looked to see if students provided ‘full explanations,’ which meant discussions of both theirproblems and solutions for challenges, their before and after-state for revisions, or their justifications for theirlearning and reflections; and 4) Non-textual supporting evidence—What forms of evidence were provided (e.g.,drawings, diagrams, code, other), as well as how effectively it was presented as part of their argument (i.e.,without any explanation at all; referred to in text/prose; included extra annotation or a captions). After analyzingthese portfolios, identified trends within students’ communication of their process and reflections on theirlearning. We not only highlight what they said about these topics (e.g., concepts addressed), but also how theseareas were communicated through the different media forms and language styles.FindingsRevisions, challenges, and reflections in student portfoliosOverall, the portfolio assignment was successful in getting students to document and share aspects of how theycreated their projects and some of the difficulties that arose as they created them. However, students completedthe portfolios with a high degree of variance, both in meeting the requirements for each section that Benrequired and in the quality of the descriptions and evidence they shared. One major area of difference we foundrelated to revisions (changes made from the initial design of the project) and challenges (an issue that came upin making the project). Though both were required with dedicated slides assigned in the template, 85% of thestudents included challenges in their portfolios, while only 45% of students wrote about revisions (36%completed both parts).There are several possibilities for why students completed the challenges section more than therevisions section. First, the prompt for revisions asked students to think about their initial design and how itchanged. This required thinking back to the beginning of the project of what would normally be a 2-3 weekperiod. However, this was extended even farther for these students because of the two weeks of paternity leavethat Ben took, something that likely further hindered their memory. Second, students might not have beendiligent in recording changes or taking pictures of early stages of the project, which would have allowed them tothink about how their project had changed from beginning to end. In his post-interview, Ben commented that,while he encouraged students to document progress, students’ records were very disorganized with “papers allover the place like a fifth grader’s exploded backpack.” One proposed change he made for the future was to “bea little bit more conscious of referring to the design notebook, that when you make [design] changes [to] makethe changes in your notebook.” Ben’s reflection as a teacher that students needed to keep track of and documentchanges therefore highlights the potential reason for the lackluster record of revisions in the portfolios. Finally,the assigned journal questions that students answered during the project and Ben’s discussion on the portfolioassignment featured challenges, bugs, and fixes far more than ideas about revisions. Thus, the curriculum andteaching likely emphasized working through challenges and mistakes more than thinking about revisionsindependent of those issues.Along with discussing challenges and revisions, portfolios provided opportunities for students to reflecton their learning, not only in the human sensor project but also in the overall electronic textiles unit. Amandatory part of the portfolio, all 33 students reflected on their learning in this overarching way and in doingso mentioned at least two of the four domains on average. In their reflections, 38% explicitly mentionedacquiring debugging and testing skills through the experience of making e-textiles projects. Additionally, 30%of students believed that planning was a practice they developed, while 18% even mentioned some soft skillssuch as “being patient,” or “not … procrastinat[ing]” which helped them with the process of making the etextiles projects. These types of comments suggest that the portfolios were a place where students could reflectmetacognitively about their learning across the many weeks of the e-textiles unit.Content and detail (or lack thereof) in student portfoliosAcross each of the areas where students reflected on their processes of making and learning, there was apredominant lack of detail in student reporting. Only 46% of challenges, 35% of revisions, and 27% ofreflections provided detailed explanations about with explicit references to specific areas of design, craft,circuitry, or code. As an example, compare the slides on the left and right in Figure 1. On the left, Leon wrotevaguely that having a plan was important as was working through mistakes, but without explaining what any ofthe specific mistakes were or why a plan would have been helpful. In contrast, Aditya’s slide on the rightICLS 2018 Proceedings724© ISLSprovides a very clear explanation an error that arose in coding. He had mislabeled one of the variables naminghis pins and this resulted in abnormal readings from the sensor (since he named the same pin, #9, both as anLED—an output, and as the sensor—an input). These types of details were lacking in many students’ portfoliosoverall, making it difficult to understand in what areas students struggled and learned.Figure 1. Leon’s portfolio page (left) and one of Aditya’s portfolio pages (right) on the human sensor project.In addition to the general lack of specificity in students’ portfolios, differences appeared within conceptualdomains in terms of how specific students were in their descriptions. Most discussions around crafting (83%)and circuitry (84%) explicated specific areas that needed fixing or revising. For example, Alejandra’sdescription of challenges in making her stuffed cookie pillow project provided relatively detailed reports ofwhere she had issues in circuitry and designing:…[W]hen 2 of my LEDs were not lighting up. I was really confused on what was wrong, butthen I noticed that conductive thread from both a positive and negative were touched when Iput the ends of my project together and that was what was wrong. To fix this problem whensewing my project shut, I put some stuffing between those two ends so they wouldn’t touch.(Alejandra, portfolio)Here, she explained a circuitry design issue that was complicated by the circuitry going across the front andback of her cookie pillow. When the pillow was closed together, those two sides touched in the middle, creatinga short circuit. Adding stuffing separated the two sides and resolved the issue. More often than not, studentswere relatively specific about issues related to design, craft, and circuitry.In contrast to design, circuitry, and crafting, only half of the mentions of coding (54%) provided detail.For example, Vivian described her challenge with coding in only one sentence: “Earlier into the project i haddifficulties on coding [sic] and understanding the light sensors.” Her explanation makes it impossible to deducewhat specifically she struggled to understand, though we might expect it to relate to sensors throughconditionals or mathematical expressions. Other students were even more vague, saying things like “I know thatcoding is pretty fun” (Amy) or “In the begginign [sic] I had no idea what to call a LED, but know I can code myown code that can feel pressure” (Kevin). In contrast to these more generic statements, the descriptions ofstudents like Aditya (above, see Figure 1) and Lien stand out. Lien explained some complex coding issues thatcame up in her handbag creation:[T]rying to get the computer to read information from both the light sensor and the humansensors like in the code on the slide caused to computer to not be able to read either of them. Idecided to use the switches on the playground to use for coding more light patternsinstead…Despite both sets are fine [sic], the computer could not read and work the code madeup of both sets. (Lien, portfolio)Here Lien described problems with her ambitious effort to use readings from two sensors. Though she knewhow to independently code each sensor and link it with lighting patterns, “Trying to mix two sets of workingcode together does not automatically make a working set of new code” (Lien, Portfolio). The contrast betweenVivian’s and Lien’s descriptions of their coding issues shows the importance of using specific language toclarify a challenge faced or a revision made. Overall, this difference in use of detailed language within thedifferent domains highlights the need to consider not only what prompts students are given within portfolios, butalso how to support students to more effectively communicate technical details through specific language.Students’ use of non-textual supporting evidenceICLS 2018 Proceedings725© ISLSThe portfolio also allowed students to employ non-textual evidence in form of photos, diagrams, and sketches tosupport their narratives about their process and their reflections. As seen in the examples previously (see Figures1, 3), portfolios were helpful in eliciting a range of non-textual information about the process of making theseartifacts. Out of the 33 portfolios, 25 students provided some form of evidence. Of these students, most usedpictures (48%) or diagrams (45%) of their projects (see Figure 1, left), while much fewer (33%) includedexcerpts of code (see Figure 1, right). Interestingly, although a majority of students referred to coding as themost challenging domain, code emerged as the least prevalent artifact used as evidence throughout theportfolios. The lack of coding evidence furthers the points mentioned above about students needing support inexplicating their coding problems and learning.Further, across all types of non-textual evidence, many students provided no explanation, annotations,or references within the text while discussing their challenges (62%), revisions (45%) or reflections (62%). Onlya few made direct reference to this non-textual evidence within their text (e.g., “in the picture below...,” “thediagram illustrates…”), and even fewer included relevant visual annotations or notations (e.g., arrows, labels,color-coding). As an example consider Leon’s portfolio page (Figure 1, left) where he included two pictures ofhis project. There were no arrows or explanations as to what these pictures showed, or how they related to hisstatements that he learned the importance of planning or working through mistakes. Aditya’s use of evidence(Figure 1, right) is comparatively better in that he uses and labels two examples of code so that viewers knowwhich came first. A viewer with experience in Arduino could match his writing with the examples to identifythe issue (i.e., labeling both variables “led1” and “aluminumfoil” as pin 9), though additional annotation such asarrows pointing to the problematic line (top line of the upper code image) would make that more clear. Thepredominant lack of explanation and annotation amongst students suggests that more effective scaffolds,examples, and modelling may be needed to help them utilize non-textual evidence effectively.DiscussionThis study is part of a larger effort to test the feasibility of and develop appropriate formats for the use ofportfolios (or process-folios) for measuring and supporting students’ computational thinking within the ECS etextile unit. We observed different affordances and challenges in the portfolio design in getting students todocument and share their processes, as well as assessing their computational thinking. These, along withrecommendations for improving the utility of the portfolio as both a learning and assessment tool, are furtherdescribed below.Portfolios as tools to support student learningIn contrast to performance-based testing, the portfolios that Ben implemented provided opportunities forstudents to articulate their design processes (design, crafting, circuitry or coding) and reflections and supportthem with evidence. They were successful at getting students to document, share, and reflect upon their overallexperience and learning trajectory. Most students provided at least some documentation (and others quite richexplication) of their learning in ways that demonstrated some metacognitive awareness (Darling-Hammond,2008). Students would often conclude with mentions of being proud of their project or their growth, animportant aspect of identity and motivation in learning with implication for their future trajectories in the field(e.g., Pinkard et al, 2007). Further, the simple act of documenting their project along the way and choosingwhich pieces of evidence to include is inherently a form of reflection since it requires students to conceptualizeand produce a narrative of learning and process (Paulson, Paulson & Meyer, 1991). The types of portfolios usedin this curriculum clearly had some potential benefits for students’ learning and reflection in CS.However, there was great variance in the quality and quantity of descriptions. Some students movedpast the initial requirements and mentioned several challenges and learning gains, describing their learning ingreat depth, while others stayed at very low levels of description. Yet most students neglected to describe therevisions they made within their project, something that is surprising considering that Ben specifically askedstudents to address changes made to their initial designs within his slide template. In addition, many students’descriptions lacked details that allowed readers to fully understand the problems they dealt with and failed toexplain what they actually learned outside of generic statements about improvements in sewing and especiallycoding and design. In other words, even though all students did provide narrations of their process, these wereoften opaque because of the lack of detailed language and included inefficient use of non-textual evidence.Clearly we need to equip students better so that they can articular their learning more effectively.Portfolios as tools to assess computational thinkingWhile the teacher did scaffold the portfolio process in several ways—through journal questions, reminders totake photographs of projects, and the template for the portfolio—we need to explore additional scaffolds toICLS 2018 Proceedings726© ISLSassist students in improving their computational communication skills. One potential change is to focus on whatGrover, Cooper and Pea (2014) call the “vocabulary of computing,” which moves beyond word choice towardgiving students actual communicative tools through which to articulate and concretize abstract computationalknowledge. This is particularly needed since, as noted earlier, students mentioned coding often as a challenge,yet were unable to describe their issues in precise ways. In practice, an emphasis on the vocabulary ofcomputing would involve being more explicit about developing shared classroom discourse aroundcomputational thinking. By giving students access to this language, teachers would not only have moreopportunities to assess what is actually occurring, but also help increase student understanding of these conceptsand practices. Another possible change would involve collecting and sharing exemplars of good computationalcommunication with students. Following Williams (2002), teachers cannot just expect that students becomeeffective communicators if this has not been defined for them beforehand.In future implementations of the curriculum we will provide different models of portfolios, recommendthat teachers discuss these with students early in the process, and study whether this helps students developbetter communicative competence about their computational learning. There is also an opportunity to use wholeclass peer critique sessions, already used in the design of the e-textiles projects in the unit, on the portfolios. Wealso hope to explore with teachers like Ben how to better integrate active reflection and documentationthroughout the e-textiles unit (not just in the final project) in an effort to support communication as acomputational practice that is fully integrated into the curriculum, rather than something engaged at distincttimepoints apart from the process. However, time is a very explicit limitation on all of these efforts. There is noroom to expand the units in light of the other material that must be covered as a part of the ECS curriculum.How can we balance the importance of creating these projects with the benefits of reflecting on the process ofcreation?Portfolios and computational communication beyond classroomsPortfolios are becoming more significant options within STEM disciplines for academic and professionalassessment. Not only are they being used for college admissions and the AP CSP course, but also for careeradvancement (Chang et al., 2015). Introducing students to portfolios within the ECS classroom gives themopportunities to practice this new format of explaining STEM knowledge and skills in addition to the personallearning awareness they offer. Further, portfolios can also be used within personal contexts. Recognizing thepotential short lives of student-made artifacts, portfolios can serve as a vehicle to keep the learning and makingexperience alive when a fully functional artifact may long be gone. Finally, portfolios can also serve a socialpurpose, enabling students to connect to the larger maker culture that exists beyond classroom. Sharing has beenpromoted as key tenet of the Maker Movement (Dougherty, 2013), wherein makers of all backgrounds and agesshare their projects and expertise with others in various formats. Research indicates that learning to become amaker is as much about creating artifacts as it is about learning to participate in communities (Pinkard et al.,2017). Thus, students’ engagement with the practice of computational communication can promote participationat-large, following the idea that computation is an essentially social practice (Kafai & Burke, 2014). For allthese reasons, more research is needed to explore the affordances of different types of portfolios in supportingand assessing computational thinking, classroom supports for encouraging deeper reflection andcommunication, and students’ own perceptions about the benefits of creating these personalized narrativesaround their learning and process.Endnotes(1) All participant names are pseudonyms to protect confidentiality.ReferencesBrennan, K., & Resnick, M. (2012, April). New frameworks for studying and assessing the development ofcomputational thinking. Paper presentation at the annual meeting of the American EducationalResearch Association, Vancouver, Canada.Buechley, L., Eisenberg, M., Catchen, J., & Crockett, A. (2008, April). The LilyPad Arduino: usingcomputational textiles to investigate engagement, aesthetics, and diversity in computer scienceeducation. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems (pp.423-432). New York, NY: ACM.Býrgýn, O., & Adnan, B. A. K. Ý. (2007). The Use of Portfolio to Assess Students' Performance. Journal ofTurkish Science Education, 4(2), 75.Chang, S., Keune, A., Peppler, K., Maltese, A., McKay, C. & Regalla, L. (2015). Open Portfolios: MakerEducation Initiative Full Research Brief Series. Retrieved from: http://makered.org/opp/publications/ICLS 2018 Proceedings727© ISLSChu, S. L., Quek, F., Bhangaonkar, S., Ging, A. B., & Sridharamurthy, K. (2015). Making the Maker: A Meansto-an-Ends approach to nurturing the Maker mindset in elementary-aged children. InternationalJournal of Child-Computer Interaction, 5, 11-19.College Board (2017). Advanced Placement Computer Science Principles Course Guide. Retrieved fromhttps://apcentral.collegeboard.org/pdf/ap-computer-science-principles-course-and-examdescription.pdfDarling-Hammond, L. 2008. Powerful learning: What we know about teaching for understanding. Jossey-Bass,San Francisco, CADavis, R. L., Schneider, B., & Blikstein, P. (2017). Making the Invisible Visible: A New Method for CapturingStudent Development in Makerspaces. In Proceedings of 12th International Conference on ComputerSupported Collaborative Learning (CSCL) 2017. Philadelphia, PA: International Society of theLearning SciencesDougherty, D. (2013). The maker mindset. In M. Honey & D.E. Kanter (Eds.), Design, make, play: Growing thenext generation of STEM innovators (pp. 7-11). New York, NY: Routledge.Eris, O. (2007). Insisting on truth at the expense of conceptualization: can engineering portfolios help?.International Journal of Engineering Education, 22(3), 551.Fields, D. A., Kafai, Y. B., Nakajima, T., & Goode, J. (2017). Teaching practices for making e-textiles in highschool computing classrooms. In Proceedings of FabLearn17, October 21- 22, 2017.Kafai, Y. B., Burke, Q. (2014). Connected code: Why children need to learn programming. Cambridge, MA:MIT Press.Grover, S., Cooper, S., & Pea, R. (2014, June). Assessing computational learning in K-12. In Proceedings of the2014 conference on Innovation & technology in computer science education (pp. 57-62). ACM.Higgs, B., & Sabin, M. (2005, October). Towards using online portfolios in computing courses. In Proceedingsof the 6th conference on Information technology education (pp. 323-328). New York, NY: ACM.Honey, M., & Kanter, D. E. (Eds.). (2013). Design, make, play: Growing the next generation of STEMinnovators. Routledge.Kafai, Y., Fields, D., & Searle, K. (2014). Electronic textiles as disruptive designs: Supporting and challengingmaker activities in schools. Harvard Educational Review, 84(4), 532-556.Litts, B. K., Kafai, Y. B., Lui, D. A., Walker, J. T., & Widman, S. A. (2017). Stitching Codeable Circuits: HighSchool Students’ Learning About Circuitry and Coding with Electronic Textiles. Journal of ScienceEducation and Technology, 1-14.Lui, D., Walker, J. T., Hanna, S., Kafai, Y. B., Jayathirtha, G. & Fields, D. A. (under review). CommunicatingComputational Concepts and Practices within High School Students’ Portfolios of Making ElectronicTextilesMargolis, J., & Goode, J. (2016). Ten Lessons for Computer Science for All. ACM Inroads, 7(4), 52-56.Michael, M. (2000, May). Fostering and assessing communication skills in the computer science context. ACMSIGCSE Bulletin, 32(1), 119-123.Papavlasopoulou, S., Giannakos, M. N., & Jaccheri, L. (2017). Empirical studies on the Maker Movement, apromising approach to learning: A literature review. Entertainment Computing, 18, 57-78.Paulson, F. L., Paulson, P. R., & Meyer, C. A. (1991). What makes a portfolio a portfolio. EducationalLeadership, 48(5).Phelps, A. J., LaPorte, M. M., & Mahood, A. (1997). Portfolio assessment in high school chemistry: Oneteacher's guidelines. J. Chem. Educ, 74(5), 528.Pinkard, N., Erete, S., Martin, C. K., & Royston, M. M. (2017) Digital Youth Divas: Exploring NarrativeDriven Curriculum to Spark Middle School Girls’ Interest in Computational Activities, Journal of theLearning Sciences, 26 (3), 477-516.Williams, J. M. (2002). The engineering portfolio: Communication, reflection, and student learning outcomesassessment. International Journal of Engineering Education, 18(2), 199-207.Wing, J. M. (2006). Computational thinking. Communications of the ACM, 49(3), 33-35.AcknowledgmentsThis work was supported by a grant # 1509245 from the National Science Foundation to Yasmin Kafai, JaneMargolis, and Joanna Goode. Any opinions, findings, and conclusions or recommendations expressed in thispaper are those of the authors and do not necessarily reflect the views of the National Science Foundation, theUniversity of Pennsylvania, or Utah State University. Special thanks to Tomoko Nakajima for her help withdata collection.ICLS 2018 Proceedings728© ISLS