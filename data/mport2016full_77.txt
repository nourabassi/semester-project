Designing a Data-Centered Approach to Inquiry Practices WithVirtual Models of DensityJonathan M. Vitale, Jacqueline Madhok, and Marcia C. Linn,jonvitale@berkeley.edu, jjmadhok@berkeley.edu, mclinn@berkeley.eduUniversity of California, BerkeleyAbstract: New standards advocate for instruction that combines disciplinary knowledge andscience and engineering practices. In this study we explore the design of an 8th grade sciencecurriculum featuring interactive virtual models and guided graph construction exercises tosupport learning about density and inquiry practices. We apply observations about students’difficulties in the 1st iteration to the redesign of the curriculum. In particular, we observed thatstudents’ often misinterpreted the virtual models or used them inappropriately to confirm priorideas. Similarly, even when guided to construct appropriate graphs, students were unable toconceptually link the abstract representation to concrete conceptual knowledge. On the otherhand, by centering student thinking on the data in the 2nd iteration and using the models toillustrate abstract concepts conveyed in graphs, students were more likely to performappropriate investigations and develop coherent, integrated explanations.IntroductionIn this paper we explore the use of graphs and virtual models to facilitate middle school students’ understandingof density. Both models and graphs are tools used in authentic science practice because they facilitate inquiry andreveal complex patterns. Virtual models have the potential to facilitate systematic testing of ideas with accessible,concrete representations (Smith, Snir, & Grosslight, 1992) when students apply appropriate scientific practices(Perkins & Grotzer, 2005). Graphs can supplement virtual models by highlighting general principles andillustrating complex relationships (Wilkerson-Jerde & Wilensky, 2014). To benefit, students need to translatebetween the abstract features of graphs and the underlying scientific context (Shah & Hoeffner, 2002). Weinvestigate ways to guide students through interactive graph activities that link the concrete features of a modelwith abstract features of a graph to support conceptual development of the concept of density.Student ideas about densityDensity is an important, but challenging concept for children to grasp. Young children rarely differentiate massand volume, thus precluding a notion of density (Kohn, 1993; Piaget, 1972; Smith, Carey, & Wiser, 1985). Olderchildren are able to differentiate mass and volume, but do not immediately comprehend how the relationshipbetween the two determines an object’s buoyancy or is related to the object’s material composition (Snir, 1991).Rather, students generate a variety of ideas that apply to specific situations. Some attribute sinking behaviorexclusively to the mass or weight of an object, others consider mass when size is equal (Howe, 2002; Linn &Pulos, 1983). To address students’ varied ideas, researchers have tried using demonstrations or models thatdirectly contradict intuitive beliefs. For example, a teacher might demonstrate that a large, heavy board of woodfloats, while a small, light pebble sinks. These demonstrations rarely result in long-term impacts because they donot address all of students varied ideas, and because students may lack the ability to generalize from limited cases(Perkins & Grotzer, 2005).Although virtual models allow for rapid testing of multiple conjectures, including the specific ideas heldby the student, they may still pose challenges for generalization. In many cases, virtual models generate similarlearning outcomes as their physical counterparts (Klahr, Triona, & Williams, 2007). Yet, virtual models may addvalue if they offer representations that help students attend to underlying relationships and mechanisms. Forexample, Smith, Snir, and Grosslight (1992) introduced a “grid-and-dots” representation to demonstrate theunderlying mechanism of density (i.e., more dots within a grid box represents higher density). Likewise, graphscan capture general relationships: Rowell and Dawson (1977) presented graphs to depict density as a constantratio between mass and volume. Specifically, 9th grade students were prompted to measure and calculate the massand volume of objects, graph this data, and draw lines of best-fit. In this activity, identical materials are graphedalong a line with a constant slope. Thus, in this case, the graph representation served two functions: as a tool forinquiry and a means to illustrate an important concept. Yet, despite the potential for this activity, nearly threequarters of the students did not recognize that a single, constant-slope line should pass through graphs of identicalmaterials. Whether the graphing representation itself or its deployment in instruction inhibited learning gains isunclear.ICLS 2016 Proceedings591© ISLSKnowledge integration and graphsRegardless of the representations of density, the way student activities are contextualized within a curriculum canhave a substantial impact on learning. For example, in a related study on water displacement Linn and Eylon(2000) found that assigning students to reflection activities had a greater influence on learning than particularfeatures of the model or representations (i.e., level of control). Research suggests that beyond specificrepresentations, a curriculum is successful when it facilitates knowledge integration – i.e., a proactive process bythe learner to resolve disparate ideas and construct coherent explanations (Linn & Eylon, 2011). Curriculumdesigners can support knowledge integration by prompting students to explain their initial ideas, observe newphenomena to generate new ideas, distinguish discrepant ideas, and synthesize their understanding throughreflection (Linn & Eylon, 2011). Virtual models and graphs, particularly with adaptive guidance, can facilitatethis process by highlighting important discrepancies between ideas.Following this framework, interactive computer models and graphing activities can provide alternativeperspectives on the same concepts. Students, therefore have an opportunity to test novel, potentially discrepantideas. Automated assessment and guidance can then be used to challenge student ideas (Vitale, Lai, & Linn, 2015).In this study we explore the initial development and redesign of a curriculum created to introduce virtual modelsand graphing activities with automated guidance to support knowledge integration.Research overviewThe design of the density curriculum was informed by principles of knowledge integration (Linn & Eylon, 2011)and dynamic visualization (McElhaney, Chang, Chiu, & Linn, 2014). To resolve the many open questionsconcerning how best to take advantage of graphing and modeling activities an exploratory research approach wasapplied. Design-based research (DBR) is an emerging methodological perspective that facilitates initial theorybuilding while concurrently addressing instructional goals (Barab & Squire, 2004). Although specific DBRapproaches vary widely, we utilized the following set of assumptions to guide this research:••••While researchers may have initial conjectures, surprises should be expected (Sandoval, 2014).Teacher, researcher, and peer interaction play an important role in learning and should be explored ratherthan minimized (Collins, Joseph, & Bielaczyc, 2004).Due to the surprising nature of DBR, classroom practices and instructional material design should beflexible to emergent circumstances (Collins et al., 2004)Multiple data sources are necessary to analyze complex situations (Barab & Squire, 2004).Guided by these assumptions we implemented the density curriculum in two design iterations to investigate thefollowing research question: how can virtual models and graph activities be designed to mutually support inquiryand learning? We used observational notes and quantitative data to evaluate the effectiveness of our first designand apply what we learned to a re-design. We then implemented this redesign in two classrooms from the sameschool in the following year and compare the learning performances between design iterations.Iteration 1We designed iteration 1 to establish a baseline for performance on instructional and assessment items and todiscover patterns of successful students. We used these results to refine the curriculum.Student and school sampleIteration 1 was conducted with two 8th grade teachers and their 205 students. Ms. S (173 students) had over 20years of science teaching experience. Ms. P. (32 students) was a second year teacher. The school serves a diversecommunity (42% reduced lunch, 13% ELL) in a suburban area of the western United States. Students performedthe pretest and posttest individually. For the curriculum, although students were expected to provide their ownresponses, they were advised to collaborate with an adjacent student.MaterialsAll computer materials, including pretest and posttest were constructed in the Web-based Inquiry ScienceEnvironment (WISE). The main curriculum unit, “Sink or Float”, can be previewed at this link:http://wise.berkeley.edu/previewproject.html?projectId=11723.Pretest and posttestICLS 2016 Proceedings592© ISLSWe constructed a test with 7 multiple choice and 4 open response items (subset coded by two raters, κ’s > .8).Several items prompted students to explain whether specified objects would float, while other items promptedstudents to apply this knowledge to the following graph of mass vs. volume:Mass vs. volume graph interpretation. The graph in Figure 1 displays the mass and volume of 6 pointsrepresenting objects placed in water. Items 3 and 5 target the concept of density as an intensive property ofmaterial. Items 6 and 7 target the relationship between mass-volume ratio and flotation.1.2.3.4.5.6.7.What is the mass of B?• 20• 30• 40• 80What is the volume of B? • 20• 30• 40• 80Which of the following is likely true about A, B, and C?•They are all made out of the same material•They are all made out of different material•I would need more information to tell about materialsWhich of the following is likely true about A, B, and C?•They are all the same shape•They are all different shapes•I would need more information to tell about shapeUsing evidence from the graph, explain your answers to theprevious two questions.The scientist put all six objects in water, she recorded whichones sank and which ones floated. Which objects sank?• D, E, F• A, B, C• A, D, E• B, C, F• C, E, F• A, B, DUsing evidence from the graph, explain your answer.Figure 1. Mass vs. volume graph pre-post items. Correct multiple choice answer are bolded and underlined.Curriculum unit“Sink or Float” was developed to facilitate understanding of density and buoyancy with a series of openinvestigations. In addition to exploratory models and graphs each activity began with relevant prediction questionsand finished with reflection prompts to engage students in knowledge integration.Virtual laboratory. Developed with a popular open source physics engine, the virtual laboratory providedstudents with an open and realistic environment to test ideas (Figure 2). Students were prompted to investigateclaims made by fictional characters (e.g., Aida: “It’s the mass that matters, not the volume.”) by constructingblocks from diverse materials, measuring their mass and volume, and testing if they sank or floated. Data (materialcomposition, mass, volume, and sink/float) was automatically displayed on a following “table-explanation” htmlpage, which prompted students to explain whether the tabular data supported the fictional claim. Later in the unit(following “materials simulation”, Figure 4) this data was re-displayed with density and students were promptedto find a relationship between density and other object features (material composition).Object Building PanelObject Testing PanelFigure 2. Virtual laboratory. In these panels (displayed vertically in curriculum), students construct objects outof various materials, and then test the materials with virtual measurement tools.Mass vs. volume graph construction. Following the virtual laboratory, students were prompted to plotpoints representing objects that would sink, objects that would float, and then draw a line to divide all potentialpoints (Figure 3). Automated guidance was provided to alert students to the number of incorrect points or problemswith their dividing line (e.g., not starting from the origin). Students had unlimited opportunities to revise the graph.Graphs were scored with a knowledge integration rubric (Vitale et al., 2015) that distinguished between 5 levelsICLS 2016 Proceedings593© ISLSof complexity: irrelevant (KI = 1), non-normative (e.g., points divided by horizontal line, KI = 2), partial (pointsdistributed in small, but correct area, KI = 3), full (points distributed widely across correct area, divider not correct,KI = 4), and complex (points correct, divider correct, KI = 5).Sample Correct ResponseSample Incorrect ResponseFigure 3. Students plot points to represent objects that sink (red), float (blue), a line to divide points.Materials simulation. In this activity students explored relationship between mass, volume, density, andbuoyancy of objects made from one of eight materials. Figure 4 displays four questions posed to students as theyengaged the simulation (although we focus on 2 – 4, because 1 could be answered as “mass” or “density”).1.2.3.4.What changes when you switch materials?• Mass• Volume• DensityWhat stays the same as you change the shape of an object?• Mass• Volume• DensityWhat happens why you double the volume of an object (andkeep the material the same)? [M is mass, D is density]• M doubles, D doubles• M halves, D halves• M stays the same, D doubles• M stays the same, D halves• M doubles, D stays the same • M halves, D stays the same• M doubles, D halves• M halves, D doubles• M stays the same, D stays the sameWhich of the following determines how fast an object will sinkor float?• Mass• Volume• Density• WidthFigure 4. Students test properties of objects made from 8 materials, and then respond to questions.AnalysisPretest and posttestOverall, scores from pretest to posttest rose significantly with a medium effect size [t(203) = 7.2, p < .001, d =0.5]; however, focusing on the graph items (Figure 4), the effect size was substantially lower [t(200) = 3.0, p <.01, d = 0.2], suggesting that the curriculum was less effective at promoting learning on the graphing applicationsthan for more general applications (e.g., predicting whether a wooden table would float).Curriculum unitVirtual laboratory. For the “Test Aida’s Idea” (mass determines sinking) step, 163 of 226 students performedvalid work (i.e., constructing at least one object). Of these 163 students only 27% constructed objects that couldfalsify Aida’s claim (i.e., at least one sinking object with mass less than or equal to a floating object).Likewise, on the following table-explanation step, 66% of students (incorrectly) agreed with Aida’sclaim or gave a mass-based explanation for sinking, while only 19% (correctly) disagreed with Aida or gave adensity/material-based explanation for sinking. Of those 44 students who constructed objects that would falsifyICLS 2016 Proceedings594© ISLSAida’s claim less than half (39%) explicitly disagreed with Aida. Even of those that did, only two made explicitconnections between data in the table and Aida’s error.Mass vs. volume graph construction. On their final graph 46% of students produced a graph thatdisplayed an irrelevant or non-normative understanding about the relationship between mass and volume (KI = 1,2), while 39% of students produced graphs with correct, well-distributed points (KI = 4, 5).Materials simulation. In this step 47%, 46%, and 57% of students observed that density changes asmaterials change, remains the same as volume doubles, and determines speed of sinking, respectively.Case studyTo better illustrate the difficulties and affordances of the activities we present the case of a student who was clearlyengaged and made gains from pretest to posttest (> 8 gain points), but nonetheless struggled with the initialsimulation and graphing activities. We used log data to follow this student’s trajectory.Student “Jen”. Jen initially agreed with Aida’s claim (mass determines sinking) and constructed identical8 ml cubes from each of the four materials. By controlling for volume, Jen implemented a special case in whichAida’s claim is true, thus reinforcing her prior belief. As such, on graph construction Jen plotted sink and floatpoints separated by mass, dispersed across the x-axis (like Figure 3, right). After receiving guidance, Jen returnedto the simulation and the table-explanation step, although she did not construct any new objects. She then returnedto the graph step and was able, presumably with guidance, to move points to the correct region of the graph.However, Jen still retained a horizontal dividing line and provided explanations on subsequent reflection exercisesthat demonstrated confusion between mass and density. On the materials simulation Jen correctly identified therole of density in the three target questions. In following steps Jen clearly linked density to materials.DiscussionBoth quantitative and qualitative results indicate that the virtual laboratory did not effectively challenge students’prior conceptions. It is notable that Jen constructed objects of identical volume, but on the graph plotted pointsacross a range of volumes. In this case a misapplied scientific practice (i.e., controlling variables) limited Jen asshe used the model, whereas no such prior knowledge about exploring continuous graphs impeded constructionof more diverse artifacts. Yet, even for those students who generated appropriately diverse objects in the virtuallab, less than half applied this knowledge to contradict Aida’s claim. Conversely, while the graph may haveprovided a stronger alert of an error, the graph construction proved insufficient for generating new ideas. Jen’sreturn to the virtual laboratory after receiving graph guidance suggests that, even though it did not lead to newideas, the concrete model provides a more accessible representation of concepts.On the other hand, the “materials simulation” clearly helped Jen understand the link between materialsand density. This simulation closely integrated the visual model with numerical data, facilitating rapid testing ofideas. This suggests that reframing activities with virtual models to focus students on data representations mayenhance inquiry practices and learning.Iteration 2To implement a data-centered approach to the application of virtual models we performed two major changes tothe curriculum. For the virtual laboratory we randomly assigned either a table or graph in both the prompt (forcritique) and the model output to determine which representation is more effective. For graph construction, tohelp students link the models and graphs, we displayed virtual model that depicted objects represented in thegraph. By comparing the outcomes and behaviors of students in this iteration to those of iteration 1 we test whethergreater model-graph integration facilitates more exploratory behavior and stronger learning outcomes.Student and school sampleIteration 2 was conducted within the same school as iteration 1 in the following year with a new cohort of 239 8thgrade students. This study included Ms. S from iteration 1 (140 students) and a first year teacher (Ms. L, 99students). Unlike iteration 1 students performed the curriculum unit in assigned pairs.MaterialsThe pretest and posttest remained the same as iteration 1. Changes in the curriculum unit are detailed below andcan be previewed at this link: http://wise.berkeley.edu/previewproject.html?projectId=14827.Curriculum unit changesICLS 2016 Proceedings595© ISLSAlthough several minor changes were made, we focus here on changes to steps explored in iteration 1.By merging the affordances of the “materials simulation” to the virtual laboratory and the graph constructionexercise we hoped to make this simulation redundant, and thus removed it from the curriculum.Virtual laboratory. Students were randomly assigned to a model that displayed either a graph (Figure 5)or table displayed below the laboratory during testing and in a pop-up dialog immediately following a completedmeasurement. Additionally to facilitate greater attention to the data and more diverse construction, students werepresented with either a graph or table (matching their output) in the step prompt depicting the non-normativeunder investigation. For example, “Aida’s graph” shows points separated by mass (Figure 5).Figure 5. Virtual laboratory with graph. Students presented with a graphical interpretation of non-normativeidea and prompted to investigate. As students conduct measurements a corresponding graph is displayed.Mass vs. volume graph construction. To help students link data to a concrete representation, we displayeda simple model illustrating the properties of points selected on the graph with a block whose darkness and sizecorresponded to the density and volume, respectively. Additionally, students could drag points to observecontinuous changes in features of the model. Post submission text guidance was similar to iteration 1 (e.g., statingnumber of incorrect points) but prompted students to observe the model.Figure 6. Graph sink and float with linked model displaying properties of selected points on graph. In this case,a point at (8, 28), incorrectly labeled as “Float” (blue), is shown to sink.AnalysisPretest and posttestStudents made large gains from pretest to posttest [t(238) = 12.3, p < .001, d = 0.8]. Compared to iteration 1,students had similar pretest scores [t(441) = 0.7, p > .1], but achieved significantly higher gains in this iteration[t(441) = 3.4, p < .001, d = 0.3]. We found no particular differences between students who received graphs ortables to represent their data; however, this needs further exploration to make any strong conclusions.Curriculum unitVirtual laboratory. For “Test Aida’s Idea” 65 of 120 workgroups constructed objects that could falsify Aida’sclaim. In contrast to the 27% from Iteration 1, this represents a significantly higher proportion [χ2(1) = 20.4, p <ICLS 2016 Proceedings596© ISLS.001]. Additionally, less than half (48 of 117) of the students agreed with Aida’s claim after completing thisactivity, representing a significantly lower proportion than iteration 1 [χ 2(1) = 18.0, p < .001].Mass vs. volume graph construction. Unlike iteration 1, new logging software allowed for a more finegrained analysis of student work. Figure 7 displays score distributions for initial and final graphs produced initeration 2 and the final graphs for iteration 1 for comparison. Final scores for iteration 2 were shifted significantlyhigher (using Wilcoxon for non-normal distributions) than iteration 2 initial scores [V = 716, p < .001].Additionally, the final iteration 2 scores were shifted significantly higher than the iteration 1 final scores [W =8336, p < .001], demonstrating a greater value for the revised, model-enhanced guidance.# WORKGROUPS10080604020012 3 4 5Iteration 1 ­ Final1 2 3 4 5Iteration 2 ­ Initial1 2 3 4 5Iteration 2 ­ FinalSCORE DISTRIBUTIONS [1 ­ 5]Figure 7. Graph construction score distributions, by iteration. Each distribution shows frequency ofeach score from 1 to 5, with modes at 2, 2, and 5, from left-to-right.Classroom observations. In addition to the curriculum changes noted above, Ms. S incorporated newdiscussion activities into her instruction. One such activity was a discussion of “claims, evidence, and reasoning”,where students were asked to discuss each with peers. Ms. S then presented students with an example responsefrom the WISE unit that displayed unclear use of evidence to justify a claim and asked students to rewrite thisresponse and share their new reasoning. As such 52% of Ms. S’s students recognized that Aida’s claim was false,while only 33% of Ms. L’s students arrived at this conclusion [χ 2(1) = 3.1, p = .08].General discussionQuantitative analyses demonstrate significant improvement between iterations that reflect increases in thecoherence of student ideas. Determining the factors leading to improvement is limited by the quasi-experimentalnature of the study. However, the similarity of pretest scores suggests that the two groups of students from thesame school had similar prior knowledge and abilities. Of course, it is unclear whether the improvement was dueto changes in the curriculum or to improved implementation strategies. We suspect a combination of both.Regarding the curriculum, the links between their investigations and the points on the graph clearlyhelped students to better coordinate tests of materials. This resulted in more instances of “falsification” for thesecond iteration than for the first. The teacher-led discussion of claims, evidence, and reasoning likely played arole by defining what is expected as strong evidence to justify or falsify a claim.For the graph construction, the large shift from initial to final graphs demonstrates the value of the linkedmodel. Observation of students revealed a number of new strategies in the revised version of the curriculum,including the production of numerous data points to test diverse possibilities and fill the space of the graph. Somestudents took advantage of the real-time link by dragging points across the graph space and observingsimultaneous changes in the model, thus adding a dynamic component to their use of the graph. Future work willinvestigate these and additional graph interpretation strategies.ConclusionsComputer models are an important tool for scientists and engineers, but can be challenging for middle schoolstudents to use appropriately. Designing models to meet the needs of students requires analysis of their priorknowledge and likely strategies. Students often need new strategies as well as guidance to take advantage of thesetypes of models and conduct effective investigations (McElhaney et al. 2014; Perkins & Grotzer, 2005). In thefirst version of the curriculum students primarily used investigations to confirm their beliefs. In this case therealism and familiarity of the virtual tools may have limited students’ creative expression. The revision of thecurriculum shifted the data representations to a more central role for idea development and used the models in aICLS 2016 Proceedings597© ISLSsupplementary role to illustrate abstract concepts. The gains between iterations suggest that this configuration ledto greater diversity of ideas and stronger links between evidence and theory.More generally, this study suggests that data representations, specifically graphs, represent an importantspace for students to apply, elaborate on, and distinguish between their ideas. The graph used in this study allowedstudents to explore changes in volume and mass systematically. Activities requiring the production andinterpretation of graphs, when carefully designed, compel students to identify general principles and think aboutthe relationship between critical variables (Shah & Hoeffner, 2002). Thus, graphs provide a framework forthinking about models productively.In addition to illustrating specific disciplinary concepts, graphing is an authentic tool that is applicableacross disciplines (NGSS Lead States, 2013). This provides teachers with an opportunity to address sciencepractices explicitly in their instruction using concrete examples from student work. As the discussion of “claim,evidence, and reasoning” given in iteration 2 suggests, this can be an effective way to both encourage moresubstantive investigation in a specific activity and link the activity to more general epistemological themes.ReferencesBarab, S., & Squire, K. (2004). Design-Based Research: Putting a Stake in the Ground. The Journal of theLearning Sciences, 13(1), 1–14.Collins, A., Joseph, D., & Bielaczyc, K. (2004). Design research: Theoretical and methodological issues. TheJournal of the Learning Sciences, 13(1), 15–42.Howe, A. (2002). Engaging children in science. Upper Saddle River, NJ: Merrill Prentice-Hall.Klahr, D., Triona, L. M., & Williams, C. (2007). Hands on what? The relative effectiveness of physical versusvirtual materials in an engineering design project by middle school students. Journal of Research inScience Teaching, 44(1), 183–203.Kohn, A. (1993). Preschoolers’ reasoning about density: Will it float? Child Development, 64(6), 1637–1650.Linn, M. C., & Eylon, B. (2000). Knowledge integration and displaced volume. Journal of Science Education andTechnology, 9(4), 287–310.Linn, M. C., & Eylon, B.-S. (2011). Science learning and instruction: Taking advantage of technology to promoteknowledge integration. New York: Routledge.Linn, M. C., & Pulos, S. (1983). Male-female differences in predicting displaced volume: Strategy usage, aptituderelationships, and experience influences. Journal of Educational Psychology, 75(1), 86–96.McElhaney, K. W., Chang, H.-Y., Chiu, J. L., & Linn, M. C. (2014). Evidence for effective uses of dynamicvisualisations in science curriculum materials. Studies in Science Education, 51(1), 49–85.Perkins, D. N., & Grotzer, T. a. (2005). Dimensions of causal understanding: the role of complex causal modelsin students’ understanding of science. Studies in Science Education, 41(1), 117–165.Piaget, J. (1972). The child’s conception of physical causality. Totowa, NJ: Littlefield, Adams.Rowell, J. A., & Dawson, C. J. (1977). Teaching about floating and sinking: An attempt to link cognitivepsychology with classroom practice. Science Education, 61(2), 245–253.Sandoval, W. (2014). Conjecture mapping: An approach to systematic educational design research. Journal of theLearning Sciences, 23(August 2014), 18–36.Shah, P., & Hoeffner, J. (2002). Review of graph comprehension research: Implications for instruction.Educational Psychology Review, 14(1), 47–69.Smith, C., Carey, S., & Wiser, M. (1985). On differentiation: A case study of the development of the concepts ofsize, weight, and density. Cognition, 21, 177–237.Smith, C., Snir, J., & Grosslight, L. (1992). Models to facilitate using conceptual change: The case of weightdensity differentiation. Cognition and Instruction, 9(3), 221–283.Snir, J. (1991). Sink or float—what do the experts think?: The historical development of explanations forfloatation. Science Education, 75(5), 595–609.States, N. L. (2013). Next generation science standards: For states, by states. Washington, DC: NationalAcademy Press.Vitale, J. M., Lai, K., & Linn, M. C. (2015). Taking advantage of automated assessment of student-constructedgraphs in science. Journal of Research in Science Teaching, Advance on. doi:10.1002/tea.21241Wilkerson-Jerde, M. H., & Wilensky, U. J. (2014). Patterns, probabilities, and people: Making sense ofquantitative change in complex systems. Journal of the Learning Sciences, (May 2015), 1–48.ICLS 2016 Proceedings598© ISLS