Investigating the Impact of an Online Collaboration Course onStudents’ Attitudes and LearningSoniya Gadgil, Maggie Braun, Martha Harty, Ken Hovis, and Marsha Lovettsoniyag@andrew.cmu.edu, mabraun@andrew.cmu.edu, mh51@andrew.cmu.edu, khovis@cmu.edu,lovett@cmu.eduCarnegie Mellon UniversityAbstract: Collaboration and teamwork are critical skills in today’s workplace, but teachingthem effectively remains a challenge. Collaborative U, an online instructional resource thatstudents complete at the start of a major group project, was designed to address this issue. Wepresent results from a randomized controlled trial comparing Collaborative U to a controlcondition equated on format and duration. Students in the Collaborative U condition maintainedtheir initial high positive attitudes towards collaboration from pre to post, whereas students inthe control condition showed a decline. Furthermore, students who completed Collaborative Ulearned more from pre to post and also rated team process and final products significantly higherthan those in the control condition on a variety of attributes. Our findings offer encouragingevidence for the efficacy of a short, online intervention in supporting teamwork skills, and haveimportant implications for integrating team-based activities into classrooms.Keywords: collaboration, teamwork, higher education, open learning, online learningIntroductionThe benefits of learning with one or more peers have been documented extensively in the learning sciences andeducational literature (Johnson, Johnson, & Smith, 1987; Roschelle & Teasley, 1999). Learning collaborativelyhas been shown to benefit students of various age groups, and institutions of higher learning have beenincreasingly integrating collaboration into their classrooms as a way to increase active learning (e.g., Barkley,Cross, & Major, 2014). Engaging in team projects during college years also helps students develop importantskills for today’s workplace, where most will be required to work in teams, as emphasized by several frameworksthat outline key 21st century skills (AAC&U, 2015; Dede, 2006).Despite the myriad cognitive and motivational benefits of collaboration, it does not always yield positiveoutcomes. For example, teams may fall prey to the effects of social loafing (Karau & Williams, 1993), fear ofevaluation (Paulus & Dzindolet, 1993), or production-blocking (Diehl & Strobe, 1987), which may hinder ateam’s productivity. Students sometimes report dissatisfaction with project teams (Barfield, 2009), and worryabout the fairness of their individual grades (Comer, 1995), and instructors may grow weary of troubleshootingcollaborative activities in the classroom (Panitz & Panitz, 1998).In this research, we report results from an online intervention designed to provide students with the toolsto effectively engage in face-to-face collaborative interactions, such as working together on a team project. Thegoals of the intervention were to improve the quality of students’ collaboration by helping them engage inproductive team skills and contribute evenly to a common goal. We describe results from a large-scale randomizedcontrolled trial, in which first-year college students were assigned by section to an intervention group thatparticipated in online instruction focused on improving collaboration skills, or to a control group that received anonline instruction of similar format and duration but not related to collaboration. We investigated the effects ofthe intervention on students’ performance, attitudes, and learning.Background and literature reviewThe term 'collaborative learning' refers to the practice of assigning students to work in teams of two or more toproduce or create something (Dillenbourg, 1999). It is incorporated into college classrooms in a variety of ways,including but not limited to group projects, think-pair-share activities, and peer reviews, among others. However,the degree to which groups are successful differs. Many studies in higher education have found collaboration tobe better than individual learning (see Lou, Abrami, & d’Apollonia, 2001; Springer, Stanne, & Donovan, 1999for meta-analyses), but others have found no difference (e.g., Crooks, Klein, Savenye, & Leader, 1998), and ahandful have found collaboration to be worse than individual learning (see Kirschner, Paas, & Kirschner, 2009for a review).ICLS 2018 Proceedings536© ISLSSeveral studies have found that when students receive collaboration support, it improves theircollaboration, and leads to better outcomes compared to when they collaborate in the absence of support(Weinberger, Stegmann, & Fischer, 2010). Collaboration support may take the form of collaboration scripts(Rummel & Spada, 2005), prompts (Xie & Bradshaw, 2008), guided activities, collaborative argumentation(Asterhan & Schwartz, 2009), workshops, or readings that address collaboration. Some of these strategies arestrongly supported by evidence (e.g., Rummel and Spada, 2005), whereas others have not received strong support(e.g., Rau, Kennedy, Oxtoby, Bollom, & Moore, 2017). In the present work, we took a cognitive task analysisapproach (see Crandall and Hoffman, 2013 for a review) to identify, instruct, and provide practice on several keyskills that team members need. The idea was to promote learning of key skills in the online resource in a varietyof contexts, some designed to be fairly realistic, and immersive experiences, so that students would be able totransfer these key skills to their real-world teams.Learning interventions tested in controlled laboratory settings often show promising results, but whenapplied at scale in larger classroom environments, the effects are frequently not sustained (Elmore, 1996). It isalso difficult to assess the efficacy of such interventions at scale, because implementing randomized controlledtrials in educational settings presents numerous challenges (Cook, 2002). As a result, evidence on efficacy oflearning interventions often falls short of the “gold standard” of randomized controlled trials (Whitehurst, 2003).In this research, we aimed to apply findings from basic research and test our intervention at scale, in the contextof a “gold standard” randomized controlled trial.Present studyWe created an online instructional module that teaches collaboration skills as a form of collaboration support. Wetested its effectiveness thoroughly by delivering it within a randomized controlled experiment, such that one groupof students received our intervention, and the other received a control module of similar duration and format.Students applied those skills in a face-to-face collaborative project that they completed as part of a generaleducation seminar taken by all first-year math and science students at Carnegie Mellon University.MethodCourse descriptionEUREKA! is a seminar-based course that is taken by all first-year students in the Mellon College of Science andis a requirement for graduation. During the seminar, students are exposed to campus resources that promoteacademic and personal success, and they participate in recurring self-assessments that promote personal wellbeing, academic improvement, and ethical decision making. Most pertinent to the current study, students alsowork on team projects focused on a scientific research topic of their own choosing. Students work over much ofthe semester in teams of 3-5 to produce a short video on a research topic of their choosing, and lead an in-classdiscussion/activity as a group. All students took an individual pretest before the online intervention, to assess theirpersonal attitudes towards collaboration and their knowledge of good collaboration practices. An identicalimmediate posttest followed the intervention (also completed individually). At two points during the groupprojects, students rated their peers as well as themselves on contributions to the team. Finally, students wereevaluated on their final products by both their instructors and their peers (see Figure 1 for timeline).Figure 1. Timeline of Activities.Developing the intervention: Collaborative UIn 2015, Carnegie Mellon University made acquiring collaboration and teamwork skills a critical priority for allstudents and a goal of its strategic plan. An interdisciplinary team was assembled around a proposal to buildICLS 2018 Proceedings537© ISLSevidence-based, scalable, faculty-friendly basic training for students involved in group projects. The resultingprototype, Collaborative U, is a 3-hour online instructional module informed by rigorous research and practicalexperience on structuring effective collaborative teams. For example, Woolley and colleagues have shown thatsocial sensitivity and equal participation among members are some of the key factors that improve effectivenessof teams (Woolley, Aggarwal & Malone, 2015). We also leveraged interactive training methods developed andrefined over a decade of training student project teams in traditional face-to-face workshops by collaboration andconflict skills trainers.Figure 2. Screenshot showing one of the “learning by doing” activities in Collaborative U.Collaborative U combines online modules that students work through individually with face-to-facepractice activities performed as teams. Instructors assigned Collaborative U as part of EUREKA! at the start ofthe team projects. Students completed two hour-long units individually online, covering basic diversitycommunication and conflict resolution skills. After each unit, students completed a 20-minute activity in theirproject teams, discussing members’ strengths and differences and practicing skills for navigating conflictsconstructively. The online modules involved an extended video-based interactive scenario for skill demonstrationand practice, and a variety of other realistic practice environments, such as texting and video chats (see Figures 2and 3 for examples).Collaborative U was deployed using the Open Learning Initiative (OLI) platform. OLI is an openeducational resources project at Carnegie Mellon University that allows instructors to develop online coursesconsisting of interactive activities and diverse multimedia content. OLI courses are sometimes deliveredasynchronously without an instructor; in other cases, they are used by instructors to support and complement faceto-face classroom instruction. Studies that compared student learning in a blended (face-to-face plus OLI) courseon introductory statistics to a traditional, face-to-face version of the same course showed that students learnedbetter and in half the time in the blended-OLI format (Lovett, Meyer, & Thille, 2008; 2010).Figure 3: Example of an immersive, real-world activity in Collaborative U.Control conditionICLS 2018 Proceedings538© ISLSLike Collaborative U, the control condition was a set of OLI modules, with a similar format but focused on adifferent topic. The control modules addressed visual design, so there was a reasonable mapping of that instructionto help students make better team products. The in-class activities that teams worked through after the individualunit work were focused on visual design for all students in the control group.Study designWe investigated the impact of Collaborative U on actual team function in a course assignment. The EUREKA!course had thirteen recitation sections, seven of which were randomly assigned to receive the Collaborative UOLI modules, and the remaining six to receive a control OLI resource targeting visual design. Students from bothconditions completed pre/post-tests on teamwork. The time on task was roughly equivalent across groups. Two20-minute face-to-face team activities and discussions were completed in class (focused on either teamwork orvisual design, respectively) so that students could apply what they learned in the OLI modules.ParticipantsParticipants were first-year students enrolled in the EUREKA! seminar at Carnegie Mellon University. 120students completed the Collaborative U module, and 106 completed the control module. The gender distributionacross both conditions was 50-50.Research questionsWe assessed the impact of collaborative support in the form of an online instructional module, Collaborative U,relative to a control module of equal duration on students’ team process, learning, and performance. Specifically,we asked the following questions:1. How does Collaborative U impact students’ attitudes towards collaboration, and their knowledge of goodcollaboration practices from pre to post, compared to control?2. How does Collaborative U impact student’s self-ratings and ratings of their collaborative peers in termsof team process, relative to control?3. How does Collaborative U impact the final team product, in this case, a project video and in-classdiscussion, compared to control?MeasuresPre and post testsBefore and after the intervention, students responded to two five-item questionnaires, on which each item wasrated on a five-point scale, with 1 corresponding to “Strongly Disagree” and 5 corresponding to “Strongly Agree”.These scales measured students’ attitudes towards collaboration and their knowledge of what makes a good team.They also took a conceptual knowledge test on collaboration before and after completing the intervention onwhich they could score between 0 and 4 points.Students’ self ratings and peer ratings of team processStudents rated themselves and their teammates at two time points on the following attributes: promptness andattendance at team meetings, preparedness at meetings, effort level, attitude, helpfulness, content knowledge,effectiveness toward project goals, flexibility, and desirability as a team member. The ratings were on a scale of1-4, with 1 indicating never/ rarely, and 4 corresponding to always. The first peer rating was completed at week11, about 5 weeks into the team project, immediately after the video was due, and the second peer rating wascompleted at week 13, after the teams led in-class discussions.Peer reviews of final project videosEach student used a rubric to grade videos produced by every other team. They rated the videos on a scale of 110 on the following attributes – objective, summarization, clarity, time distribution, interest, audio quality, videoquality, group dynamics, and relevance, and assigned an overall score.ResultsIn this section, we will first present results from pre and post assessments for the Attitudes towards Collaborationand Charactersitics of good team scales, as well as the content knowledge test. We will then describe results fromstudents’ self-ratings and peer ratings of team processes. Finally, we will present results from peer reviews offinal project videos.ICLS 2018 Proceedings539© ISLSPre and post testsOverall, on students’ mean rating on the Personal attitudes towards collaboration scale, there was a marginaleffect of test time, such that both conditions changed significantly from pretest to posttest, F(1, 208) = 2.81, p =.09. Students in both Collaborative U and control conditions showed a marginal decline in their mean scores frompre to post. However, this decline was driven primarily by the control condition (see Figure 4a). Analyses ofsimple effects indicated that the decline from pre to post was marginally significant for the control condition,F(1,208) = 3.68, p = .056.Mean Score out of 5Mean Score out of 5†3.53.02.52.03.53.02.52.0Collaborative UControlCollaborative UControlPretestPosttestPretestPosttest(a)(b)Figure 4. (a) Personal attitudes towards collaboration and (b) Characteristics of good teams.Mean ConcpetualKNoweldge ScoreOn the Characteristics of good teams scale (see Figure 4b), there was no main effect of test -time, F(1, 208) =0.39, ns, indicating that overall, there was no change from pre to post . The interaction between test-time andcondition was not significant F(1,208) = 1.14, ns . Examination of means suggests that students in CollaborativeU showed a slight improvement, and those in the control condition showed a slight decline, however, since themain effects and interaction did not reach significance, follow up tests were not conducted.1.501.000.500.00Collaborative UPretestControlPosttestFigure 5. Performance on content knowledge test.Students also took a conceptual knowledge test on collaboration before and after completing the intervention, onwhich they could score between 0 and 4 points. Figure 5 shows the mean pretest and posttest scores for eachcondition. A repeated measures ANOVA was significant for test-time, F(1,209) = 36.47, p = 0.00, indicating thatall students improved from pre to post. The main effect for condition was also significant, indicating that themeans for the Collaborative U and control conditions were significantly different, F (1, 209) = 4.08, p = 0.04. Atest-time by condition interaction was also significant, F(1,209) = 32.58, p = 0.00. Follow up tests indicate thatthe difference between pretest and posttest was significant for the Collaborative U condition, F(1,209) = 78.26, p= 0.00, but not for the control condition, F(1,209) = 0.049, ns.First peer review and self reviewOn the first peer review that took place in week 11, students in the Collaborative U condition rated their peershigher than those in the control condition on a variety of attributes (see Figure 6). For effort level t(536) = 3.099,p = .002, attitude (t(533) = 2.765, p = .006), helpfulness t(536) = 2.182, p = .029, flexibility t(536)= 3.65, p =.0002, and desirability as a team member (t(536)= 2.91, p = .003), ratings by students in Collaborative U conditionwere significantly higher compared to those in the control condition. The overall rating for team members wasalso significantly higher in Collaborative U compared to the control condition t(536) = 2.03, p = .04. On contentknowledge t(536) = 1.66, p = .09, and effectiveness towards project goals (t(536) = 1.73, p = .08), they wereICLS 2018 Proceedings540© ISLSMean First Peer Review Ratingmarginally higher. On two other measures — attendance and preparedness at meetings, the two conditions werenot significantly different. Interestingly, on self-ratings, students in Collaborative U and control were notsignificantly different on any of the attributes.****4†*†******3.753.53.253Promptness Preparedness Effort Level/attendance at meetingsat teammeetingsAttitudeHelpfulnessCollaborative UContent Effectiveness Flexibility Desirabilityas a teamknowledgetowardmemberproject goalsOverallratingControlFigure 6. First Peer Rating.Second peer review and self reviewMean Second Peer ReviewRatingOn the second peer review that took place in week 14, students in Collaborative U continued to rate their peershigher compared to those in the control condition on several measures. For attitude (t(475) = 1.67, p = .09), contentknowledge t(476) = 1.90, p = .058), and flexibility the difference in rating was marginally significant t(477) =1.85, p = .06), favoring Collaborative U. On ‘desirability as a team member’ the difference was significant t(475)= 3.17, p = .001, again favoring Collaborative U (see Figure 7). On preparedness at meetings, effort level,helpfulness, effectiveness towards project goals, as well as overall rating, the differences were not significant.Just as on the first round of ratings, students in Collaborative U and control did not differ significantly on selfratings for any of the attributes.†††4**3.753.53.253Preparedness Effort Levelat meetings:AttitudeHelpfulnessContent Effectiveness Flexibilityknowledgetowardproject goalsCollaborative UControlDesirabilityas a teammemberOverallratingFigure 7. Second Peer Rating.Peer Reviews of Team ProductsOn ratings of team products demonstrated via team-led, in-class discussions, students in Collaborative U receivedhigher ratings compared to those in the control condition on several measures. On objective (t(842) = 2.05, p =.04), summarization (t(784) = 2.30, p = .02), clarity (t(785) = 2.86, p = .004), time distribution (t(783) = 3.40, p= .0007), group dynamics (t(784) = 3.68, p = .0002), relevance (t(762) = 2.49, p = .01), and overall score t(843)=2.41, p = 0.016, the differences were significant, favoring Collaborative U (See Figure 8). On interest (t (784)=1.68, p = .09), the difference was marginal. Finally, and of note, on audio quality and video quality — attributesnot directly related to collaboration, the two conditions were not significantly different.ICLS 2018 Proceedings541© ISLS9.5*Mean Peer Discussion Rating10***†********98.587.5ObjectiveSummarizationClarityTimeDistributionCollaborative UInterestAudio QualityVideo Quality Group DynamicsRelevanceOverall ScoreVisual DesignFigure 8: Peer review ratings of in-class discussions.DiscussionIn this paper, we describe results from a randomized controlled trial comparing a short online instructional modulefor collaboration support with a control condition equated on format and duration. We found compelling evidencethat completing our instructional intervention had significant impacts on students’ team processes and products.On personal attitudes towards collaboration, students in Collaborative U maintained their initial high scores frompre to post, whereas the control condition showed a significant decline. This result suggests that engaging withthe Collaborative U modules provided an inoculation effect that buffered against the decline experienced bystudents in the control condition. Students in Collaborative U also learned more content knowledge from pre topost. Further, when compared with a control condition, students in Collaborative U rated their peers higher onseveral attributes critical to good team participation. Students in Collaborative U also generated better finalproducts as a result of the team activity, as measured by peer review ratings of various attributes.While our findings are encouraging, we note a few caveats. First, our study was done within the contextof a highly selective private university. In order to be more generalizable, our study needs to be replicated acrossdifferent settings, such as public universities and community colleges. Second, we used peer reviews to rateteammates’ contributions to teams. However, more objective measures of quality of collaboration are available,such as the Collective Intelligence Battery (Woolley, Chabris, Pentland, Hashmi, & Malone, 2010) which wouldbe useful in corroborating the results of peer reviews and project grades. Third, while our study showed anadvantage for the Collaborative U condition on immediate assessments, we need to understand how CollaborativeU affects student attitudes and perceptions of collaboration in the long term, and whether it helps prepare themfor future collaboration opportunities. We are currently pursuing these questions by longitudinally following upa subset of the students who participated in the present study. These robust measures of learning will furthersolidify the evidence that online collaboration support can lead to better learning and collaborative performance.Despite the limitations discussed above, our findings show strong evidence that collaboration support inthe form of an instructional module can improve students’ team performance and their knowledge and attitudestoward collaboration. By comparing it against a time-equated, relevant control condition, we showed that it wasnot simply additional instructional time that explains the superior outcomes for the Collaborative U group. Giventhe increased use of collaboration as a form of active learning in higher education, we believe that our findingshave wide applicability. Delivering the intervention through an online platform makes it easier to implement atscale.ReferencesAsterhan, C. S., & Schwarz, B. B. (2009). Argumentation and explanation in conceptual change: Indications fromprotocol analyses of peer‐to‐peer dialog. Cognitive Science, 33(3), 374-400.Barfield, R. L. (2003). Students' perceptions of and satisfaction with group grades and the group experience in thecollege classroom. Assessment & Evaluation in Higher Education, 28(4), 355-370.Barkley, E. F., Cross, K. P., & Major, C. H. (2014). Collaborative learning techniques: A handbook for collegefaculty. John Wiley & Sons.Comer, D. R. (1995). A model of social loafing in real work groups. Human Relations, 48, 647-668Cook, T. D. (2002). Randomized experiments in educational policy research: A critical examination of the reasonsthe educational evaluation community has offered for not doing them. Educational Evaluation andPolicy Analysis, 24(3), 175-199.ICLS 2018 Proceedings542© ISLSCrandall, B. W., & Hoffman, R. R. (2013). Cognitive task analysis. The Oxford handbook of cognitiveengineering, 229-239.Crooks, S. M., Klein, J. D., Savenye, W., & Leader, L. (1998). Effects of cooperative and individual learningduring learner-controlled computer-based instruction. The Journal of Experimental Education, 66(3),223-244.Dede, C. (2010). Comparing frameworks for 21st century skills. 21st century skills: Rethinking how studentslearn, 20, 51-76.Diehl, M., & Stroebe, W. (1987). Productivity loss in brainstorming groups: Toward the solution of ariddle. Journal of Personality and Social Psychology, 53(3), 497-509.Dillenbourg, P. (1999). What do you mean by collaborative learning?.Elmore, R. (1996). Getting to scale with good educational practice. Harvard Educational Review, 66(1), 1-27.Hart Research Associates (2015) Falling Short? College Learning and Career Success. Washington, DC:Association of American Colleges and Universities (AAC&U).Johnson, D. W., Johnson, R. T., & Smith, K. A. (1998). Active learning: Cooperation in the college classroom.Interaction Book Company, 7208 Cornelia Drive, Edina, MN 55435.Karau, S. J., & Williams, K. D. (1993). Social loafing: A meta-analytic review and theoretical integration. Journalof Personality and Social Psychology, 65(4), 681-706.Kirschner, F., Paas, F., & Kirschner, P. A. (2009). A cognitive load approach to collaborative learning: Unitedbrains for complex tasks. Educational Psychology Review, 21(1), 31-42.Lou, Y., Abrami, P. C., & d’Apollonia, S. (2001). Small group and individual learning with technology: A metaanalysis. Review of Educational Research, 71(3), 449-521.Lovett, M. C., Meyer, O., & Thille, C. (2008). Open Learning Initiative: Testing the accelerated learninghypothesis in statistics. Journal of Interactive Media in Education, 2008(1).Lovett, M. C., Meyer, O., & Thille, C. (2010). In search of the perfect blend between an instructor and an onlinecourse for teaching introductory statistics. Proceedings of the Eighth International Conference on theTeaching of Statistics. Auckland, New Zealand: International Association for Statistical Education.Panitz, T., & Panitz, P. (1998). Encouraging the use of collaborative learning in higher education. UniversityTeaching: International Perspectives, 161-201.Paulus, P. B., & Dzindolet, M. T. (1993). Social influence processes in group brainstorming. Journal ofPersonality and Social Psychology, 64, 575-58.Rau, M. A., Kennedy, K., Oxtoby, L., Bollom, M., and Moore, J.W. (2017) Unpacking “Active Learning”: Acombination of flipped classroom and collaboration support is more effective but collaboration supportalone is not. Journal of Chemical Education, 94(10), 1406-1414.Roschelle, J., & Teasley, S. D. (1995, August). The construction of shared knowledge in collaborative problemsolving. In Computer-supported collaborative learning (Vol. 128, pp. 69-197).Rummel, N., & Spada, H. (2005). Learning to collaborate: An instructional approach to promoting collaborativeproblem solving in computer-mediated settings. The Journal of the Learning Sciences, 14(2), 201-241.Springer, L., Stanne, M. E., & Donovan, S. S. (1999). Effects of small-group learning on undergraduates inscience, mathematics, engineering, and technology: A meta-analysis. Review of EducationalResearch, 69(1), 21-51Weinberger, A., Stegmann, K., & Fischer, F. (2010). Learning to argue online: Scripted groups surpass individuals(unscripted groups do not). Computers in Human Behavior, 26(4), 506-515.Whitehurst, G. (2003). The Institute of Education Sciences: New wine, new bottles. A presentation by IES directorGrover (Russ) Whitehurst. Retrieved from http://www2.ed.gov/rschstat/research/pubs/ies.htmlWoolley, A. W., Aggarwal, I., & Malone, T. W. (2015). Collective intelligence and group performance. CurrentDirections in Psychological Science, 24(6), 420-424.Woolley, A.W., Chabris, C.F., Pentland, A., Hashmi, N., & Malone, T.W. (2010) Evidence for a collectiveintelligence factor in the performance of human groups. Science, 330, 686–688.Xie, K., & Bradshaw, A. C. (2008). Using question prompts to support ill-structured problem solving in onlinepeer collaborations. International Journal of Technology in Teaching and Learning, 4(2), 148-165.AcknowledgmentsThis research was approved by the CMU Institutional Review Board (IRB) under the protocol“Study2016_00000291: Collecting Data on the Impacts of Educational Interventions”. This work was facilitatedby the Teaching as Research service, provided by CMU’s Eberly Center for Teaching Excellence and EducationalInnovation and was supported by a Carnegie Mellon University ProSEED/ Simon Initiative Seed Grant to M.Harty & R. Vituccio.ICLS 2018 Proceedings543© ISLS