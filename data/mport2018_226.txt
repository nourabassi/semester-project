The Quality of Open Online Education and Learning:Towards a Quality Reference Framework for MOOCsChristian M. Stracke and Esther Tanchristian.stracke@ou.nl, esther.tan@ou.nlOpen University of the NetherlandsAbstract: This paper aims to address the quality issues of open online education and learningwith a focus on MOOCs. Specifically, our research goal is to develop a Quality ReferenceFramework (QRF) with quality indicators and tools in close collaboration with all interestedstakeholders worldwide. Based on a rigorous literature review and analysis of existing qualityapproaches and quality indicators for MOOCs, the Global MOOC Quality Survey wasdesigned targeting at three core interest groups: MOOC learners, MOOC designers andMOOC facilitators. A total of n=267 took part in the survey. The survey results werecomplemented with 45 semi-structured interviews with MOOC designers, facilitators andproviders. This mixed method research was selected to provide a more coherent picture andanalysis of the quality issues of MOOCs by investigating them from diverse and differentperspectives. This paper presents first results from the survey and semi-structured interviews,the first QRF draft and the feedback gained from workshops at international conferences.Introduction and theoretical discussionGlobal challenges and changes in the educational and economic front have not only greatly shaped our workingand living conditions, but also affected the way we teach and learn (OECD, 2016). Notwithstanding theindividual process of learning has not completely changed, the contexts and channels of teaching and learningare becoming more diverse (Stracke, 2017a). In particular, educational systems are challenged by changingobjectives and developmental goals to innovate and to open up education (Stracke, 2017b).Within the Open Online Education, Massive Open Online Courses (MOOCs) has undeniably gained astrong foothold in the education arena, in particular, in higher education and lifelong learning (Conole, 2015;Stracke 2017b). The first MOOC came into being in the year 2008 and, since then, the number of MOOCs hasbeen constantly rising (Gaskell & Mills, 2014). A first peak could be discovered in the year 2012 which wascommonly coined, the "Year of the MOOCs" (Daniel, 2012). It gave rise to a growing discourse on the qualityof MOOCs and their value as learning experience and educational tool. This also explains the multitude ofresearch on the quality of MOOCs in the last five years. Reiterating the words of Macleod et al. (2015), “whenone designs any course, one has to have some learner cohort in mind” (p. 9). Researchers on quality of MOOCscaution against discussing quality issues using a specific MOOC type, rather, the quality features of a goodMOOC should take into account the general design principles and good pedagogical practices (Bali, 2014;Daradoumis, Bassi, Xhafa, & Caballe, 2013). Others advocate that research on quality of the learningexperience with MOOCs should consider the given learning situation as well as the core stakeholders involved(Hayes, 2015; Macleod et al., 2015). Hence, this paper seeks to address this longstanding issue on the quality ofMOOCs by investigating the quality indicators of a good MOOC from the perspectives of four core MOOCstakeholders: MOOC learners, MOOC designers, MOOC facilitators and MOOC providers. In this paper, theresearch activities with the interim results are presented to provide a first insight into the varying perspectiveson the quality of MOOCs from the four core stakeholders.Motivation and research backgroundThe quality of MOOCs, and of online education and learning in general, is often questioned. The dropout rate isthe typical measure in traditional distance education courses and in all formal education settings. The samemode of measurement is often applied to MOOCs to determine their quality. The MOOC completion rate isreportedly very low and often under 10 %. Therefore, it saw the first demands for re-booting the design ofMOOCs and the related research for their quality improvement (Margaryan, Bianco, & Littlejohn, 2015; Reich,2015). But this discussion is mainly based on an improper adoption and interpretation of dropout rates. Dropoutrate is a formal evaluation concept from face-to-face education which is not the most appropriate evaluationmethod for MOOCs which engender mostly non-formal learning experiences (Onah, Sinclair, & Boyatt, 2014).Thus, alternative evaluation measures have been proposed and discussed to measure the quality of MOOCs byinvestigating learners’ intentions and goals (Henderikx, Kreijns, & Kalz, 2017; Stracke, 2017b). On the samenote, to address these quality issues, the development of a Quality Reference Framework (QRF) for MOOCsICLS 2018 Proceedings1029© ISLSwas envisaged: An international alliance was established to connect and bring together the key experts andorganizations to collaboratively address the quality of open online learning and education with a focus onMOOCs. Our expectation is that this alliance will demonstrate the potential significance and achieve itsoverarching goal to improve the quality of MOOCs and online education and learning in general.Methodological frameworkA Quality Reference Framework (QRF) for MOOCs is the main long-term objective of this empirical work.This will be achieved by means of both quantitative and qualitative research. To address the quality issues andto facilitate the QRF development, several research surveys and instruments with different methodologicalapproaches were developed and combined. They serve to analyse the current status and to explore the needsfrom different perspectives. First, an in-depth literature review and analysis of existing quality approaches,evaluation instruments and quality indicators for MOOCs were conducted and the findings are currently underpublication. Based on findings from the literature review and analysis of existing quality approaches, the GlobalMOOC Quality Survey was designed and developed in two phases: in phase one, a small pre-survey focusing onlearners’ intentions and personal goals was implemented. There was a total of 45 participants. Findings showedthat most MOOC learners and MOOC designers do not share similar intentions and goals. In phase two, theGlobal MOOC Quality Survey was developed for three target groups: learners, designers and facilitators ofMOOCs. It was conducted with the support of leading international associations and institutions over a period offour months. Table 1 below introduces the constructs that were developed for and used in the Global MOOCQuality Survey and Table 2 presents an overview of all participants from the three target groups and of thesubsets of the participants that responded to the open questions.Table 1: Overview of the constructs developed for and used in the Global MOOC Quality SurveyConstructsPedagogical DecisionsLearning ObjectivesDuration and StructureDuration and InteractionLearning ResourcesLearning SupportFlexibility and InclusionLearning ProgressLearning EnvironmentLearning AssessmentLearning CertificationDesign ProcessOnline FacilitationMOOC learnersXXMOOC designersXXXXXXXMOOC facilitatorsXXXXXXXXXXXXXXXXTable 2: Overview of all participants of the Global MOOC Quality Survey and of the subsets for open questionsAll participantsOpen questionsMOOC learners166117MOOC designers6841MOOC facilitators3327TOTAL267185Semi-structured interviews with MOOC designers, facilitators and providers were also conducted to obtainmore in-depth details and insights. Each interview contains different key questions for the three target groupsand the interview questions are in line with the constructs of the Global MOOC Quality Survey (see Table 3).Table 3: Overview of the interviews with MOOC designers, facilitators and providersKey questionsNo. of InterviewsSummariesICLS 2018 ProceedingsMOOC designers1515 x 1 hour15MOOC facilitators1015 x 1 hour151030MOOC providers1315 x 1 hour15TOTAL3845 x 1 hour45© ISLSIn parallel, several interactive workshops were also organized to obtain more feedback and to initiate in-depthdiscussions at international conferences (see Table 4 below) with the aim to facilitate close collaboration withall interested stakeholders worldwide for the development of the QRF with quality indicators and tools. Table 4provides the overview of the workshop with selected key quality indicators for the MOOC design phase thatgained most attention and discussions in average by the workshop participants.Table 4: Overview of the workshop on the needs and phases for a QRF and related quality indicatorsParticipantsAll questionsKey questionsQRF phasesKey QRFindicators(selected fordesign phase)OE Global 201724YesLearning design& theory,Definition ofsuccess factors,Re-usage offormer coursesEDUCON 201720YesYesYesPedagogy,Templates &story boards,Language, Userexperiences,InteractivityEARLI 201716YesYesUsability andaccessibility,Learning paths,Defined goals,tasks, content &added valueEC-TEL 20174YesYes(not addressed)Interim resultsThe first interim results from the Global MOOC Quality Survey, the interviews and the workshops are presentedbelow.Interim results from the Global MOOC Quality SurveyMore than 250 participants shared their experiences and expertise (n=267) and most of them reported positiveexperiences with MOOCs. However, the experiences with MOOCs vary across the three target groups MOOClearners (n=166), MOOC designers (n=68) and MOOC facilitators (n=33) as shown in the following figures:Figure 1. Learners' experiences.Figure 2. Designers' experiences.Figure 3. Facilitators' experiences.Learners (µ=4.22, σ=.876) rates their MOOC experiences higher than designers (µ=3.99, σ=.855) but a little bitlower than the facilitators (µ=4.30, σ=.529). Our first interpretation is that the designers underestimate theirinstructional design and the MOOC quality whereas the facilitators seem to slightly overestimate theeffectiveness of their facilitation in the MOOC as they may feel responsible for the MOOC facilitation andtherefore tend to indicate a more positive rating. Our in-depth analysis on the other data and correlations (still inprogress) explore all relationships in greater detail.Interim results from semi-structured interviewsTwo main areas addressed by all interviewed target groups (MOOC designers, facilitators and providers) were:The pedagogical design and the learning activities. For the pedagogical design, three critical determinants of thedidactical approaches were highlighted and commonly repeated: Content, learning objectives and learners'profile. For the learning activities within the MOOC, three conditions to support the learning process werehighlighted and commonly repeated: Interaction, feedback and assessment. That is in line with our expectations;however we need more in-depth data analysis. Currently the quantitative and qualitative analysis of theinterviews has just begun started and further results will be available soon.ICLS 2018 Proceedings1031© ISLSInterim results from the four workshopsAlmost all workshop participants (61 out of 62) were positive on the selected fiveprocesses for the QRF (Analysis, Design, Implementation, Learning process andEvaluation; as presented in figure 4) and agreed or fully agreed with them. Thefeedback on the QRF target groups and proposed instruments and tools to support theintroduction and usage of the QRF were diverse and the analysis of the data isunderway. Also, the workshop results will be analysed and evaluated to allow abetter understanding of the feedback from different learning communities attendingthe international educational conferences and participating in our workshops.Figure 4. QRF processes.It can be summarized that the mixed method research combining different data sets and perspectives has led to amulti-dimensional needs and preferences for the QRF development.Conclusions and implicationsThis paper presents the major findings and interim results from the first activities towards the development anddesign of a Quality Reference Framework (QRF) for the improvement of MOOCs and online learning andeducation. The data analysis has just started but the first insights are promising. In particular, the combination ofdifferent methodologies seems to provide a multi-dimensional overview of the needs and preferences of thedifferent target groups.Our vision is to improve and to foster quality in Open Online Education and Learning with a focus onMOOCs which will lead us to a new era of learning experiences. We are developing a QRF for the adoption,design, delivery and evaluation of MOOCs in order to empower MOOC designers and providers for the benefitof MOOC learners. The main goal is the development and the integration of quality approaches, newpedagogical designs and organisational mechanisms into MOOCs with a strong focus on the learning processes,methodologies and assessments. This paper is a first small step towards this ambitious objective to facilitate andsupport better design and delivery of MOOCs in close collaboration with all interested stakeholders worldwide.ReferencesBali, M. (2014). MOOC pedagogy: gleaning good practice from existing MOOCs. MERLOT Journal of OnlineLearning and Teaching, 10 (1), pp. 44-55.Conole, G. (2015). Designing effective MOOCs. Educational Media International, 52 (4), pp. 239-252.Daniel, J (2012). Making Sense of MOOCs: Musings in a Maze of Myth, Paradox and Possibility. [see:http://sirjohn.ca/wordpress/wp-content/uploads/2012/08/120925MOOCspaper2.pdf]Daradoumis, T., Bassi, R., Xhafa, F., & Caballé, S. (2013). A review on massive e-learning (MOOC) design,delivery and assessment. In Proceedings of Eighth International Conference on P2P, Parallel, Grid, Cloudand Internet Computing (3PGCIC), 2013 (pp. 208-213). IEEE Xplore.Gaskell, A., & Mills, R. (2014). The quality and reputation of open, distance and e-learning: what are thechallenges? Open Learning, 29 (3), pp. 190-205.Hayes, S. (2015). MOOCs and quality: A review of the recent literature.Henderikx, M. A., Kreijns, K., & Kalz, M. (2017). Refining success and dropout in massive open online coursesbased on the intention-behaviour gap. Distance Education, 38, pp. 353-368.Macleod, H., Haywood, J., Woodgate, A., & Alkhatnai, M. (2015). Emerging patterns in MOOCs: Learners,course designs and directions. TechTrends, 59 (1), pp. 56-63.Margaryan, A., Bianco, M., & Littlejohn, A. (2015). Instructional quality of massive open online courses(MOOCs). Computers & Education, 80, pp. 77-83.Nyberg, D. (1975). The philosophy of open education. London: Routledge and Kegan Paul.OECD (2016). Education at a Glance 2016: OECD Indicators. Paris: OECD Publishing.Onah, D. F., Sinclair, J., & Boyatt, R. (2014). Dropout rates of massive open online courses: behaviouralpatterns. In EDULEARN14 Proceedings (pp. 5825-5834). IATED Academy: IATED Digital Library.Reich, J. (2015). Rebooting MOOC research. Science, 347 (6217), pp. 34-35.Stracke, C. M. (2017a). Open Education and Learning Quality: The Need for Changing Strategies and LearningExperiences. In Proceedings of 2017 IEEE Global Engineering Education Conference (EDUCON)(pp. 1044-1048). IEEE Xplore. DOI: 10.1109/EDUCON.2017.7942977Stracke, C. M. (2017b). The Quality of MOOCs: How to improve the design of open education and onlinecourses for learners? In P. Zaphiris and A. Ioannou (Eds.), 4th International Conference, Learning andCollaboration Technologies 2017, Part I, LNCS 10295 (pp. 285–293). Berlin, Germany: Springer.ICLS 2018 Proceedings1032© ISLS