Building a Team Leadership Index Through ComputationalMethodsKui Xie, Gennaro Di Tosto, and Lin Luxie.359@osu.edu, ditosto.1@osu.edu, lu.962@osu.eduThe Ohio State UniversityAbstract: To help monitoring and controlling the latent social dynamics associated withleadership, we test a methodological approach that makes use of computational techniques tomine the content of online communications and analyze group structure to identify students whobehave as leaders. The results allow us to quantify each individual's contribution and summarizetheir engagement in the form of a leadership index. The proposed methodology is fullyautomated and has the potential to be easily replicable. The summary offered by the leadershipindex is intended as actionable information that can guide just-in-time interventions to helpsustain student engagement.IntroductionAs pedagogical models for supporting online collaborative learning, structured tasks and peer-moderated onlinediscussions have shown unique benefits (Rovai, 2007). Students often assume leadership roles to facilitatediscussions. They can positively affect the dynamics in their groups by engaging with participants, raisingquestions and advancing problem solving (Zha & Ottendorfer, 2011). The social dynamics in peer-moderatedonline discussions are complex. For example, student leaders can be appointed officially by the instructor (e.g.,Xie, Yu, & Bradshaw, 2014) or can emerge through group interactions (e.g., Wickham & Walther, 2007).However, because students in online educational settings are often physically isolated, these complexprocesses are often latent and not explicitly observed (Xie, Lu, Cheng, & Izmirli, 2017). This makes theassessment of leadership in online group learning critical yet challenging. While some literature has portrayedteam leadership as a set of personal traits (e.g., beliefs, attitude, self-efficacy, and identity), this study focuses onhow leadership is manifested through engagement, communication and interaction. In online learning settings,learners exercise their leadership by initiating conversations, setting group goals, moderating discussions,managing conflicts, monitoring project progress, and evaluating team products (Chang & Lee, 2013). In addition,leadership is often distributed among group members and evolves through members’ active participation in groupprocesses (Spillane, 2005). Even when some specific learners are formally assigned a leading role, others mayalso play informal leadership roles. This shared and distributed perspective directs us to look for the locus ofleadership through learners’ behavior and interaction, rather than their individual mental perceptions.Research on leadership, though, has relied heavily on students’ self-reporting (e.g., Chang & Lee, 2013)or on other qualitative approaches (e.g., Gressick & Derry, 2010) which have methodological and practicallimitations (Greene, 2015). Data tracked in technology-based learning systems afford powerful new analyticalapproaches to uncover the complex processes of group learning interactions (e.g., Xie, Miller, & Alison, 2013;Baker & Inventado, 2014). We propose the adoption of a computational approach, based on natural languageprocessing (NLP) and social network analysis (SNA), for the detection of leadership in peer-moderated onlinecollaborative learning.Study aimWe aim to develop a quantifiable index of team leadership through the mining of corpus data and log data recordedin an online discussion system. Therefore, we situate the definition of leadership in the context of peer-moderatedonline discussions, specifically referring to the individual contributions made online and their effect on groupstructure. Starting from the analysis of the messages logged into the digital forum of an online course, wedeveloped and tested computational techniques capable of identifying patterns of interactions associated withmessages that display elements of leadership.Our objective was twofold: to design a methodology easy to automate and deploy in multiple contextsand to combine our analysis into a single outcome index, capable of reflecting a quantitative summary of students’leadership behavior and providing actionable knowledge for group instructors to sustain students’ engagement.The following research questions guided the design of this study: (a) To what extent can data mining extractlinguistic features to detect leadership in order to minimize human intervention? (b) To what extent can socialICLS 2018 Proceedings905© ISLSnetwork analysis model leadership at an individual level? (c) To what extent does our computational approachprovide evidence of emergent leadership?ContextParticipants were 57 students (gender: males 11, females 46; age: min 19, max 53, median 29) from four sectionsof a mixed-level course at a university in the Southeastern United States. A majority of participants were majoringin education-related disciplines, and their distribution by academic level was: freshmen 4 (7.0%), sophomores 6(10.5%), juniors 18 (31.6%), and seniors 29 (50.9%). They reported their ethnicity as follows: White 31 (54.4%),African-American 21 (36.8%), and Other 5 (8.8%).This 16-week course was offered entirely online and presented students with discussion topics drawnfrom issues related to technology integration in K-12 education. The four sections were taught by the sameinstructor and followed identical learning procedures. Student-led weekly discussions were the major classactivities. In each discussion session, up to two students were appointed as moderators. They designed discussionquestions around the topic of the module, while the rest of the class followed instructions designed by theappointed moderators and participated in asynchronous online discussions. Every student was given anopportunity to lead a discussion session during the semester. The instructor facilitated the first week discussion;students led the remaining ones.MethodsTo address our research questions, we analyzed student online discussions recorded in the university learningmanagement system (LMS). The metadata and text content from 4,083 forum posts constituted the starting input.Data analysis involved two steps, each with its own computational technique.The first analytical step sought to identify and enumerate interactions that exemplify leadership behaviorby processing students’ posting content. To that end, we adopted supervised learning techniques based on naturallanguage processing (NLP) to classify posts in two categories: leader messages and generic discussion messages.Leader messages have the function of moderating interactions, facilitating discussion, or eliciting participationfrom others. They were identified in one of two ways: (1) automatically, assuming that online contributions madeby appointed moderators contain leadership elements (term-based condition); (2) manually, by three researchers,who independently reviewed a random sample of posts and labeled them as either leader or generic messagesusing their best judgement until unanimity in the coding was obtained (label-based condition). As a result, twobalanced datasets were generated, and we refer to them respectively as term-based coding and label-based coding.These datasets were then used to train two binary classifier models, a Logistic Regression model (LR) and anAdaptive Boosting model (AdaBoost), which were applied to probabilistically predict the likelihood of each ofthe remaining posts to belong to the class of leader messages.The second analytical step studied leadership as a personal characteristic displayed by students in theirinteractions. With leader messages resulting from the previous step as input, we used social network analysis(SNA) to quantify the influence students had when communicating with their peers and to define their structuralrelationship. The influence of actors in a social network is a function of the number of connections they have, i.e.their centrality—with eigenvector centrality being a widely-adopted version of this measure and Katz centrality(Katz, 1953) an established variation particularly suited to our domain, characterized by asymmetric networkswith a relatively small number of nodes. Our leadership index, a measure useful in ranking students’ contributionto peer-moderation, is therefore built on Katz centrality values in weighted directed networks connecting thesenders and the recipients of the forum posts identified as leader messages.FindingsThe NLP modules processed a feature vector matrix containing 1,305 posts of appointed moderators and regularparticipants with 3,592 unique words as features. The datasets were split into a training set (90% of the entiredata) and a testing set (remaining 10%). Ten-fold cross-validation was applied to both LR and AdaBoost models.Accuracy, precision, recall, and F1-measure were measured to evaluate the performance of training and testingsteps across the term-based and label-based coding conditions (see Table 1).Table 1: Comparison of coding conditions in the categorization of students’ forum postsTerm-based codingLogistic Regression AdaBoostICLS 2018 Proceedings906Label-based codingLogistic Regression AdaBoost© ISLSCross-ValidationTestingAccuracyPrecisionRecallF1-MeasureAccuracyPrecisionRecallF1-Measure0.7020.6770.7500.7120.6710.7470.6350.6860.5680.6130.5850.5990.7180.7620.6860.7220.7990.8080.7500.7780.8600.9120.8380.8730.6880.8080.5830.6780.7970.8570.7270.787The label-based condition outperformed the term-based condition across both LR and AdaBoost,indicating that a set of leader messages in the first dataset contains more unique linguistic patterns associated withleadership than those in the latter dataset. These results are well within our expectations, since manual codingrequired intensive labor. More interesting for our purposes, though, the promising performances in the term-basedcoding condition justify our assumption that an exogenous factor, such as the mechanism of peer-moderationadopted in our online course, affects student behavior in a consistent way.Social network analysis (SNA) was subsequently used to identify individuals who were central to thenetwork structure and to compare their engagement with that of appointed moderators. Senders’ and recipients’information was used to visualize the leadership patterns for each weekly discussion as recorded by the LMS. Theprobabilistic output of the LR model developed in the previous step was applied to weight the edges in the graph,converting communication networks into leadership networks. Our results highlight that appointed moderators,although influential, are not always the most central nodes. As demonstrated in all networks derived from loggedinteractions, other students emerge as leaders, and SNA can help bring them into focus: they are the emergentleaders our approach aims to identify.To test the validity of the computational approach, we compared classifications determined through theterm-based and label-based coding conditions. We found a positive correlation between the average leadershipindex obtained by each student in these coding conditions: r = .776, t (50) = 8.704, p < .05, which indicates thatthe two conditions are able to capture similar relationships among students. However, term-based coding, whichdoes not require the intensive manual coding of the label-based condition, can provide automatic and real-timefeedback and is therefore preferable. We also looked at correlations between leadership index and engagementmeasures derived from the trace data aggregated at the week level. Table 2 provides the descriptive statistics andthe correlation coefficients. In general, students’ leadership index was significantly correlated with theirengagement measures. These results align with findings from the literature, which suggest that team leaders oftenexercise their influence through active interactions and communications (Xie, Yu, & Bradshaw, 2014).Table 2: Descriptive Statistics of Weekly Engagement and Correlations (N=365)Leadership indexNumber of postsNumber of repliesLength of posts (character)Topics startedTopics readLength of logins (second)Times of loginsMean1.1259.5428.9335816.121.61022.42120134.2490.236Std. Dev.. 1356.4136.1754152.3791.18317.51616122.2567.634Min1103500231898Max2.0825042273328115144997430Correlations withLeadership Index.639*.623*.425*.215*.420*.535*.098The leadership index also allowed us to study emergent leadership over time, observing how studentsresponded to being appointed moderators and clustering students based on their recorded patterns of leadershipto further highlight specific profiles. Using the leadership index scored during the week they were appointed peermoderators as reference point, students were grouped in five clusters, according to the gap-statistics (Tibshirani,Walther, & Hastie, 2001). Patterns in the response to the mechanism of moderation appointment are clearlyvisible: some students were only affected while acting as official moderators (cluster 2); others appeared to carryover that behavior after their turn (cluster 4), while cluster 3 displayed leadership before and up to moderationweek, but disengaged from activities after; clusters 1 and 5 represent students with consistently low andICLS 2018 Proceedings907© ISLSconsistently high leadership. This shows how leadership is a social and developmental process and studentsdevelop their leadership in a variety of ways (Emery, Daniloski, & Hamby, 2011).ConclusionsThis study examined student participation in structured tasks and peer-moderated online discussions as recordedby one course LMS and proposed a novel measure to detect leadership in group learning. Our findings underscorethe dynamic nature of leadership behavior, the result of both an explicit mechanism of appointment to moderatingroles and social dynamics emerging from student interactions. The derived leadership index is the output of amethodology designed to minimize human intervention. Analyzing different linguistic patterns in the context ofpeer-moderated collaborative learning, the resulting classification performs comparably to one produced by threeresearchers manually coding samples from the dataset, a conclusion that highlights the reproducibility of this kindof study in the broader framework of learning analytics.The leadership index is also intended as actionable information, suitable to be incorporated in learningmanagement systems to enhance their reporting and analytical features. A simple but timely signal of the degreeto which a student engages in online discussions could constitute the basis for interventions aimed at helpingteachers to retain and sustain student participation. Our presentation will discuss directions for future research andthe implications of this approach for the fields of learning analytics and online education more broadly.ReferencesBaker, R. S., & Inventado, P. S. (2014). Educational Data Mining and Learning Analytics. In J. A. Larusson & B.White (Eds.), Learning Analytics (pp. 61–75). New York, NY: Springer New York.Chang, W. L., & Lee, C. Y. (2013). Virtual team e‐leadership: The effects of leadership style and conflictmanagement mode on the online learning performance of students in a business‐planning course. BritishJournal of Educational Technology, 44(6), 986-999.Emery, C., Daniloski, K., & Hamby, A. (2011). The reciprocal effects of self-view as a leader and leadershipemergence. Small Group Research, 42(2), 199-224.Greene, B. A. (2015). Measuring cognitive engagement with self-report scales: Reflections from over 20 years ofresearch. Educational Psychologist, 50(1), 14-30.Gressick, J., & Derry, S. J. (2010). Distributed leadership in online groups. International Journal of ComputerSupported Collaborative Learning, 5(2), 211-236.Katz, L. (1953). A new status index derived from sociometric analysis. Psychometrika, 18(1), 39–43.Spillane, J. P. (2005, June). Distributed leadership. In The educational forum (Vol. 69, No. 2, pp. 143-150). Taylor& Francis Group.Tibshirani, R., Walther, G., & Hastie, T. (2001). Estimating the number of clusters in a data set via the gap statistic.Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2), 411–423.Wickham, K. R., & Walther, J. B. (2007). Perceived behaviors of emergent and assigned leaders in virtual groups.International Journal of e-Collaboration, 3(1), 1-17.Xie, K., Lu, L., Cheng, S.L., & Izmirli, S. (2017) The interactions between facilitator identity, conflictualpresence, and social presence in online collaborative learning. Distance Education. 38(2), 230-244.Xie, K., Miller, N.C., & Allison, J.R. (2013). Toward a social conflict evolution model: Examining the adversepower of conflictual social interaction in online learning. Computers and Education, 63, 404-415.Xie, K., Yu, C., & Bradshaw, A.C. (2014). Impacts of role assignment and participation in asynchronousdiscussions in college-level online classes. The Internet and Higher Education, 20, 10-19.Zha, S., & Ottendorfer, C. L. (2011). Effects of peer-led online asynchronous discussion on undergraduatestudents' cognitive achievement. American Journal of Distance Education, 25(4), 238-253.ICLS 2018 Proceedings908© ISLS