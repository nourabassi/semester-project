Mobilizing Learning Progressions for Teacher Use: Examining theUtility of Outside Learning Progressions in Task Co-DesignErin Marie Furtak, University of Colorado Boulder, erin.furtak@colorado.eduKelsey Tayne, University of Colorado Boulder, kelsey.tayne@colorado.eduAbstract: While many learning progressions have been developed in science education, fewstudies have examined the utility of these progressions as tools for teachers in contexts outsideof their original design. This paper is a case study examining how one group of high schoolbiology teachers drew upon two different learning progressions (evolution and carbon cycle)over the course of one academic year as they designed and enacted formative assessmenttasks, and then interpreted responses to the tasks. We find that the progressions were taken updifferently and may have provided central ideas for the curricular units but primarily acted astools for facilitators to frame discussion around student ideas. Our findings suggest theprogressions appeared not to be ready-to-use tools for teachers in these new contexts.IntroductionLearning progressions – representations of the sequential development of student ideas and scientific practiceswithin core content domains (Corcoran, Mosher, & Rogat, 2009) – have been the focus of much scienceeducation research in recent years (e.g. Duschl, Maeng, & Sezen, 2011). Scores of learning progressions havebeen developed across multiple disciplinary core ideas and scientific practices in science, and these progressionshave been developed and used for a number of different purposes, including curriculum design, assessmentdevelopment, and modeling of student growth.Among the lines of research that have developed around learning progressions is a set of studies thathave explored, in a qualitative sense, how learning progressions can serve as tools to support teacher design offormative assessments (Briggs & Peck, 2015), their ability to diagnose student thinking (Furtak et al., 2016),and the ways in which they interpret student response data linked to the progressions (Alonzo & Elby, 2014).These results, while encouraging, have each focused on teachers using learning progressions in contexts closerto that in which they were originally designed, either working with similar curriculum materials (e.g. Furtak &Heredia, 2014) or facilitated by designers of the progression (Alonzo & Elby, 2014). As a result, the field hasfew images from research as to how the multitude of published learning progressions might support teachersoutside of the context of the progressions’ original design and development. This gap in our collectiveunderstanding represents a significant limitation in understanding the scalability of this line of research. Thispaper presents a case study of a group of high school biology teachers working with two learning progressionsto support their engagement in formative assessment task design, enactment, and interpretation.BackgroundWe frame our research from a situative perspective (Greeno, 2006), taking learning as changes in participationin practice, and teacher and student participation in classroom activity as coordinated by sets of tools andresources that embody particular design principles intended to structure participation in particular ways(Akkerman & Bakker, 2011). In the following sections, we provide relevant background to learningprogressions, arguments for using them directly with teachers, and the ways in which learning progressions maysupport formative assessment task design and enactment.Learning progressionsLearning progressions are hypotheses about the ways in which student thinking develops over a period of time(NRC, 2007). Several researchers have identified types of learning progressions, including Wilson (2009),Duschl, Maeng and Sezen (2011), and Lehrer and Schauble (2015). The variations in designs range from thosewith a small (e.g. within one unit) to a large (e.g. across a K-12 span of time) grain size; those that includestudents’ prior experiences and what some might call ‘misconceptions’ and those that focus on the ways inwhich students learn correct ideas in developmental progression; and those that focus on a single dimension ofstudent understanding versus those that are multidimensional (Catley, Lehrer & Reiser, 2005).Regardless of the design features of a learning progression, we emphasize that these progressionsshould not be viewed as developmentally inevitable (Alonzo & Gotwals, 2012), but rather lay out how studentthinking and engagement in practice might unfold in the presence of a particular set of learning experiences,ICLS 2018 Proceedings520© ISLSsuch as a curriculum that takes students through particular stages of understanding. From this perspectivelearning progressions, while likely helpful tools in the development of particular curriculum materials andassessments, likely will not maintain the same meaning when traveling from one locus to another, but will takeup different meanings in new contexts (Star, 2010). In fact, teachers might not perceive learning progressionsdeveloped outside their local context as useful (Furtak, 2012).From this framing, a central question about learning progressions as hypotheses about studentunderstanding and engagement in practice is not whether or not learning progressions are ‘right’ in terms ofcapturing student learning in all contexts, but the extent to which they serve a particular purpose in a givencontext of use (Lehrer & Schauble, 2015). In the case of our own research, we ask questions as to whetherlearning progressions might serve as useful resources for teachers when taken away from the original context oftheir design. Given the amount of resources dedicated to these progressions and the materials they support, it isimportant to address the emergent question of whether progressions offer support when used in new settings,and if so, what kind of activity these resources support. We describe one such possible setting - a teacherlearning community focused on formative assessment design - in the next section.Formative assessment design cycleWe have engaged in a series of projects in partnership with teachers, schools, and districts to examine the waysin which communities of teachers draw upon the information included in learning progressions to informprocesses of formative assessment task design and enactment. We define formative assessment as the tasks andtools that teachers use to elicit student thinking and organize classroom participation structures around attendingand responding to student thinking, as well as the processes in which teachers and students engage to makelearning goals explicit, share thinking, and provide feedback to move learners forward (Bennett, 2011).Our program of research follows assertions made by many in mathematics and science education whoargued that learning progressions, while important tools for researchers, might also support teachers’ classroompractice. For example, Heritage et al. (2009) suggested that learning progressions might help to concretize the‘next steps’ part of formative feedback that can be so elusive to teachers, even once they have diagnosed studentthinking. Similarly, Bennett (2011) argued that a learning progression could help teachers distinguish among theideas students express as they learn. Furtak (2012) suggested learning progressions might serve as frameworksfor teachers to design formative assessments help them interpret and respond to student ideas during instruction.Drawing on these and other studies (e.g. Borko et al., 2008), we developed the Formative AssessmentDesign Cycle (FADC) as a multi-step process that supports teachers in the development of formative assessmenttasks. The cycle begins with facilitators walking teachers through a learning progression to Explore StudentThinking (1), using a learning progression to categorize and interpret student work samples. Next, teachersidentify ideas on a learning progression that they would like to assess during their instructional units, andDesign Tasks (2) to specifically elicit those ideas, anticipate the ways students might respond to the task, andrehearse the types of feedback they would provide to different types of ideas (Horn, 2010). Learningprogressions can provide fundamental support in this step, as they provide a continuum of ideas students mayhold as they progress through a sequence of learning. The fourth step has the teachers Enact Tasks (3) in theirown classrooms, using a learning progression either implicitly or explicitly to interpret student thinking on-thefly. Finally, teachers come back together to Reflect (4) on classroom enactment by looking at student worktogether and using a learning progression to categorize groups of student responses and plan next steps to movestudents forward on the learning progression. This feedback is discussed in multiple timeframes (Wiliam, 2007),such that teachers identify not only what they will do in the next class session, but also how they will draw uponthis information to support students for the rest of the unit, and academic year. At the same time, teachers reflecton the task itself, identifying the extent to which it elicited student ideas on the learning progression, and how itmight be improved and revised for the next year.In this paper, we used previously-developed learning progressions to guide formative assessment taskdesign, enactment, and reflection in the FADC, and collect multiple sources of evidence to respond to thefollowing research question: How did a biology teacher learning community use two learning progressionsduring enactment of the formative assessment design cycle? How can learning progressions originally designedfor other contexts support teachers in the design and interpretation of classroom assessments?MethodThis paper draws on data collected as part of a larger study that explores the way that high school scienceteachers design, enact, and reflect upon formative assessments with the support of multiple learningprogressions. We worked with previously-published learning progressions to support teachers’ formativeassessment design at multiple high schools across content areas. In the present analysis, we focus on the case ofICLS 2018 Proceedings521© ISLSone department of biology teachers at Prospect High as they learned about and used two learning progressionsas part of their FADC work within the context of their 11th grade biology classes: Matter and Energy Cycling inSocio-Ecological Systems (Mohan et al., 2009), and Natural Selection (Furtak & Heredia, 2014).Learning progressionsThe first learning progression, originally developed as part of the Carbon Time curriculum, traced energy andmatter cycling in socio-ecological systems from K-12 and beyond (Figure 1; Mohan et al., 2009). Lower-anchorideas on the learning progression begin with informal accounts that students often have when they enter school,based upon their observations of plants and animals, decomposition, and flames consuming fuel. Levels of theprogression move from more macroscopic observations, plant and animal growth, toward a more microscopicaccount of the molecular processes of photosynthesis, respiration, and combustion. Ultimately, at the top level,students are able to examine the ways in which carbon is involved in these processes at the molecular level.Figure 1. Carbon Time learning progression (Mohan et al., 2009, p. 684).We also worked with the Elevate learning progressions, originally designed for use in high schoolbiology (Furtak & Heredia, 2014). Building Mayr’s framework for natural selection (Mayr, 1982), the Elevateprogressions integrate ideas from ecology (e.g. biotic potential and population stability), genetics (variation,inheritance), and the consequences of those ideas on differential survival and reproduction of individuals withinpopulations over long periods of time (Figure 2). The vertical levels represent how student thinking can developover time, from lower-anchor ideas students bring to school toward upper-anchor, scientifically-accepted ideas.Figure 2. Natural selection learning progression (Furtak et al., 2016, p. 274).ParticipantsThe five participants in this study were all of the teachers responsible for one or more biology courses atProspect High in the 2016-2017 academic year. These teachers ranged from 3-19 years of classroom experience,and all had college degrees in biology. We were also participants in the community as facilitators. The firstauthor is a former high school biology teacher who has supported science teachers in formative assessmentdesign and enactment for more than a decade. The second author has a background in K-12 informal scienceand environmental education and previously worked with teachers on climate change education.Professional development approachThe authors, either together or separately, met with the biology teachers at their school twice each month duringthe 2016-2017 academic year to introduce the learning progressions, guide the process of formative assessmenttask design, and provide structure as teachers categorized student work samples and identified next instructionalsteps. The meetings were designed to follow the Formative Assessment Design Cycle as described above.ICLS 2018 Proceedings522© ISLSSources of dataWe used multiple sources of data to triangulate our findings for this paper, which reflect our experiences at 11different on-site meetings at Prospect High school year. Our primary source of data is in-depth fieldnotescreated by the two authors at each of these meetings. We also kept copies of teacher learning communitymeeting agendas, the two learning progressions, copies of teacher-designed formative assessments, and copiesof student work. We also took pictures of teacher-created artifacts during on-site meetings. In addition, weconducted interviews with teachers in which we explicitly asked them about their impressions of the learningprogressions and how they supported their diagnosis of student thinking.Analytic approachWorking with fieldnotes and transcribed teacher interviews, the second author developed an initial, open codingapproach in which she identified general themes and patterns in the data focused on the ways that teachers usedthe learning progressions to support their task design. Both authors then met together to discuss these themesand patterns, and then developed a research memo format that would inform the next pass through the data.Both authors then read and analyzed all fieldnotes, creating separate research memos that summarized the waysin which the learning progressions were used in the different phases of the FADC and, as an additional step tosearch for disconfirming evidence of instances in which the learning progressions could have been used, butwere not. These memos were created at a low level of inference and were cross-referenced with the data tocreate an audit trail. The authors met and discussed the memos in detail, and the second author also pulledteacher responses to interview questions specifically about the learning progressions to discuss and triangulatewith the data. During these discussions, the authors recorded all of their adjudicated claims, and kept notes onoverarching themes that emerged from the data. We then used these memos to create drafts of our resultssection, following Erickson’s (1986) guidelines for particular description and general commentary.ResultsTeachers’ formative assessment task design work spanned 11 meetings across the academic year, with a focuson the matter and energy cycling progression in the fall semester, and the natural selection progressions in thespring. This timing was dictated by teachers’ usual progress through the SEPUP curriculum, the adoptedcurriculum resource at Prospect High. We present our findings according to the teachers’ focus on each learningprogression individually, and then draw contrasts and comparisons across the progressions.Matter and energy cycling: The ‘Carbon Time’ learning progressionThe first learning progression we used with the teachers, the Carbon Time progression, was intended to supportteachers’ formative assessment task design and enactment in their fall ecology unit. This process began in theExplore student ideas phase with teachers first developing what we called a ‘local scope and sequence’, whichthey created to represent the sequence of concepts and activities they taught with the support of the SEPUPcurriculum. Although the university-based facilitators introduced the learning progression to the teachers in anearly meeting, the teachers did not use it directly to adapt or revise this scope and sequence document. Mostly,the facilitators used the learning progression to support a discussion of student ideas as a range or spectrum, notjust right or wrong answers. At Meeting 2, a facilitator described the learning progression to the group as a wayof understanding where students’ ideas are and supporting students in developing new ideas. At Meeting 3, afacilitator referred to the Carbon Time learning progression as having significant “upward freedom” forassessment purposes because of the wide range of ideas that the learning progression presents.As the semester unfolded, the facilitators moved teachers into the design formative assessment tasksphase, and teachers created two activities to use in their classrooms, both adaptations from the resourcesdesigned as part of the Carbon Time curriculum. Facilitators had reviewed items from the assessment linked tothe Carbon Time curriculum prior to the meeting, and selected possible tasks to share with the teachers. One ofthese tasks consisted of questions about energy and matter in a burning match, and the other included questionsabout matter and energy cycling in a tree. Despite these materials’ link to the learning progression, there was noexplicit reference to the progression itself when teachers were adapting the tasks for use in their classrooms inour meetings together. For example, in the iterative design of the Energy and Matter in an Oak Tree formativeassessment, teachers discussed the value of having multiple questions that addressed a similar scientific idea sothat teachers can better understand what students are thinking. In the final version, shown in Figure 3, studentswere given several inputs (air, sunlight, water, soil) and asked where the mass is coming from as an oak treegrows from an acorn and where energy is coming from. Students were asked to circle if most, some or none ofthe mass/energy came from those inputs.ICLS 2018 Proceedings523© ISLSFigure 3. A task for matter and energy cycling, teacher-designed “Oak Tree” task on the left and a formativeassessment task for natural selection unit “Peppered Moth” task (Furtak, 2012) on the right.Teachers then enacted these tasks with students and brought student work samples back to a meeting toReflect and Identify Next Steps. Margaret brought a copy of the Carbon Time progression to help her sortstudent work, noting that she had already tried to use it to make piles of student work but wasn’t able to alignthe categories in the progression with the student responses to the Burning Match task. We encouraged her towork with her colleagues to develop their own system for making piles of student work that made sense to them.While one pair of teachers made just two piles – those that were right and wrong – the other groups made moredescriptive categories, including “matter consumed,” “matter transformed/converted,” and “into air/smoke.”They then discussed instructional supports that might be provided for the students in each category, drawing onthe categories they had created. Later, when teachers interpreted student response patterns to the Energy andMatter in an Oak Tree task, teachers and facilitators created piles of student work again but did not reference orattempt to use the Carbon Time learning progression to do so. In discussing formative assessment design andenactment in one particular meeting, a facilitator referenced the learning progression saying that a writtenartifact can be compared back to the learning progression. Despite the challenge to use the learning progressionto sort student ideas, teachers indicated that creating the piles and sorting student data was valuable for theirpractice. One teacher shared that she did not feel that the sorting process was valuable at first but that afterwardsit helped her to better understand specific student responses so she could support her students.Natural selection: The ‘Elevate’ learning progressionWe began Setting Learning Goals and Exploring Student Ideas for the Evolution unit in the spring semester byintroducing the natural selection learning progression at Meeting 8, and then supporting teachers in adaptingtheir own local scope and sequences for the natural selection unit at Meeting 9. The teachers had multipleseparate scopes and sequences they created as part of this process which, they later reflected in interviews, werelikely influenced by the Elevate progressions. That said, like the Ecology planning process, teachers did notdirectly use the Elevate progressions to create their scope and sequences, but rather formed these on the basis oftheir prior instructional approaches and curriculum materials. Teachers discussed student ideas about howorganisms change in response to the environment, a common misconception in this domain (Shtulman, 2006),but they did so prior to examining how these ideas were incorporated into the learning progression.Teachers also explored student ideas about natural selection by analyzing student responses (collectedfrom another school) to a formative assessment task developed as part of a previous study (Furtak, 2012), andwatching a video of high school students discussing their responses to that task. Facilitators asked teachers tocreate a spectrum of student ideas from what they felt were more correct to less correct. In this conversationneither the facilitators nor the teachers readily referred back to the learning progression for this activity.Next, as teachers and facilitators Designed and revised formative assessment tasks, they used a varietyof resources including the Elevate progressions, state and district standards, activities they had used in the past,their textbook, and a concept map of the big ideas covered in the unit developed by one of the teachers.Teachers considered designing a sequence of formative assessment tasks around the Elevate progressions tohelp them decide where to put the tasks in the sequence of their unit, but ultimately did not end up creating anyformative assessment tasks this way. After reviewing several possible tasks to use with the teachers in thisphase, the facilitators selected a task from a prior study as it was relatively simple, they had student responseICLS 2018 Proceedings524© ISLSdata for it to examine, and could also share video of teachers using it with students. Ultimately, they used thetask facilitators had provided them without changing it – the Peppered Moth, shown in Figure 1 - and anothertask, Climate Change Extinction, developed after teachers looked at the results of the Moth Task.Similar to the carbon cycle unit, when reflecting on enactment, teachers analyzed student data from thePeppered Moth formative assessment by creating multiple piles of student responses based on student responsedata, not the learning progressions. Piles were related to students expressing ideas about organisms being able tochange themselves, or ideas about differential reproduction. These ideas, which are related to the Elevateprogressions, were developed from the task itself, but by explicitly using the Elevate progressions.Cross-case analysis: Relative utility of progressions in supporting task designTeachers described the learning progressions as a “menu” or something to provide “benchmarks” for the unit asthey designed formative assessment tasks. While all of the teachers mentioned the Elevate progressions, onlyone mentioned the Carbon Time progression, likely because we interviewed teachers at the end of the year whenthey had just used the Elevate progressions. Ron felt the Carbon Time progression was less clear; when askeddirectly about the Carbon Time progression, Jim noted that there just hadn’t been enough time to use it, saying“we weren’t able to experiment with the carbon time stuff just because the time constraints are nutty.”Teachers explicitly pointed to the Elevate progressions as a source of big ideas. Erika reflected that,“We used the evolution one that you guys showed us, where it showed us how it would develop over time and Imean, really we just kind of made a list of what were the big ideas.” Sarah also described the Elevateprogressions as supporting her in thinking about student ideas and how these ideas progress through a unit,stating, “I think it’s useful to know where the students should be and then where we can take them with thatwork, the learning progression like, what, how do they follow that and where should they be at the end so thatwe can go back and see what we need to know from them in the beginning and then base our curriculum on that,or what we’re going to teach on that.” However, teachers’ descriptions of the learning progression as a resourcefor considering big ideas was somewhat vague. For instance, when asked about what features a teacher foundmore and less useful, Jim responded, “Well, the evolution [progressions], I don’t have the specifics, I’d have totake that out of the Google Drive, but it was a good introductory start.”Ron suggested the Elevate progressions had influenced his classroom practice, noting that “I spentmore time on the struggle for survival this year versus other years, basically making that connection betweenoverproduction of everything from insects to elephants and that builds in a struggle for survival.” In terms ofhow the Elevate progressions supported unit design and sequencing, Sarah said that it broke down “…what[students] would need to know first, like natural selection, and then they understand that and what they need toknow about that to get to the end point.” Ron mentioned the challenge of not having specific lessons to connectto the learning progression, noting that he felt the progression needed “…to be put in context of a lesson thatwould be delivered and tied to it so that there is a clear lesson formative matching. If you have the formative butthere’s no lesson attached to it, then you’re going to have to cobble together a lesson.”DiscussionTaken together, our case analysis – while admittedly with one school and a small sample of teachers – suggestssome areas in which the progressions were directly useful to teachers, and other areas in which they could havebeen used but were not. We first summarize these main conclusions, and then identify future areas for research.Lack of alignment between progressions and local scope and sequenceThe SEPUP curriculum in place at our partner high school was built on the concept of spiraling, where coreideas re-occur throughout a year of study, and are treated with increasing complexity as the school yearprogresses (Bruner, 1961). In this environment, teachers created scopes and sequences to guide their instructionthat were more tied to the curriculum materials they were accustomed to using, rather than adapting them to thelearning progressions. Since many learning progressions are developed with the intention of supporting aprocess of curriculum design, this finding may only be an issue when teachers are using resources developedwith a learning progression to supplement other instructional resources created with other designs andprogressions in mind. Ultimately, given the piecemeal approach that many high school teachers take whenselecting materials from multiple sources to support their instruction of different core ideas, a lack of alignment– whether real or perceived - between teachers’ current curriculum materials and those associated with learningprogressions may ultimately limit the ways in which progression-based resources are adopted in classrooms.Suites of tools to support teacher practiceICLS 2018 Proceedings525© ISLSWe note that in both units we studied, the teachers used one formative assessment task that was provided tothem as part the learning progression resources, and then adapted materials to create a second formativeassessment task. In each case, the tools were taken up into classroom use without direct reference to the learningprogressions, and the progressions were also not used directly to interpret student responses. Given perspectivesabout how teachers need suites of related tools to support their implementation of new instructional practices(Thompson, Windschitl & Braaten, 2013), this suggests that while learning progressions themselves may notalways be directly useful to teachers, providing teachers with resources linked to the progressions might help tosupport them in instructional approaches related to the ideas the progressions contain. When teachers weresorting student responses to the Moth Task, for example, teachers created piles based on the student responsesthemselves, but these piles were directly related to the learning progression given the close link between thestructure of the Moth task and two of the Elevate progressions.Learning progressions as meditational tools for facilitatorsAlthough the learning progressions themselves were not directly used in the ways we might have expected, weacknowledge that they did inform the ways in which facilitators described student thinking as a spectrum,pushing beyond binary framing of student ideas. Furthermore, the progressions guided the facilitators inselecting instructional resources to use to inform formative assessment task design (the Burn Match andPeppered Moth). In this sense, the tools mediated the work of the facilitators and the teachers, suggesting anadditional use for these resources: as tools to guide the design of professional learning experiences for teachers.Grain sizeThere were a number of key differences between the learning progressions, namely that the Carbon Timeprogression spanned multiple years of student learning, whereas the Elevate progressions represented studentthinking as it might unfold within a unit of instruction in one year of a high school course. Teachers found theElevate progressions more directly useful in informing their planning; however, this might be because therepresentation of the Elevate progressions was more closely related to the types of scope and sequences theyused to plan units, rather than having such a zoomed-out view on student learning. Our study, while small andexploratory, suggests that the progressions that now underlie the NGSS may also be difficult to translate intodirect action as teachers design and interpret tasks. Such progressions will need additional tools and resourcessuch as sample tasks, rubrics, or other interpretive frameworks to be useful at the classroom level.Conclusion and future directions for researchUltimately, our study generates several questions about future directions in bringing learning progressionsdirectly to teachers. First, it points to the importance of considering learning progressions as belonging to sets ofresources, all of which might support teacher learning and task design. It also tempers our expectations aroundthe extent to which learning progressions in and of themselves are directly useful for teachers, and suggests thatfuture researchers may consider how they can inform the design of teacher activities in professional learningexperiences. From this perspective, although learning progressions might continue to be developed, we maycome to reposition them in the field – rather than an end in and of themselves – as a representation of cognitionthat then serves a foundation for the design of subsequent resources (e.g. Pellegrino, Chudowsky & Glaser,2001), and then these sets of resources could travel to new contexts, rather than the progressions in and ofthemselves. Finally, in engaging in learning progressions research, our findings suggest that researchers need toconsider the contexts, implications, and potential uses of the progressions they create in order to strive toproduce research that has meaningful implications for use in guiding science teaching, learning, and assessment.ReferencesAlonzo, A.C. & Elby, A., (2014). The Nature of Student Thinking and Its Implications for the Use of LearningProgressions to Inform Classroom Instruction. In Polman, J. L., Kyza, E. A., O'Neill, D. K., Tabak, I.,Penuel, W. R., Jurow, A. S., O'Connor, K., Lee, T., and D'Amico, L. (Eds.). Learning and becoming inpractice: The International Conference of the Learning Sciences (ICLS) 2014, Volume 2. Boulder, CO:International Society of the Learning Sciences.Alonzo, A.C. & Elby, A., (2015). One Physics Teacher’s Use of a Learning Progression to Generate Knowledgeabout His Students’ Understanding of Force and Motion. Paper presented at the Annual Meeting of theAmerican Educational Research Association, Chicago, IL.Alonzo, A. C., & Gotwals, A. W. (2012). Learning Progressions in Science. (A. C. Alonzo & A. W. Gotwals,Eds.). Rotterdam, The Netherlands: Sense Publishing.ICLS 2018 Proceedings526© ISLSAkkerman, S. F., & Bakker, A. (2011). Boundary crossing and boundary objects. Review of EducationalResearch, 81(2), 132–169.Bennett, R. E. (2011). Formative assessment: A critical review. Assessment in Education: Principles, Policy &Practice, 18(1), 5–25.Borko, H., Jacobs, J., Eiteljorg, E., & Pittman, M. (2008). Video as a tool for fostering productive discussions inmathematics professional development. Teaching and Teacher Education, 24(2), 417–436.Bruner, J. (1960). The Process of Education. Cambridge: Harvard University Press.Catley, K., Lehrer, R., & Reiser, B. (2005). Tracing a Prospective Learning Progression for DevelopingUnderstanding of Evolution. Paper Commissioned by the National Academies Committee on TestDesign for K-12 Science Achievement.Corcoran, T., Mosher, F. A., & Rogat, A. (2009). Learning progressions in Science: An evidence-basedapproach to reform. Philadelphia, PA: Consortium for Policy Research in Education.Duschl, R., Maeng, S., & Sezen, A. (2011). Learning progressions and teaching sequences: A review andanalysis. Studies in Science Education, 47(2), 123–182.Erickson, F. (1986). Qualitative methods in research on teaching. In M. C. Wittrock (Ed.), Handbook ofResearch on Teaching (pp. 119–161). New York: Macmillan.Furtak, E. M. (2012). Linking a learning progression for natural selection to teachers’ enactment of formativeassessment. Journal of Research in Science Teaching, 49(9), 1181–1210.Furtak, E. M., & Heredia, S. C. (2014). Exploring the influence of learning progressions in two teachercommunities. Journal of Research in Science Teaching, 51(8).Furtak, E. M., Kiemer, K., Circi, R. K., Swanson, R., de León, V., Morrison, D., & Heredia, S. C. (2016).Teachers’ formative assessment abilities and their relationship to student learning: Findings from a fouryear intervention study. Instructional Science, 44(3).Greeno, J. G. (2006). Learning in Activity. In R. K. Sawyer (Ed.), The Cambridge Handbook of the LearningSciences (pp. 79–96). Cambridge: Cambridge University Press.Heritage, M., Kim, J., Vendlinski, T., & Herman, J. (2009). From evidence to action: A seamless process informative assessment? Educational Measurement: Issues and Practice, 28(3), 24–31.Horn, I. S. (2010). Teaching replays, teaching rehearsals, and re-visions of practice: Learning from colleagues ina mathematics teacher community. Teachers College Record, 112(1), 225–259.Lehrer, R., & Schauble, L. (2015). Learning progressions: The whole world is NOT a stage. Science Education,99(3), 432–437.Mayr, E. (1982). The growth of biological thought: Diversity, evolution, and inheritance. Cambridge, MA: TheBelknap Press of Harvard University Press.Mohan, L., Chen, J., & Anderson, C. W. (2009). Developing a multi-year learning progression for carboncycling in socio-ecological systems. Journal of Research in Science Teaching, 46(6), 675–698.National Research Council. (2007). Taking science to school: Learning and teaching science in grades K-8.Washington, D.C.: National Academies Press.Pellegrino, J. W., Chudowsky, N., & Glaser, R. (2001). Knowing what students know: The science and design ofeducational assessment. Washington D.C.: National Academies Press.Penuel, W. R., Fishman, B. J., Haugan Cheng, B., & Sabelli, N. (2011). Organizing research and development atthe intersection of learning, implementation, and design. Educational Researcher, 40(7), 331–337.Smith, J. P., DiSessa, A. A., & Roschelle, J. (1993). Misconceptions reconceived: A constructivist analysis ofknowledge in transition. The Journal of the Learning Sciences, 3(2), 115–163.Star, S. L. (2010). This is not a boundary object: Reflections on the origin of a concept. Science, Technology &Human Values, 35(5), 601–617.Thompson, J., Windschitl, M., & Braaten, M. (2013). Developing a theory of ambitious early-career teacherpractice. American Educational Research Journal, 50(3), 574–615.Wiliam, D. (2007). Keeping learning on track: Classroom assessment and the regulation of learning. In J. F. K.Lester (Ed.), Second handbook of mathematics teaching and learning (pp. 1053–1098). Greenwich,CT: Information Age Publishing.Wilson, M. (2009). Measuring progressions: Assessment structures underlying a learning progression. Journalof Research in Science Teaching, 46(6), 716–730.AcknowledgementsThis material is based upon work supported by the National Science Foundation under Grant No. 1561751. Anyopinions, findings, and conclusions or recommendations expressed in this material are those of the authors anddo not necessarily reflect the views of the National Science Foundation.ICLS 2018 Proceedings527© ISLS