Visualizing Complex Classrooms Through Real Time ObservationsJoey Huang, Andrea Gomoll, Erin Tolar, Cindy Hmelo-Silver, and Selma Sabanovichuang220@indiana.edu, agomoll90@gmail.com, etolar@umail.iu.edu, chmelosi@indiana.edu,selmas@indiana.eduIndiana UniversityAbstract: Analyzing video data is a complex problem for social science researchers. Thisstudy explored the use of an analytical visualization method to support the process ofnarrowing a video data corpus—focusing on meaningful moments for further qualitativeanalysis. We used the real-time observational coding tool to examine students’ activities andengineering design practices in a STEM curriculum. The findings suggest that using this toolsupports time-efficient analyses of large corpuses of video data.Keywords: visualization, video analysis, engineering design, human-centered roboticsIntroductionVideo data is one of the most complex types of data in empirical social sciences research, making it challengingto work with (Mondada, 2006). Even a few minutes of recording includes a massive quantity of information,such as visual, acoustic, and gestural data that needs to be transcribed and coded for analysis. Video thus createsissues of data management, retrieval, and selection for researchers. In particular, methodological and practicalquestions arise when trying to balance micro and macro-levels of analysis (Knoblauch et al., 2006). Becausevideo analysis is so time consuming, it may not be useful for timely feedback during instructional interventions.To address issues of managing timeliness and balancing micro- and macro-analytic approaches toanalyzing video data, this study investigated the use of a real-time observational coding tool called theGeneralized Observation Reporting Protocol (GORP; UC Davis Center for Educational Effectiveness, 2016).GORP is a web-based system that allows observers to record data using a customizable interface (see Figure 1).The coded data are systematically stored and organized in the cloud for future analysis. GORP allows users togain an overview of the class activities and track aspects of students’ learning activities. We tested this in ahuman-centered robotics (HCR) curriculum that focuses on the design of robots to serve human needs, thushelping learners make connections between the social and technical aspects of science and engineering (Schaal,2007; Gomoll et al., 2017). Specifically, we captured students’ collaborative activities as they engaged in HCRdesign processes (Gomoll et al., 2016). This poster presents our use and analysis of GORP data to supportiterative video analysis—moving from the high-level picture of group engagement to the finer-grained analysisof specific video segments that highlighted collaborative activities and engineering design practices.MethodsData were collected from public schools in two U.S. states. Participants included ten eighth graders and sixseventh graders taking an elective science class in a public middle school. The inquiry-based HCR unit tookplace over five weeks with 35-50 minute daily class sessions. We videotaped and observed two focal groupswith two males and two females per group. The coding scheme included two major categories and a total of tencodes (see Figure 1): 1) Student actions (e.g., solo work, hands on material, off-task) (purple codes), and 2)Engineering Design practices (e.g., ask questions, imagine, collection information) (green codes). One observerper focal group coded in three-minute increments. Within a three-minute increment, each code in Figure 1 couldbe applied once. All observers achieved inter-rater reliability above 85% on a 60-minute classroom video from aprevious implementation before entering the classroom to code.Using the output of the GORP coding, we constructed a visualization, the Chronologically-OrderedRepresentation of Discourse and Tool-Related Activity (CORDTRA) to help us move from macro- to microlevel of analysis (Hmelo-Silver et al., 2011). CORDTRA diagrams provided visual representations which canaid in interpreting complex patterns and analyzing students’ activities in collaborative learning environments.CORDTRA analysis included the real-time codes that quantify different types of learning activities. This createsa chronological picture in which multiple processes were represented in parallel on one timeline (see Figure 2).We created the CORDTRA diagrams to provide macro-level visualizations of our GORP coding results.ICLS 2018 Proceedings1609© ISLS78910111213141516Figure 2. An excerpt of CORDTRA output (21minutes period) of two students from Focus Group1 at the Designing Robot Bodies class session.Figure 1. GORP interface displayed on asmartphone, tablet, or laptop (green codes: studentactions; purple codes: engineering design practices).FindingsUsing CORDTRA visualizations to explore GORP data, we were able to highlight specific patterns of designpractices across our robotics unit and to pinpoint moments for further exploration in video and interactionanalysis data sessions. The CORDTRA diagrams were generated quickly via R programming software andprovided a macro level picture of all engineering design codes occurring for each student group in smallincrements of time. Figure 2 shows an excerpt of two students’ activities and engineering design practices in oneclass section in which we identified rich collaboration and use of engineering design practices while they builttheir robots. Through the analysis of the GORP coding, we were able to zoom in to deepen our exploration ofpatterns of students’ collaborative engineering design practices throughout the HCR curriculum. For instance, ifwe are interested in understanding how the engineering design practices, such as collect information, wereperformed by students 1 and 2 in Figure 2 informed group activity, we could zoom in on segments (e.g. 12-14).Collaborative data analysis sessions informed by CORDTRA diagrams unpacked these interactions.DiscussionFuture work will explore how sharing real-time observational data with students and teachers can help them todevelop engineering design practices in situ. Since GORP data can quickly generate CORDTRA diagragms,these have potential for formative evaluation. Adaptations of this real-time coding tool provide a time-efficientapproach to analyzing data and have the potential to support creative examinations of learning in a variety ofdisciplines and contexts. In future work, CORDTRA visualization shows a promising approach for reducinglarge corpuses of video data. The visualization provides a high-level view of activity over time and helpresearch teams to zoom in on intriguing moments and patterns.ReferencesGomoll, A., Šabanović, S., Tolar, E., Hmelo-Silver, C. E., Francisco, M., & Lawlor, O. (2017). Between thesocial and the technical: Negotiation of human-centered robotics design in a middle schoolclassroom. International Journal of Social Robotics, 1-16. Doi: 10.1007/s12369-017-0454-3.Gomoll, A., Hmelo-Silver, C. E., Šabanović, S., & Francisco, M. (2016). Dragons, ladybugs, and softballs:Girls’ STEM engagement with human-centered robotics. Journal of Science Education andTechnology, 25(6), 899-914. Doi: 10.1007/s10956-016-9647-zHmelo-Silver, C. E., Jordan, R., Liu, L., & Chernobilsky, E. (2011). Representational tools for understandingcomplex computer-supported collaborative learning environments. In Analyzing interactions in CSCL(pp. 83-106). Springer US.Mondada, L. (2006). Video recording as the reflexive preservation-configuration of phenomenal features foranalysis. In Hubert Knoblauch, Bernt Schnettler, Jürgen Raab & HansGeorg Soeffner (Eds), Videoanalysis. Methodology and methods. Qualitative audiovisual data analysis (pp.51-68). Bern: Lang.Knoblauch, H., Schnettler, B., and Raab, J. (2006) Video Analysis. Methodological Aspect of InterpretiveAudiovisual Video-Analysis in Social Research. In Knoblauch, H., Schnettler, B., Raab, J. andSoeffner, H. (Eds.), Video Analysis: Methodology and Methods, Oxford: Peter Lang.Schaal, S. (2007). The new robotics—towards human-centered machines. HFSP Journal, 1(2), 115-126.ICLS 2018 Proceedings1610© ISLS