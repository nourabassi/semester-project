Understanding Middle School Teachers’ Processing ofStudent-Generated Resources in Science ClassroomsXinyang Liu, Shandong Normal University, liuxinyang_sdnu@163.comShu Chen, Yinglian Jin, Xinning Pei, Tainian Zheng, and Sihan Xiaocherryshucs@gmail.com, jinyinglian@126.com, xnpei@kcx.ecnu.edu.cn, tnzheng@iice.ecnu.edu.cn,shxiao@kcx.ecnu.edu.cnEast China Normal UniversityAbstract: Teachers constantly encounter various responses generated by students in theclassroom. These responses, which can be regarded as instructional “resources” that havepotential value for facilitating students’ deep learning, are not fully used in teachers’ everydaypractice. By proposing the notion of “student-generated resources” (SGRs) and adopting a“resources use” rather than sociolinguistic perspective, this study investigates what SGRs arethere in the classroom and how teachers process them. Based on classroom observations, weidentify five types of SGRs. Following the “perceive–interpret–mobilize” processing flow,teachers demonstrate three processing results (utilize, feedback, and abandon). Further, weidentify three approaches of teachers’ utilization of SGRs and five approaches of their feedbackto SGRs. Our findings suggest that teachers tend to give feedback to SGRs rather than utilizethem as resources. This study broadens theoretical landscape about classroom resources andhelps teachers take full advantage of SGRs in empowering students’ learning.IntroductionThe classroom is a place full of dynamic and unpredictable events, such as students’ answers to teachers’ questionsand questions raised by students. Teachers’ processing of students’ responses shapes and features teacher-studentinteraction as well as instruction and learning in the classroom. The structure and content of teacher-studentinteraction is the focus of studies following the discourse analysis perspective (Frances, 2002). The famous IRE/F(Initiate-Response-Evaluate/Feedback) framework, first proposed by Mehan (1979) and Sinclair and Coulthard(1975) and revised by Lemke (1990), has dominated this field for a long time (Louca, Zacharia, & Tzialli, 2012).However, IRE/F-based analyses fail to capture the complexity of the discourse with regards to what the studentsare contributing, most of these studies view teacher’s responses to students as relatively passive reactions. Littleresearch moves forward to trace effects of teacher’s responses and their potential influence on consequentialinstructional activities.Our study adopts an alternative perspective that views student-generated events as potential instructionalresources, termed here as student-generated resources (SGRs). Specifically, in this study, SGRs include students’responses (especially non-normative answers) to teachers’ questions as well as students’ ideas, questions orexperiment findings expressed in class. We not only focus on how teachers deal with SGRs, but also explore theirperceiving and interpreting of SGRs, mobilizing and integrating other related resources with SGRs, and the finalutilizing of them. In line with Chin and Osborne (2008), we viewed students’ questions as “a potential resource.”Such resource not only helps students in the learning process, but also serves useful functions as a pedagogicaltool for the teacher. The resource perspective expands our vision from teachers’ in-the-moment decision makingprocedure (Erickson, 2001) to the entire processing flow, providing us with a more systematic view of teachers’classroom practice.Our perspective draws on the emerging research field of curriculum (resource) use (Cohen, et al., 2003;Remillard, 2005). The underlying assumption of this field is that teachers are central players in the process oftransforming curriculum ideals, captured in the form of mathematical tasks, lesson plans and pedagogicalrecommendations, into real classroom events (Lloyd, Remillard, & Herbel-Eisenmann, 2009). Over the lastdecade, studies in this field have grown tremendously, generating several enlightening frameworks (e.g. Brown,2002; Gueudet & Trouche, 2012), enhancing our understandings of how teachers use curriculum resources.Research in this field broadens researchers’ understandings of curriculum materials or resources, not onlytextbooks, instructional guides and digital learning environments as well as interactions among teacher, studentand curriculum are also regarded as an important origin of curriculum resources.By adopting the resource perspective, we try to bridge the fields of teacher-student discourse interactionand of curriculum (resource) use. Building on the intersection point of the two fields, our study tries to answer thefollowing questions:ICLS 2016 Proceedings402© ISLS1.2.What SGRs are there in middle school science classrooms?How do teachers process these SGRs?Theoretical frameworkTeacher-student discourse interactionFollowing a sociolinguistic perspective (Carlsen, 1991; Frances, 2002), Teacher-student discourse interactionstudies has stressed the importance of classroom discourse for teaching and learning. The main approaches forstudying teacher discourse followed primarily the Initiation–Response–Evaluation (IRE) or Initiation–Response–Followup or Feedback (IRF) structure (Lemke, 1990). These approaches have received criticism, especiallyregarding the focus of research approaches in using IRE exclusively on a teacher’s role in initiating andmaintaining a conversation. Research needs to provide a more coherent framework for studying teacher discoursein relation to student discourse (Aguiar, Mortimer, & Scott, 2010; Cazden, 2001; van Zee, Iwasyk, Kurose,Simpson, & Wild, 2001).Studies guided by other perspectives have broadened the vision of classroom discourse. Scott (1998)defined the notion of “teacher responsiveness” including three elements: 1) monitoring (monitor the presentperformance of students), 2) analyzing (analyze the nature of any differences between present performance andthe target performance), and 3) assisting (respond with an appropriate intervention to support students).Louca, Zacharia, and Tzialli (2012) argued that it might be more useful for the research community tohave a framework that focuses on student contributions during the conversation and the teacher decisions andresponses based on those contributions. Therefore, they developed a framework for investigating classroomdiscourse by focusing more broadly on what the teacher responds to, how she responds, as well as the process ofdeciding how to respond. This framework includes Identification, Interpretation—Evaluation, and Response. TheIdentification part concerns what the teacher responds to (student discourse contributions), the Interpretation—Evaluation part concerns how the teacher interprets and evaluates students’ discourse contributions, while theResponse part concerns how the teacher responds to students’ discourse contributions.Teachers’ use of curriculum (resource)For researchers in this field, “use” means a variety of interrelated pedagogical activities, including how teachersengage or interact with these resources as well as how and the extent to which they rely on them in planning andenacting instruction, and the role resources play in teachers’ practice. (Lloyd, Remillard, & Herbel-Eisenmann,2009)Research on curriculum (resource) use (e.g. Cohen, et al., 2003; Remillard, 2005; Gueudet & Trouche,2012; Jin, et al., 2015) proposes that teachers perceive and interpret what happened in the classroom before theydraw upon resources in the subsequent instruction. Hammer (1997) argued that teachers should coordinate relevantresources to achieve instructional goals before they have the opportunity to implement instruction. Brown (2002)proposed the notion of “pedagogical design capacity” to characterize teachers’ capacity to perceive, interpret andmobilize curriculum resources in the pursuit of desired outcomes. Adler (2000, 2012) proposed to turn the nounword resources into a verb “re-sources”, emphasizing the nature of teacher’s use of curriculum materials is areconstruction procedure. Similarly, Gududet and Trouche (2012) also pointed out that through a procedure ofwhat they called instrumentalization, teachers transform external resources (e.g. textbook, software, unpredictablestudent responses) into “lived” resources applicable in their own classroom contexts.A framework for analyzing teachers’ processing of SGRsBy reviewing literature, we found an intersection point of the above two fields: they both have interests in teachers’processing flow of SGRs. Viewing students’ responses as instructional resources, we constructed our frameworkfor analysis of teachers’ processing of SGRs by integrating the key procedures derived from widely usedcurriculum (resource) use research (e.g. Brown, 2002) and teacher-student discourse interaction research (e.g.Louca et al., 2012), as shown in Figure 1. The verbs “perceive-interpret-mobilize” in rectangles defined three keysteps of teachers processing of SGRs. In curriculum (resource) use research, “perceive” means teachers’awareness of the resource that has potential value for instruction (Brown, 2002). Louca et al named the similarstep that teachers noticed students’ verbal responses as identification (Louca et al., 2012). “Interpret” refers toteachers’ evaluation of SGRs and current contexts so as to decide whether or not to use SGRs in the next step. Ifteachers decide to use a certain piece of resource, they need to choose and integrate other related resources. Thisstep is named “mobilize”. For instance, the teacher refers to his/her PCK to give a comment to one student’sresponse to an open-ended question or gives a clear explanation to one student’s question about the experimentICLS 2016 Proceedings403© ISLSdesign. As a result, at the end of the processing procedure flow, there are three different types of processing results,labeled as utilize, feedback and abandon. Specifically, our framework illustrated branches (not perceived, notdecided to use) in the processing flow and three types of processing results (utilize, feedback and abandon), thesedetails were mentioned or implied in the two fields but not thoroughly discussed. We hope to promoteunderstanding of these details with our framework.Figure1. A Framework for analyzing Teachers’ Processing of SGRs.MethodsParticipants and contextThis study took place in a middle school located in downtown Shanghai. Two experienced teachers werepurposefully selected from 4 science teachers in that school according to criteria proposed by Berliner (1994,2004) they had taught science in school for more than 7 years, and 2) their achievement in science teaching hadbeen recognized by both principals and colleges. We chose experienced teachers in our study because they havewell-developed professional competences and more stable teaching behaviors, which would enable us to capturethe patterns and features of teachers’ processing of SGRs. Teacher A had 19 years teaching experience whileTeacher B had 8. They taught science for 7th graders and 6th graders respectively.According to Shanghai Middle School Science Curriculum Standards, Science, as a subject, is designedfor students in grade 6 and 7 and aims at developing students’ comprehensive science understanding andknowledge before taking physics, chemistry, life science and geography in grade 8. After discussing with bothteachers, we finally chose “photosynthesis and respiration” for Teacher A and “features of living things” forTeacher B. Both teachers said they had interest and confidence for teaching their own topic. This context washelpful for us to capture abundant SGRs and explore teachers’ sophisticated processing of them. Each topicincluded 45 minutes of classroom instruction and 45 minutes of laboratory experiment, and was taught by oneteacher in two classes respectively. Students in all the classes had similar performances and achievements inscience learning.Data sourcesEight lessons (each topic included two lessons, one teacher taught for two classes repeatedly) were recorded usingvideo camera. Immediately following each lesson, short interview (3-5 minutes) were conducted and recorded tohelp us verify some ideas about teachers’ teaching behaviors we observed. All of the video and audio records weretranscribed. We used Nvivo 10 to manage data and conduct analysis.Data analysisCategories of SGRsWe first viewed all the lesson videos and identified every piece of SGR according to the definition mentionedabove. Then by using open coding method (Glaser & Strauss, 1967), we labeled and categorized each piece ofstudent-generated resource. We then looked through all labels and verified their fitness. Finally, we adjusted andrefined the following list (see Table 1) to develop codes for categorizing SGRs.ICLS 2016 Proceedings404© ISLSTable 1: Categories of SGRsCategoryNR-CloseDescriptionNon-normative Response to teacherraised Close-ended questionNon-normative Response to teacherraised Open-ended questionTypical ExampleT: Where does respiration take place?S: In our lungs.NR-OpenT: Do you know other common features ofanimals?S: Animals live together.RR-OpenReasonable Response to teacher raisedT: Give me an example of animal’s adaption toOpen-ended questionenvironment.S: Bears hibernate in winterSQStudent raised QuestionA student asked Teacher A what is the black thingin the bottom of the test tube.SEStudent Experiment phenomenon orA student reported his snail showed no reaction toproblemlight.*As correct answers to close-ended questions are predictable, this kind of student responses was not consideredas generated resource in our study.Procedure of teacher’s processing SGRsThe theoretical framework mentioned above served as a reference for analyzing teacher’s processing procedureof student-generated resources. Meanwhile, we kept open-minded and sensitive to any evidence emerged fromthe data that might bring revision to the theoretical framework. After a similar process mentioned above, wedeveloped codes to identify different processing stages. (Table 2)Table 2: Stages of teachers’ processing SGRsStagePerceivedDescriptionThe teacher noticed a piece of studentgenerated resource.Not PerceivedWe noticed a piece of resource but no evidenceshowed that the teacher noticed it.The teacher showed response to a piece ofresource she noticed.The teacher noticed a piece of resource butshowed no response to it.Decided to useNot decided touseUtilizedThe teacher made use of the resource in thefollowing instruction.FeedbackThe teacher only gave the student(s) some kindof feedbackTypical ExampleWhen discussing “whether coral is animalor plant”, some students said “animal”others said “plant”, We observed that bothwere noticed by Teacher B.(not occurred in the lessons we observed)Teacher B asked students who said “coralis animal” to explain their reasons.Teacher B noticed some students said“coral is plant”, but never asked them toexplain.A student asked “why should we first putthe plant in a dark room for 24 hours”, thenTeacher A used it as a question to ask theclass.When a student replied “chlorophyll” forthe question on the products ofphotosynthesis, Teacher A said “No,chlorophyll is a kind of matter of the plantitself.”ResultsCategories and frequencies of SGRsAccording to the codes of SGR categories, we finally identified 36 pieces of SGRs in Teacher A’s classes and 26pieces of SGRs in Teacher B’s classes. (Considering the same lesson repeated in different classes, SGRs observedin different classes with both same content and teacher processing mode are counted as one single resource).ICLS 2016 Proceedings405© ISLSFigure 2 shows the frequencies of different types of resources generated by students in science class. Overall, themajority of SGRs (Teacher A: 89%, Teacher B: 88%) are students’ responses to teachers’ questions (includingNR-Close, NR-Open, RR-Open). In Teacher A’s class, we identified all five types of SGRs (36 pieces), of whichup to two-thirds were NR-Close type (22 pieces), while in Teacher B’s class, there’s no SQs, RR-Open typeoccupies 50% (13 pieces) of all SGRs in her class.NR-CloseNR-OpenRR-OpenSQSEFigure2. Frequencies of different categories of SGRs in two teachers’ classes.Procedure and results of teachers’ processing SGRsBy coding teachers processing stages of SGRs, we found teachers basically followed the “perceive-interpretmobilize” procedure and both teachers could perceive and interpret all the SGRs. In terms of the processing results,teachers have similar preferences. They abandoned only two pieces of SGRs each, all the four pieces of SGRsbelong to NR-Close category. As shown in Figure 3, when science teachers successfully incorporated otherresources to mobilize the SGRs, they might not utilize them. Rather, they were more likely to give feedback forthe SGR’s own sake. For instance, a teacher might directly correct students’ non-normative answers or only tellstudents whether their answers are right. Both Teacher A and Teacher B gave lots of feedback to SGRs in theirscience class, accounting for 61.1% and 69.2% of all the processing results respectively. However, Teacher Autilized one third of SGRs in the class and Teacher B utilized less than one quarter of all the SGRs. (see Figure 3,width of the arrow lines indicates quantity of SGRs in the branches)Figure 3. Teachers’ processing flow of SGRs.Distribution of utilization and feedback among five categories of SGRsIn general, teachers decided to use the majority of the SGRs regardless of their categories. Figure 4 illustrates thedistribution of utilization and feedback among five different types of SGRs. We found that the two teachersutilized three of the five categories of SGRs: NR-Close, RR-Open and SQ. Both teachers could utilize NR-Closetype of SGRs, of all the SGRs utilized by each teacher, NR-Close type of SGRs took 92% and 67% respectively.In terms of each type of SGRs, both teachers utilized more than one half of NR-Close type of SGRs in their class.In the contrast, neither NR-Open nor SE type of SGRs were utilized by two teachers.ICLS 2016 Proceedings406© ISLSUtilizeFeedbackFigure 4. Distributions of utilization and feedback among five categories of SGRs.Teachers’ instructional approaches of utilization and feedbackWhen teachers utilized SGRs, they demonstrated 3 types of approaches: 1) Testing students’ knowledge. Forexample, a teacher might repeat or revoice a student’s answer and then ask the class “Do you agree on his/heridea?” or “Who can tell us what’s wrong with his/her answer?”. Teacher A used about 50% of the utilized SGRsto test students’ mastery of knowledge, while for Teacher B, the proportion was 66.7%. 2) Creating problemcontexts. For instance, a student proposed a question to Teacher A, “Why we should use alcohol to dissolve andremove chlorophyll in leaves? ” Then Teacher A used this question as a trigger to engage all the students inthinking about the purpose of this key step in the experiment. Teacher A adopted this approach to process 42% ofthe utilized SGRs and Teacher B processed 33% of the utilized SGRs in his/her class. 3) Extending content in thetextbooks such as introducing the concept of carbohydrate one the basis of students’ responses. Two pieces ofSGRs were utilized by Teacher A for content extension, while none utilized by Teacher B.In terms of giving feedback to SGRs, both teachers had five specific ways to process them: 1) Judge,which means telling the truth of false was the most common way adopted by both teachers. In Teacher B’sfeedback to SGRs, 56% of them were processed in this way. For Teacher A, the proportion was 35%. 2) Query,referring to pointing out problems in students’ responses. For example, a teacher asked the students who reportedan experiment design that “could you guarantee that your design would prevent air from entering into the testtube?” Teacher A gave query to 1/3 SGRs received feedback, and Teacher B only processed one piece of SGRsin this way. 3) Redirect students’ responses to the topic they were talking about. For example, one student arguedthat running away in the face of danger was a common feature of animals, and then teacher told her that “this isanimals’ adaptability to surroundings”. Only one piece of SGR was redirected in Teacher A’s class, while inTeacher B’s class, 28% feedback were given by this approach. 4) Correct, that is, teachers correct mistakes orinaccuracy in students’ responses. 5) Explain, namely give explanations to problems students encountered in doingtheir experiment. These two approaches were used seldom by both teachers.Discussion and conclusionThis study shows that science classes were short of student initiated SGRs that might be of highly value forteaching utilization. The majority of SGRs were students’ responses to teachers’ questions (including NR-Close,NR-Open, RR-Open), whereas students initiated questions (including SQ and SE) were much less. This illustratesthat students did not have sufficient opportunities or get necessary scaffolding to generate their own questions.This finding resonates with the results of many studies reviewed by Aguiar et al. (2010), which suggest thatstudents’ questioning is both infrequent and unsophisticated in the science classroom. Among students’ responses,NR-Close type of SGRs took 56%. Though RR-Open SGRs occupy the second largest portion, most of those“open questions” can be characterized as directives, such as “Please give us an example of …” or “Tell me aphenomena in your everyday life that can illustrates …” which could be attribute to what Scott (1998) defined as“authoritative discourse”, both of the teachers admitted that they made efforts to control students’ utterance “onthe expected way” to textbook topics. In that case, science teachers should be prompted to be less dominated inthe class and give students more chances to propose their own questions that could be utilized as precious resourcesfor enhancing students’ science learning.The analysis of teachers’ processing procedure and results of SGRs reveals that the framework foranalyzing teacher-student interaction in the curriculum (use) perspective could be available and practical forresearchers. In our study, both teachers were able to notice and perceive all the SGRs, and they wouldICLS 2016 Proceedings407© ISLSautomatically mobilize other resources they owned to utilize or give feedback to these SGRs. Besides, as we paidmore attention to how teachers’ responses influenced students’ learning rather than the formal pattern itself, weidentified specific instructional approaches teachers adopted in utilizing or giving feedback to SGRs. Whenteachers decided to utilize SGRs, they would flexibly use them to test, create problems situations or extendcontents in the textbooks, which showed their general awareness of valuable SGRs and competences in processingSGRs. As classes moved, we found that students’ understanding of science concepts or phenomena was enhanced.As a result, teachers’ practical wisdom could contribute to further academic researches on the usage of SGRs, andthen maximize the value of SGRs for students’ science learning and understanding.Our study also illustrates teachers’ disabilities and weakness in dealing with these in-the-moment events.These would help us give more effective and targeted suggestions for teachers to optimize their processing ofSGRs, thus empower students’ science learning. The distribution of teachers’ processing results among fivecategories of SGRs shows that most of the SGRs utilized by teachers were NR-Close type, while NR-Open, RROpen and SE types of SGRs were not fully employed. It could be inferred that NR-Close type of resources weremuch easier for teachers’ recognition and utilization with the least variability and uncertainty among all five typesof SGRs. Therefore, we should develop teachers’ abilities to address SGRs with high uncertainty and complexity.In our view, giving feedback which was the most common processing result of SGRs, could also benefitstudents’ learning. The key point lies in specific ways teachers adopt to approach the resources. In our analysis,the five types of feedback we identified and named in this study are similar with four different types of teacherfeedback (Chin, 2006). The analysis suggests that when teachers gave feedback to SGRs, they mostly judged theanswers and pointed out directly whether the answers were right or wrong. While query regarded as higher-ordercognitive feedback (Chin, 2006) took less than one quarter of all the pieces of SGRs. The effectiveness offeedback to SGRs was reduced because of the low-order cognitive ways teachers adopted. In this sense, we shouldfacilitate teachers to give more high-order cognitive feedback in order to facilitate students’ higher-order thinking.In this study, we proposed the notion of “student-generated-resources” (SGRs). We argued that SGRshave much potential value for enhancing students’ science learning if it can be made full use of by science teachers.We identified five types of SGRs and constructed a theoretical framework which links researches on curriculum(resource) use and teacher-student discourse interaction for analyzing teachers’ processing of SGRs. In particular,we focused on teachers’ processing results of different types of SGRs and their specific ways to utilize and givefeedback to SGRs in the class. These findings helped us to figure out characteristics of teachers’ processing ofSGRs and thus give practical suggestions on teachers’ instruction which may empower students’ learning inscience class.ReferencesAdler, J. (2000). Conceptualising resources as a theme for teacher education. Journal of Mathematics TeacherEducation, 3(3), 205-224.Adler, J. (2012). Knowledge resources in and for school mathematics teaching. In Ghislaine, G., Pepin, B. &Trouche, L. (Eds.), From Text to 'Lived' Resources: Mathematics Curriculum and Teacher Development(pp. 3-22). Netherlands: Springer.Aguiar, O. G., Mortimer, E. F., Scott, P. (2010). Learning From and Responding to Students' Questions: TheAuthoritative and Dialogic Tension. Journal of Research in Science Teaching, 47(2), 174-193.Berliner, D.C. (1994). Expertise: The wonder of exemplary performances. In Mangieri, J.N. & Block, C.C. (Eds.),Creating powerful thinking in teachers and students (pp. 161–186). Fort Worth, TX: Holt, Rinehart &Winston.Berliner, D.C. (2004). Describing the behavior and documenting the accomplishments of expert teachers. Bulletinof Science, Technology & Society, 24(3), 200-212.Brown, W. M. (2002). Teaching by Design: Understanding the Interaction between Teacher Practice and theDesign of Curricular Innovations (Unpublished doctoral dissertation). Northwestern University,Evanston, IL.Carlsen, W.S. (1991). Questioning in classrooms: A sociolinguistic perspective. Review of Educational Research,61(2), 157–178.Cazden, C.B. (2001). Classroom discourse: The language of teaching and learning (2nd ed.). Portsmouth, NH:Heinemann.Chin, C. (2006). Classroom Interaction in Science: Teacher questioning and feedback to students’ responses.International Journal of Science Education, 28(11), 1315-1346.Chin, C., Osborne, J. (2008). Students' questions: a potential resource for teaching and learning science. Studiesin Science Education, 44(1), 1-39.ICLS 2016 Proceedings408© ISLSCohen, D.K., Raudenbush, S.W., & Ball, D.L. (2003). Resources, Instruction and Research. EducationalEvaluation and Policy Analysis, 25(2), 119-142.Erickson, F. (2011). Accessing mathematics teachers-in-the-moment noticing. In Sherin, M. G., Jacobs, V.R., &Philipp R. A. (Eds.), Mathematics teacher noticing: Seeing through teachers’ eyes (pp. 79-94). NewYork and London: Routledge.Frances, C. (2002). Classroom discourse analysis. London: BookEns Ltd.Glaser, B. G., & Strauss, A. L. (1967). The discovery of grounded theory. New York: Aldine.Gueudet, G & Trouche, L. (2012). Teacher’s Work with Resources: Documentational Geneses and ProfessionalGeneses. In Ghislaine, G., Pepin, B. & Trouche, L. (Eds.), From Text to 'Lived' Resources: MathematicsCurriculum and Teacher Development (pp. 23-41). Netherlands: Springer.Hammer, D. (1997). Discovery learning and discovery teaching. Cognition and Instruction, 15, 485-529.Jin, Y., Liu, X., & Pei, X. (2015, April). Science Teachers’ Utilization of Teaching Resources in Junior HighSchool in Shanghai. Paper presented at the annual meetings of the American Educational ResearchAssociation. Chicago, USA.Lemke, J.L. (1990). Talking science: Language, learning and values. Norwoord, NJ: Ablex.Lloyd, G. M., Remillard, J. T., Herbel-Eisenmann, B. A. (2009). Teachers' Use of Curriculum Materials: AnEmerging Field. In J. T. Remillard, B. A. Herbel-Eisenmann & G. M. Lloyd (Eds.), MathematicsTeachers at Work: Connecting Curriculum Materials and Classroom Instruction (pp. 3-14). New York& London: Routledge.Louca, L. T., Zacharia, Z. C., Tzialli, D. (2012). Identification, Interpretation—Evaluation, Response: Analternative framework for analyzing teacher discourse in science. International Journal of ScienceEducation, 34(12), 1823-1856.Mehan, H. (1979). Learning lessons: Social organization in the classroom. Cambridge, MA: Harvard UniversityPress.Remillard, J. T. (2005). Examining key concepts in research on teachers’ use of mathematics curricula. Review ofEducational Research, 75 (2), 211-246.Scott, P. (1998). Teacher Talk and Meaning Making in Science Classrooms: a Vygotskian Analysis and Review.Studies in Science Education, 32(1), 45-80.Sinclair, J.McH., & Coulthard, R.M. (1975). Towards an analysis of discourse: The English used by teachers andpupils. London: Oxford University Press.van Zee, E.H., Iwasyk, M., Kurose, A., Simpson, D., & Wild, J. (2001). Student and teacher questioning duringconversations about science. Journal of Research in Science Teaching, 38(2), 159-190.ICLS 2016 Proceedings409© ISLS