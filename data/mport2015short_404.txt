Fostering Discussion across Communication Mediain Massive Open Online CoursesOliver Ferschke, Iris Howley, Gaurav Tomar, Diyi Yang, Yu Liu and Carolyn Penstein Roséferschke@cs.cmu.edu, ihowley@cs.cmu.edu, gtomar@cs.cmu.edu, diyiy@cs.cmu.edu, yul1@cs.cmu.edu,cprose@cs.cmu.eduLanguage Technologies Institute, Carnegie Mellon UniversityAbstract: This paper presents data from one cycle of a design based research process inwhich we grapple with challenges in engaging students in more intensive discussion basedinteractions in Massive Open Online Courses (MOOCs). We compare across threecommunication media provided to students in that context in terms of relative popularity andoverlap in student sub-populations. We also compare the communication between thesecontexts in terms of their content focus, concentration of reasoning articulation, and theinteraction between the two. This comparison allows investigating the specific contribution ofsynchronous collaboration in a MOOC, which is relatively novel. The analysis suggests thatthere is value in providing a diverse set of discussion contexts in that they may lendthemselves to differently natured interactions, but that it creates a need for greater effortstowards effective bridging between media and channeling of students to pockets of interactionthat are potentially of personal benefit.Keywords: discussion affordances, massive open online courses, reasoningIntroductionAs the field of online education increases its focus on delivery of effective instruction at massive scale as inMassive Open Online Courses (MOOCs), we become more painfully aware of teaching resources as a limitedcommodity. Analyses of attrition and learning in MOOCs both point to the importance of social engagement formotivational support and overcoming difficulties with material and course procedures (Breslow et al., 2013).Furthermore, we learn from the field of Computer Supported Collaborative Learning (CSCL) that with propersupport, students can learn substantially from their interactions with other students (Fischer et al., 2013).However, the reality of current content-focused xMOOCs, such as the typical MOOCs offered throughCoursera, edX, and Udacity, is that opportunities for exchange of ideas, help and support are limited to threadeddiscussion forums, which are often not well integrated with instructional activities and as a result lack many ofthe qualities identified as reflecting instructionally beneficial interactions from prior work in the field of CSCL(Rosé et al., 2014). In contrast, constructivist MOOCs, or cMOOCs, typically provide an eclectic variety ofaffordances for social interaction including blogs, Twitter communication, email, Facebook study groups andothers, with the idea that students should have the freedom to find a context for learning socially within thisvariety that they feel comfortable with, which may be effective for engendering a wider variety of discoursescontextualized within the learning and therefore meeting different instructional needs (Siemens, 2005; Smith &Eng, 2013). One downside of this approach, however, is that many students find the variety disorienting andanxiety-inducing, especially those who lack appropriate self-regulated learning skills.This paper presents data from one cycle of a design based research process in which we grapple withthese trade-offs as we seek effective practices for incorporating theory-motivated discussion based learningopportunities in MOOCs. Specifically, we aim to import from the field of CSCL insights into the specificaffordances for instructionally beneficial conversational interaction offered by alternative online discussioncontexts as well as insights into what might be productive strategies for moving among them so that appropriate,integrated support and guidance for students could be designed and offered. In the first cycle within thisiterative process, which we report on in this paper, we have developed two interventions to address specificlimitations we have seen in the current generation of xMOOCs, and then deployed them in a recent edX MOOC.In the remainder of the paper we describe the prior work that motivated the design of these interventions. Wethen present our deployment effort and the interpretation of the data that has been collected during the first twoweeks of this edX MOOC that provides the context for our study. Finally, we conclude with plans for next stepsin the iterative design based research process.CSCL 2015 Proceedings459© ISLSFoundational workThe central means of communication provided by many courses is still the traditional web forum. Nevertheless,Web 2.0 technologies provide diverse opportunities for discussion in MOOCs, some of which have been utilizedin that context. However, so far there is no coherent vision for seamless, effective integration of thesetechnologies with MOOC based instruction. Instead, social communication in MOOCs, as in the web ingeneral, is both eclectic and highly fragmented. For example, it is almost a given that for typical MOOCs,several groups in social networks such as Facebook or Google+ are created and sometimes actively maintainedby the student population, but much more frequently quickly abandoned. Twitter is another social media outletthat is sometimes used in MOOCs, more often in cMOOCs than xMOOCs, which is mainly used as a broadcastmedium but also exhibits instances of short public discussions. Discussion may also take place in connectionwith blog posts. This eclectic organization leaves students not having a clear picture of where to go to engage indiscussion that interests them (Smith & Eng, 2013).Most agree that social interaction in general and discussion in particular is not a major portion of theexperience the majority of MOOC students have. Nevertheless, the inner workings of student experience in thatcontext has been investigated in early work on MOOCs. Recent work studying social interaction in MOOCs hasfocused on identifying factors associated with attrition rather than learning (Wen et al., 2014a; Wen et al.,2014b; Yang et al., 2014). The motivation for this work is that scarce human resources could be channeled towhere they are most needed, or augmented with automated forms of just-in-time support, that might enablestudents to persist in the course through times of elevated vulnerability. These hypotheses about what factorswould ultimately flag students at risk have been validated by utilizing a statistical analysis technique referred toas survival analysis, which has been used to gauge the impact of time variant factors on dropout in other types ofonline communities (Wang, Kraut, & Levine, 2012). Factors that have been successfully modeled throughdiscourse analytics, and which have been validated as significant predictors of dropout using survival modeling,include motivation and cognitive engagement (Wen et al., 2014a), student attitudes towards course affordancesand tools (Wen et al., 2014b), satisfaction with help received, and relationship formation and loss (Yang et al.,2014). Of all of the factors explored so far, the most dramatic impact on attrition was related to relationshipformation and relationship loss in the MOOC discussion forums, even though the students who participate inthose forums are among the most highly committed to the course to begin with.In these results we find support for the importance of community, and evidence of the potential positiveimpact of work towards integration in the community, and engagement in joint meaning making towards deeperengagement with the course materials. If students drop out of a course early, no matter how valuable theinstructional materials are, students will not have the opportunity to benefit from them. Beyond issues ofattrition, the literature on discourse analytics in the context of MOOCs also views conversational interactionsfrom the standpoint of what is valuable for learning. Across many different frameworks for characterizingdiscourse patterns associated with successful collaborative learning, the idea of eliciting articulation ofreasoning and idea co-construction is a frequent central element (Chan, 2013; Chin & Clark, 2013; van Alst,2009). Thus, in our work it is a specific goal to provide affordances for engaging in this behavior throughscaffolded synchronous collaboration, which is novel in a MOOC context. In contrast to other studiescomparing features of communication across media (Meyrowitz, 1998; Watson-Manheim & Balanger, 2007),the goal of our specific investigation is to understand how MOOC students in a platform that includes choices inwhere to engage in discussion, choose to engage differently in learning relevant practices such as articulation ofreasoning and help exchange across communication media.MOOC designBuilding on the understanding gained through analysis of conversational interactions in a wide variety ofinstructional settings, interventions have been developed and successfully deployed in both classroom andonline settings that support effective collaboration and learning in those settings. In this section we describe twointerventions designed to provide opportunities for discussion based learning. While one of the interventionsfocuses on help exchange, the other focuses on collaborative reflection. Both interventions were deployed in anine week long MOOC on Data, Analytics and Learning (DALMOOC) that was offered on the edX platformbetween October and December 2014 with a total of 20,991 registered students. Our analyses are focused on thefirst two weeks of the course since that was the time of most intensive usage of the conversational interventions.The Quick HelperThe first intervention, called the Quick Helper, is designed to support help seeking as well as increase theprobability that help requests will be met with a satisfactory response. While virtually all MOOCs offer threadeddiscussion affordances where students can post help requests, some students are reticent to ask for help, andCSCL 2015 Proceedings460© ISLSeven when students do post help requests, many of these requests go unanswered. Our help seeking interventionconnects students, whose questions may go unresolved, with student peers who may be able to answer theirquestions. The Quick Helper is continuously available to students by means of a button. When they click, theyare guided to formulate a help request. The help request is posted to the DALMOOC discussion board, and thetext and metadata are forwarded to our Quick Helper system. Using this help request, a social recommendationalgorithm selects three potential help providers from the pool of student peers. The student is then given theoption to invite one or more of these potential helpers to their thread as shown in Figure 1. Once selected, anemail with a link to the help request thread is then automatically sent to the selected helpers inviting them toparticipate in the thread. In the first two weeks of DALMOOC, 77 unique students elected to use our QuickHelper system approximately 127 times. Further discussion of our initial interventions applied to Quick Helperand its results are out of the scope of this paper.Figure 1. A screenshot of the helper selection in Quick Helper (left) and the Bazaar Collaborative Reflection chat (right).Bazaar Collaborative ReflectionA second intervention, referred to as Bazaar Collaborative Reflection, makes synchronous collaborationopportunities available to students in a MOOC context. Research in Computer-Supported CollaborativeLearning has demonstrated that conversational computer agents can serve as effective automated facilitators ofsynchronous collaborative learning (Dyke et al., 2013). However, typical MOOC providers do not offer studentsopportunities for synchronous collaboration, and therefore have not so far benefitted from this technology.Students click on our Lobby program and are matched with one other student that is also logged in to it. Oncematched, they are provided with a link to a chat room where they can work with their partner students on asynchronous collaboration activity, supported by a conversational computer agent. This work builds on earlierfindings from a series of studies where a Computer Facilitator has improved learning during collaboration (Dykeet al., 2013; Adamson et al., 2014).In order to gain a deeper understanding of the problems that may arise from synchronous collaborativeactivities in MOOCs, we integrated a collaborative chat environment with interactive agent support. In order tofacilitate the formation of ad-hoc study groups for the chat activity, we make use of a simple setup referred to asa Lobby. Students enter the Lobby with a simple, clearly labeled button integrated with the edX platform. Inorder to increase the likelihood of a critical mass of students being assigned to pairs, we suggested a couple oftwo hour time slots during each week of DALMOOC when students might engage in the collaborative activities.These timeslots were advertised in weekly email newsletters. However, the chat button was live at all times sothat students were free to attempt the activity at their convenience.Upon entering the lobby, students are asked to enter the name that will be displayed in the chat. Whensuccessfully matched with another learner, the student and their partner are then presented with a link to a chatroom created for them. If another student does not enter the Lobby within a couple minutes, they are requestedto return later. A visualization is presented to the student that illustrates the frequency of student clicks on thebutton at different times of the day on the various days of the week so that they are able to determine the besttime to return. Students enter the synchronous chat room via the link, and interact with each other as well as aconversational agent who appears as a regular user in the chat, as shown in Figure 1. This chat setup has beenCSCL 2015 Proceedings461© ISLSused in earlier classroom research (Adamson et al., 2014). In our initial investigation in DALMOOC, we makeuse of statically scripted agents who guide the students through course-related discussion questions but futureinvestigations may include agents that dynamically react to the students as in our earlier work (Dyke et al.,2013; Adamson et al., 2014).MethodThe goal of our analysis is to compare across three communication media affordances for help exchange andcollaborative reflection. Since the first week of the course may be anomalous due to students getting oriented tothe organization and material, we sampled from two different weeks. We avoided sampling from the samestudents in the two weeks as much as possible in order to minimize any statistical dependencies between weeks.DataTable 1: Descriptive statistics over sampled communication data for analysisBazaar (week1)Bazaar (week2)Forums (week1)Forums (week2)Twitter (week1)Twitter (week2)Unique Students42421241017773Units3837200200100100Messages242377200200100100Words6,0693,1248,10813,4011,6631,740For our analysis we sampled from communication data in three streams, namely, the Bazaar chats, the Forumposts, and the Twitter tweets. It was our goal to sample in a way that would give us broad exposure acrossstudents and weeks in an unbiased way. From the discussion forums, we randomly sampled 200 posts per weekafter filtering out any messages posted by instructors or staff. Tweets have been collected using the TAGSTwitter Archiver, which was configured to retrieve all tweets containing the #dalmooc hashtag that identifiestweets pertaining to the course. In interest of broad sampling, for each user, we kept at most two tweets andremoved all tweets by instructors or staff. We also removed duplicates and retweets. From the resulting set oftweets, we selected 100 contributions per week. For the chat data, in order to identify a unit with approximatelyas much content as the discussion posts, we chose as a unit of analysis a chunk of conversation occurringbetween two agent prompts, where each of these agent prompts was designed to start a new topic ofconversation. Within each chunk, we considered all of the contributions belonging to the same speaker as asingle unit, although we interpreted it within context. In interest of broad sampling, we chose to sample onechunk per chat transcript and disregarded all chats with less than two students (e.g. conversations between asingle student and the agent). However, in some chunks, only one speaker spoke, which explains why thenumber of units is sometimes less than 42. Due to the lower number of chats in the second week of the course,we sampled 21 chunks per week in order to have an even distribution across weeks.Data codingTable 2: Descriptive statistics over coded dataBazaar (week1)Bazaar (week2)Forums (week1)Forums (week2)Twitter (week1)Twitter (week2)Social18 (47.4%)22 (57.9%)39 (19.5%)32 (16.0%)19 (19.0%)7 (7.0%)Course Process23 (60.5%)7 (18.9%)88 (44.0%)88 (44.0%)31 (31.0%)38 (38.0%)Course Content14 (36.8%)21 (56.8%)53 (26.5%)80 (40.0%)38 (38.0%)57 (57.0%)Reasoning26 (68.4%)22 (59.5%)62 (31.0%)67 (33.5%)28 (28.0%)35 (35.0%)In order to get a sense for the differences in the discourse occurring within our three communication contexts,we coded each contribution along two dimensions. The first dimension used three thematic distinctions toenable us to identify talk segments pertaining to three primary purposes, which were not treated as mutuallyexclusive: Social, Course Process, and Course Content. Social segments were ones where students worked toCSCL 2015 Proceedings462© ISLScreate social connections with one another by sharing personal information, including contact information forfurther interaction. Course Procedure segments were ones in which the structure of the course, the courseenvironment, or course procedures were discussed. And finally, Course content segments were ones in whichthe conceptual content of the course was substantively discussed. In order to locate discussion that potentiallycontributes to content learning, the primary relevant discussion would focus on that content. Under this heading,students may be reflecting on what they have learned or answering one another’s questions. Discussion ofcourse procedures is important for helping students cope when they are struggling with technical problems likefinding resources, installing software, or navigating the courseware. Most of these contributions could beviewed either as exchange of help, or at least calling out for help. For example, even complaints about confusionregarding course procedures could be viewed as indirect requests for help. Thus, we may loosely considersegments coded this way as help-exchange related contributions. Making social connections also plays avaluable role in community building and provision of emotional support. Since some contributions mix thesethree foci, we coded this dimension as a set of three binary indicators applied separately to each contribution. Inorder to be beneficial for content learning, it is important to identify the manner in which content is discussed,and not just that it was mentioned. Thus, we coded a second dimension that distinguishes segments in whichreasoning is articulated and therefore made public from those in which it is not. For this, we adopted apreviously validated operationalization (Gweon et al., 2013). Each segment was coded either as displayingreasoning or not. With these two distinctions taken together, we can observe help related exchanges focusing oncourse procedures by looking at the frequency of discussion about course procedures, and we can observeopportunities for substantive reflective discussion about course content by identifying those segments related tocourse content where reasoning is articulated.Participation analysisIn order to assess the extent to which our three Communication contexts (e.g., the edX discussion forum, theintegrated Bazaar Collaborative Reflection tool and Twitter) engaged different users and in different types oftalk, we examined the population of students who participated in each as well as the overlap between pairs ofcontexts. Ultimately, we are interested both in the distinctions between student populations with these contextsas well as how students connect across platforms in order to learn how these different communication spaces arealready interconnected organically. This will inform our future efforts in providing explicit support beyond theborders of single communication platforms.The Bazaar tool for collaborative reflection was part of an intervention that particularly requested pairsof students to reflect on the course content in a collaborative manner. Consequently, what we hoped to see in thechats was a constructive dialog in which the students revisit the topic of the week, gain a deeper understandingof the subject matter, connect the new knowledge with their personal experiences and exchange ideas. Forumsare asynchronous communication tools and posts are not technically restricted to a certain length. Therefore, weexpected the forum posts to constitute the largest amount of text compared to chats and tweets. In contrast topublic communication platforms, such as Twitter, the target audience of forums is the community of studentsand instructors, both of which influences the content focus of the posts as well as the way they are written. Incontrast to chats and forums, Twitter is an external microblogging service that openly broadcasts to the public.Users can post messages of up to 140 characters on their Twitter stream. At the same time, these messages aredisplayed in the streams of all followers of the original poster. Tweets can be marked with hashtags, whichallows tweets with similar tags to be aggregated. The students in our MOOC were encouraged to use the#dalmooc hashtag in all course related tweets in order to engage other students or interested individuals in adiscussion without them having to be followers of the poster. This hashtag was also used to sample the data forthe purpose of our analysis. An interesting situation arises from the fact that posting a tweet with the coursehashtag reaches both the people who are actively looking out for posts with this tag but also all the followerswho are generally interested in the posts from this user but do not necessarily belong to the course in-group.FindingsQuantitative analysis of participation across communication contextsIn order to quantify the overlap between the sets of users of each communication context, we attempted to mapeach contribution to an edX account and then compute the intersection of the resulting lists of users from eachplatform. Forum users can directly be identified in the edX logs and are therefore fully accounted for in ouranalysis. Bazaar chat users were able to log into the lobby with arbitrary screen names. We therefore use theedX clickstream logs to map each Bazaar user to an edX account. In some cases, it was not possible to computethe match because students did not enter the chat directly through the edX platform. Tweet authors were mappedCSCL 2015 Proceedings463© ISLSto edX accounts via voluntary information provided in user profiles from an additional social communicationchannel integrated in DALMOOC.Figure 2. Overlap and distinction between subsets of participants in the Bazaar chats, Twitter, and discussion forumsThe diagram in Figure 2 shows the relative overlap in users between pairs of social contexts. Thenumbers in the ovals represent the number of users whose edX ID could be matched with an ID from theassociated context. The links represent the overlap. For example, 20.5% of all Twitter users we could map toedX accounts (78) also posted to the discussion forum while 4.4% of the forum users also posted on Twitter.This analysis suggests that, while we observe some overlap between subpopulations of students who participatein these contexts, the subpopulations are largely distinct.Quantitative analysis of communication content and typeWe hypothesized that students view the purpose of communication in the three contexts in different ways thatwould influence both the content focus and the nature of the discussion e.g., the extent to which we wouldobserve students articulating their reasoning. We also hypothesized that the content focus of the discussion itselfwould influence the nature of the discussion as well.In order to get a sense of the difference in content focus across the three contexts, we performed a chisquared test, with Communication context and Week as the independent variables and each of the binary contentfocus variables as dependent variables. We also included the interaction between Communication context andWeek. There was a main effect of Communication context on concentration of Social segments χ2 (2, n=675) =50.6, p < .0001 such that there was a significantly higher concentration of Social talk in the Bazaar chats thanthe other two contexts. There was a significant interaction between Communication context and Week χ2 (2,n=675) = 6.42, p < .05 such that in Twitter, there was less social talk in week 2 than in week 1, but this did notgeneralize to the other two contexts. For Course processes, we observed a significant effect of Week χ2(1,n=675) = 6.27, p < .05 such that there was a lower concentration of talk about Course procedures in the secondweek. We also observed a marginal effect of Communication context χ 2 (2, n=675) = 5,37, p < .05 such thatthere was somewhat less of a concentration of Course Procedure talk in the discussion forums than in Twitter,with Chat in between the two. There was also a significant interaction between Communication context andWeek χ2 (2, n=675) = 14.7, p < .001 such that the reduction in Course procedures talk was mainly in the Chat,with slight increases in the other two contexts. For Course content, there was a main effect of Week χ 2 (1,n=675) = 14.0, p < .001 such that there was a higher concentration of discussion pertaining to Course context inthe second week of the course than the first across contexts. There was a main effect of Communication contextχ2 (2, n=675) = 13.6, p < .005 such that there was a higher concentration of Course content related talk in theChats and Twitter than the Forums. There was no interaction between Week and Communication context.Since we observed interactions between Communication context and Week on the three content foci,when we examined the relationships between Communication contexts and concentration of Reasoning, weconsidered also interactions with Content focus and Week. Thus, each model contains Communication context,Week, one of the Content focus variables, all two way interaction terms, and the three-way interaction term asindependent variables. The dependent variable was Reasoning. In all three models, there was a significant effectof Communication context such that there was a higher concentration of Reasoning in the Bazaar Chats than theother two communication contexts. And there was never a significant main effect of Week or interactionbetween Communication context and Week. A simple model with Communication context as the independentvariable and Reasoning as the dependent variable was also significant, so we report that test here χ2 (2, n=675) =28.4, p < .0001. There was no significant main effect of Social talk on Reasoning, but there were main effects ofthe other two binary content focus variables. In the case of Course content χ2 (1, n=675) = 41.4, p < .0001 therewas a higher concentration of reasoning in segments pertaining to Course content than those that did not havethis. There was also a significant main effect of Course Procedures χ2 (1, n=675) = 9.25, p < .05 such that thereCSCL 2015 Proceedings464© ISLSwas a higher concentration of Reasoning in segments pertaining to Course Procedures than those without.However in this case there was a significant two-way interaction between Week and Course Process χ2 (1,n=675) = 11.5, p < .001 such that in Week1 there was a higher concentration of Reasoning when Course Processwas being discussed, but this was not true in Week2. There was also a significant three way interaction betweenWeek, Course process, and Communication context such that in Week2 there was a higher concentration ofReasoning in the Forums when Course process was discussed than not, but not in Week1.Qualitative analysisAs we have shown in our quantitative analysis before, chat conversations show the highest average of reflectivecontributions across all the platforms we observed. An even more interesting difference lies in the way thecourse content is reflected in the chats. The one-on-one conversations in Bazaar exhibit a strong constructivecharacter where reflective statements are not merely precompiled by each student and then exchanged, they arerather collaboratively constructed in the course of the conversation. The following short excerpt from a longerBazaar chat shows such an interactive reflection. Rather than each student providing a single complete reply tothe agent question, the students construct a joint reply by building on each other’s contribution in their ownreflection.AgentStudent 1Student 2Student 1Student 2Let’s start by looking at the logic of analytics, namely, how we use data tounderstand the world. Did this resonate with you? What are your concerns withthis worldview?"Well this seems like a great place to start... you will meet a supervisorsomewhere in this course i expect... using data is much more reassuring thanworking on solely intuition... on the other hand, it may be limiting to work withonly things you can capture in numbers...yes, that’s my thinking too, often real phenomena are oversimplified withnumbers we should gather data also for example affective data etcbut the pattern of working with data can be made more playful, juxtaposingdifferent elements which might appear unrelated, and working to ask questions,as opposed to providing answers... by affective data, what do you mean?for example, asking about learners emotions during learningWhile the segments pertaining to building social connections did not have any specific significance with respectto engendering articulation of reasoning, it is notable the extent to which students use each communicationmedium to reach out to other for social connection, often with the apparent desire to continue to interact over thecourse. In the chat, this was especially evident in longer discussions with a lively exchange of ideas.Student 2Student 1Student 2Very enjoyable session, thanks for the picture... can you give me a link to yourblog or some other means of getting back in touch please? maybe we will dosome other activity at some point further along? how are you getting along withtableau? do you have data?@HANDLE at twitter and i also started a course blog http://URLcool, thanks.... USER@DOMAIN.COM for me...While the requests to connect expressed in the chats are much more personal and based on a positive exchangeof ideas, the forums serve more as a market for people to find other like-minded students with similar interestsor from similar backgrounds.Discussion and current directionsIn this paper we have described an analysis of data from one cycle of a design based research process in whichwe aim to engage students in more intensive discussion based interactions in Massive Open Online courses. Wecompared across three communication contexts, including Twitter, threaded discussion forums, andsynchronous collaborative chats. What we find is that different subpopulations of learners within DALMOOC,an edX MOOC that is the focus of this study, tended to gravitate towards different ones of these contexts.Furthermore, each context was associated with its own unique profile in terms of content focus and the nature ofthe discussion (i.e., concentration of articulation of reasoning). We see ample evidence within contributionsacross media pertaining to social connection that these MOOC learners crave continuing social engagement withCSCL 2015 Proceedings465© ISLSother individuals participating in their MOOC course. The analysis suggests that there is value in providing adiverse set of discussion contexts but that it creates a need for greater efforts towards effective bridging betweenmedia and channeling of students to pockets of interaction that are potentially of personal benefit. Thus, whileproviding an eclectic combination of communication contexts has value in terms of engaging a wider variety ofMOOC learners, it appears to exacerbate the problem of students who report being overwhelmed by the amountof communication in the forums and having trouble finding the places where there is interaction with the contentfocus and style they are comfortable with. Together these results suggest a research agenda going forward thatseeks to design methods for greater orchestration across media. While some recent work develops socialrecommendation approaches that operate within single communication media, such as discussion forums (Yanget al., 2014), much work is left to do to develop more effective bridging and integration across media.ReferencesAdamson, D., Dyke, G., Jang, H. J., Rosé, C. P. (2014). Towards an Agile Approach to Adapting DynamicCollaboration Support to Student Needs, International Journal of AI in Education 24(1), pp91-121.Breslow, L., Pritchard, D., de Boer, J., Stump, G., Ho, A., Seaton, D. (2013). Studying learning in theworldwide classroom: Research into edX’s first MOOC, Research & Practice in Assessment 8, pp 1325.Chan, C. K. K. (2013). Collaborative knowledge building: Towards a knowledge creation perspective. In C. E.Hmelo-Silver, C. A. Chinn, C. K. K. Chan & A. M. O'Donnell (Eds.), International Handbook ofCollaborative Learning (pp. 437-461). New York: Taylor and Francis.Chinn, C. A., & Clark, D. B. (2013). Learning through collaborative argumentation. In C. Hmelo-Silver, C. A.Chinn, C. K. K. Chan & A. M. O'Donnell (Eds.), The International Handbook of CollaborativeLearning (pp. 314-332). New York: Routledge.Dyke, G., Howley, I., Adamson, D., Kumar, R., & Rosé, C. P. (2013). Towards academically productive talksupported by conversational agents. In Productive multivocality in the analysis of groupinteractions (pp. 459-476). Springer US.Fischer, F., Kollar, I., Weinberger, A., Stegmann, K., Wecker, C., & Zottmann, J. (2013). Collaboration Scriptsin Computer-Supported Collaborative Learning. International handbook of collaborative learning,Routledge, New York, 403-419.Meyrowitz, J. (1998). Multiple media literacies. Journal of communication, 48(1), 96-108.Rosé, C. P., Goldman, P., Sherer, J. Z., Resnick, L. (2014). Supportive Technologies for Group Discussion inMOOCs, Current Issues in Emerging eLearning, Special issue on MOOCs, December 2014.Siemens, G. (2005). Connectivism: A learning theory for a digital age. International Journal of InstructionalTechnology and Distance Learning, 2(1)Smith, B. & Eng, M. (2013). MOOCs: A Learning Journey: Two continuing education practitioners investigateand compare cMOOC and xMOOC learning models and experience, in Proceedings of the 6thInternational Conference on Hybrid Learning and Continuing Education, pp244-255van Aalst, J. (2009). Distinguishing between knowledge sharing, knowledge creating, and knowledgeconstruction discourses. International Journal of Computer Supported Collaborative Learning, 4, 259288.Wang, Y., Kraut, R.,and Levine, J. (2012). To stay or leave?: the relationship of emotional and informationalsupport to commitment in online health support groups. In Proceedings of the ACM 2012 conferenceon Computer Supported Cooperative Work, pp 833-842.Watson-Manheim, M. B., & Balanger, F. (2007). Communication media repertoires: Dealing with themultiplicity of media choices. MIS quarterly, 267-293.Wen, M., Yang, D., Rosé, D. (2014a). Linguistic Reflections of Student Engagement in Massive Open OnlineCourses, in Proceedings of the International Conference on Weblogs and Social MediaWen, M., Yang, D., & Rosé, C. P. (2014b). Sentiment Analysis in MOOC Discussion Forums: What does it tellus? Proceedings of Educational Data MiningYang, D., Sinha, T., Adamson, D., & Rosé, C. P. (2013). Turn on, Tune in, Drop out: Anticipating studentdropouts in Massive Open Online Courses, NIPS Data-Driven Education Workshop.Yang, D., Wen, M., Rosé, C. P. (2014). Peer Influence on Attrition in Massively Open Online Courses,Proceedings of Educational Data MiningAcknowledgementsThis research was funded in part by NSF Grants DATANET 1443068, IIS-1320064, and OMA-0836012 as wellas a collaborative grant with Google.CSCL 2015 Proceedings466© ISLS