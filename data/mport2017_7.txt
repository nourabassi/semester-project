Contrasting Explicit and Implicit Scaffolding for TransactiveExchange in Team Oriented Project Based LearningXu Wang, Miaomiao Wen, and Carolyn Roséxuwang@cs.cmu.edu, mwen@cs.cmu.edu, cprose@cs.cmu.eduCarnegie Mellon UniversityAbstract: Script based support for collaborative learning may employ either explicit orimplicit scaffolding. If the effect of script based support is mainly by means of its effect oncollaborative processes, it would be reasonable to expect that if two forms of supportmanipulate the same process variable, they would provide redundant rather than synergisticeffects when offered together. However, explicit forms of scaffolding may provide additionalbenefits from the reification of the processes that they provide, which could be received asinstruction. This paper contributes to research on dynamic support for collaborative learningby proposing a novel form of micro-level prompt designed to elevate the amount ofTransactive exchange. In a 2×2 factorial design, we measure the impact of this explicit formof scaffolding and an implicit form of support for Transactive exchange developed in priorwork, alone and in combination in terms of impact on two key outcomes, namelycollaborative product quality and acquisition of multi-perspective knowledge. In this study,the pair of manipulations provide synergistic support for group product quality, but only theexplicit support contributes to acquisition of multi-perspective knowledge.IntroductionWork related to both static and dynamic script based support for collaborative learning has leveraged thetheoretical construct of Transactivity (Teasley et al., 2008; Azmitia & Montgomery, 1993;De Lisi & Golbeck,1999), often demonstrating a mediating or moderating effect on learning, especially conceptual learning ofdifficult content (Azmitia & Montgomery, 1993; Schellens et al., 2007) and acquisition of argumentativeknowledge (Weinberger et al., 2010). In notable recent work, Wen (2016) provides evidence that Transactivityin collaborative discussion can be increased through careful assignment of students to teams based onobservation of a past history of Transactive exchange earlier in the course. Building on Wen’s prior work, inthis paper we address the question of whether explicit scaffolding of collaborative processes provided duringcollaboration offers an additional beneficial impact on outcomes above that achieved through implicit support.The findings highlight the importance of explicitly reifying desired collaborative processes over elevating thoseprocesses through an implicit mechanism such as a team formation protocol.More specifically, this paper presents a study of dynamic support for collaborative learning at scale asa contribution to the line of research aiming to import research from the CSCL community to the context ofMassive Open Online Courses (MOOCs). Interest in collaborative learning in MOOCs has been present sincethe earliest MOOCs, especially cMOOCs (Yeager et al., 2013). However, the reality remains that participationin typical MOOCs is a solitary experience. The bulk of prior work related to analysis of collaborative ordiscussion based learning in MOOCs has largely focused on information exchange in discussion forums (Wanget al., 2015; Wang et al., 2016) or designed collaborative learning experiences that are very short activities, suchas collaborative reflection activities (Rosé & Ferschke, 2016). While there has been a desire to incorporate moreambitious project-based learning in MOOCs (Ronaghi, 2014), limited success has been reported. Wen (2016)offers hope that this problem can be overcome, by presenting evidence from a combination of controlledexperiments and MOOC deployments that demonstrate positive impact of a team formation approach that offersproject teams in MOOCs a more productive starting condition. Despite a successful MOOC deployment inwhich all formed teams turned in a final project, inspection of group processes suggest that additionalimprovements could be achieved through support of collaborative processes after team formation.This paper contributes new insights related to dynamic support of at scale collaborative learning, withthe goal of providing an empirical foundation for a later high external validity MOOC deployment. The mostsimilar prior work to our own combines high internal validity controlled experimentation in a crowdsourcingenvironment such as Amazon’s Mechanical Turk (Coetzee et al., 2015; Wen et al., 2016) with subsequent highexternal validity deployments in at scale online learning environments such as online courses or team basedMOOCs. In this paper, we present a controlled study that provides design recommendations for a subsequentMOOC deployment that will offer dynamic support of collaborative processes during teamwork in that context.CSCL 2017 Proceedings25© ISLSIn the remainder of this paper we first offer an overview of related work leading into the specifichypotheses underlying our study as well as its proposed contributions. Next we offer the details of the designand preparation for our study. Next we offer an empirical analysis of the results of our study. Finally, we discusswhat we can conclude from the results and how they motivate the design of a subsequent MOOC deployment.Novel dynamic support prompts in relation to prior workCollaborative work can be structured either at the macro level or the micro level. A frequent method forstructuring collaborative work at the macro level is the use of what is known as the Jigsaw paradigm (Aronson,1978), to increase the interdependence between team members. In this paradigm, students are provided withspecialized expertise, and the task makes each piece of specialized knowledge that defines the Jigsaw to benecessary in order to achieve a satisfactory collaborative product. The Jigsaw used in Wen et al. (2016)consisted of four bodies of relevant knowledge for a task of constructing an integrated energy plan; each of thefour bodies of knowledge focused on the pros and cons associated with one form of energy. Another way tointroduce complementarity and interdependence is to assign students to roles that define their intendedcontribution (Strijbos & Weinberger, 2010; Schellens et al., 2007), such as assignment of different taskresponsibilities. In our work, we use the same task and Jigsaw paradigm used in Wen’s study.Micro-level structuring focuses more on the collaborative processes themselves. Sometimes thisinvolves reification of desirable forms of contribution to the discussion, such as with scaffolds in a messageauthoring buffer (Weinberger et al., 2005) or buttons on a structured graphical user interface (Baker & Lund,1997). Both static and dynamic forms of script based support for collaboration have been evaluated in the priorCSCL literature. A specific form of dynamic support that has been successful at increasing the intensity ofsubstantive exchange of and improvement of reasoning contributions was originally designed as an automatedform of what is referred to as Accountable Talk Classroom Facilitation (Michaels et al., 2002). A series ofearlier studies of conversational agents employing Accountable Talk Facilitation have been successful atelevating collaborative processes and learning (Adamson et al., 2014). Results from this prior work demonstratethat Accountable Talk based support for collaborative learning significantly increases conceptual learning.Typically macro and micro level support are treated separately. However, in our work we employAccountable Talk prompts as micro-level support, but we tailor them to the Jigsaw role of each student. Inparticular, when we direct a student to evaluate and respond to another student’s contribution, we ask them to doso from the perspective of their assigned jigsaw role. Thus, in addition to supporting Transactive exchange, thegoal is for the Accountable Talk prompts to intensify the interdependence between students by emphasizingtheir unique knowledge.Theoretical foundation and hypothesesA key theoretical construct that underlies our work is that of Transactivity, where our operationalization ofTransactivity is defined as the process of building on an idea expressed earlier in a conversation using areasoning statement. Research has shown that such knowledge integration processes provide opportunities forcognitive conflict to be triggered within group interactions, which may eventually result in cognitiverestructuring and learning (De Lisi & Golbeck, 1999). While the value of this general class of processes in thelearning sciences has largely been argued from a cognitive perspective, these processes undoubtedly have asocial component. From the cognitive perspective, Transactivity has been shown to positively correlate withstudents' increased learning, since transactive discussion provides opportunities for cognitive conflict to betriggered (Azmitia & Montgomery, 1993;De Lisi & Golbeck, 1999). It has also been shown to result incollaborative knowledge integration (Gweon, 2012), since optimal learning between students occurs whenstudents both respect their own ideas and those of others' (De Lisi & Golbeck, 1999). From the socialperspective, Transactivity demonstrates good social dynamics in a group (Teasley et al., 2008).Wen (2016) showed that by using Transactivity in one context to index collaboration potential inanother context, we are able to significantly improve collaborative product quality. This raises the question ofwhether we can also increase learning with the same implicit support used in that study. However, in thelearning sciences, there has often been a tension observed between emphasizing performance and emphasizinglearning. In project courses, for example, students tend to take up roles where they can use the knowledge theyalready have in order to achieve a high quality product, which undercuts the learning that could take place.Often, learning requires focus on skills that are just beyond a person’s ability level. Thus, engagement thatleads to learning may frequently appear less successful in terms of performance. We cannot assume that amanipulation that supports a high quality product will necessarily support higher learning. In the case of themanipulation of group composition used in Wen (2016), Transactivity played a central role, and as alreadymentioned much prior work associates Transactivity with learning (Teasley et al., 2008; Azmitia &CSCL 2017 Proceedings26© ISLSMontgomery, 1993;De Lisi & Golbeck, 1999). Thus, (1) we hypothesize that the composition manipulationthat implicitly supports Transactivity will increase learning. Conversely, prior work has demonstrated thatdynamic support that intensifies collaborative processes leads to increased learning. Thus, (2) we alsohypothesize that the dynamic support manipulation of accountable talk that uses an explicit means toincrease knowledge integration processes would increase quality of a collaborative product where quality isrelated to knowledge integration.As discussed above, in this study we introduce a novel form of adaptive prompting behavior that alignsthe prompts with the students’ roles in a Jigsaw task, aiming to elicit more discussion and reasoning related tothe unique information the student has. Because such adaptive prompts reinforce the perspectives held bystudents, (3) we hypothesize that the dynamic support we provide that explicitly scaffolds collaborativeprocesses will lead to increased acquisition of multi-perspective knowledge.Wen (2016) shows that group composition has a positive effect on group product through moderatingTransactivity in collaboration. Because dynamic support using Accountable Talk prompts also aims atincreasing Transactivity in collaboration, there’s a question of whether the implicit group compositionmanipulation and the explicit dynamic support manipulation during the collaboration process would interactsynergistically or whether they would prove to be redundant forms of support. Prior work suggests that thesupport for learning offered through scaffolding a structured reasoning process is synergistic rather thanredundant with the support received through intensive human interaction when conceptual knowledge is thetarget of learning (Kumar et al., 2007). Furthermore, explicit scaffolding may be received differently thanimplicit scaffolding, and thus lead to a different learning effect. (4) Thus, we hypothesize a synergistic effect ongroup product quality if Accountable Talk prompts designed to explicitly scaffold a structured reasoningprocess are combined with a manipulation designed to intensify collaboration in a more organic implicit way,such as the composition manipulation.MethodIn order to test hypotheses 1-4, we conduct a 2×2 factorial design where we independently manipulate thepresence of the implicit group composition manipulation and the explicit Accountable Talk manipulation. Thisenables us to test the impact of the implicit support manipulation and the explicit support manipulation on groupproduct quality as well as testing whether the two manipulations have a synergistic or redundant effect. As akey part of the paradigm for conducting this experiment, we use the same knowledge integration task used inprior research related to the implicit support composition manipulation (Wen, 2016). In order to examine theeffects of both factors on individual learning and team product quality, we designed two outcome measures. 1)Individual pre-test and post-test to measure individual learning gains, including both measures of conceptualknowledge and multi-perspective knowledge. 2) A group proposal to measure team knowledge integrationquality. The overview of the theoretical model is shown in Fig.1. In the rest of section, we will describe the taskwe used, the logic of the prompting behaviors in our agent, measurement of learning, participant recruitmentand a manipulation check.Figure 1. Overview of theoretical model for the study.Task descriptionIn order for collaborative learning to be successful, the preconditions for interdependence and substantiveexchange and integration should be established. We followed the Jigsaw paradigm and designed this Jigsawknowledge integration task. Because each student represents a different perspective and receives uniqueinformation, it becomes critical for the students to transactively talk to each other and integrate their informationto complete the task, which was found to be a successful knowledge integration task (Wen, 2016).CSCL 2017 Proceedings27© ISLSIn the experiment, the student works through 6 steps, which take approximately 45 minutes. Step 1 is apre-test where students are asked to write an individual proposal on an open-ended task involving proposing anenergy plan for a city. In Step 2, students read an article. We designed the task to be a Jigsaw task, so thatdifferent students read materials focusing on their one assigned energy type, including coal, wind, nuclear orhydroelectric energy as types. In Step 3, students write one individual proposal based on what they have readfrom their own assigned perspective corresponding to the energy type, including “economical”, “environmentalfriendliness and low startup cost”, “carbon neutrality and economy in the long run”, “environmental friendlinessand reliability”. The proposal will be posted to a discussion forum. In Step 4, students comment on each other’sproposals. For students in the Transactivity grouping condition that provides implicit support for groupprocesses, they are then assigned to teams of four based on the group formation paradigm developed in Wen etal. (2016) to maximize the observed pairwise Transactivity across all teams, which means team members areassigned based on whom they’ve had the most Transactive exchanges with in the past, while also enforcing theJigsaw paradigm. For students in the random grouping condition, they’re randomly assigned to teams of fourbased only on the Jigsaw constraint. In Step 5, students work in teams on a collaborative task using an interfacewhere they write their group proposals on the left, and they will at the same time chat in the chat window on theright. The right window is where we provide the explicit scaffolded adaptive support to them as micro-scripting.Both conditions receive macro-level task structuring in the chat. We will in detail discuss the prompts weprovide in the explicit support manipulation in the next section. In Step 6, students do a post-test, which is anisomorphic task to the pre-test with minimal rewording.Scaffolded adaptive scriptingIn this section, we give a brief introduction to how the role-aligned adaptive scripting works. We inherited theconversation agent architecture Bazaar from Kumar (2011) and use it to introduce new conversational agentbehaviors in this work. The system needs to understand two features from each contribution a student has typedin. The first is whether the student is in support of a plan. We designed this to be key-word based, we keep adictionary of all possibilities we’ve found a student has used to refer to a certain plan, such as plan 1, plan A,option A, etc. We also keep a dictionary of all possibilities we’ve found students using to show being against aplan, such as, “totally against”, “don’t agree with”, etc. We use both rules to decide whether a student is insupport of a plan. The second is whether the student shows reasoning. We labeled contributions from our pilotstudies as reasoning or not and trained a machine learning model using a machine learning toolbench to assignthis label to contributions in our study. At the same time, the system also keeps track of which student hastalked least, and which plans have been brought up or fully discussed (i.e., discussed with reasoning).When the student doesn’t show reasoning towards a certain plan, there are two possible promptingbehaviors from the agent:1) Ask the student to elaborate on the plan from his perspective, where there are three templates for this.One example is “Hey xx, can you elaborate on the reason you chose plan # from your perspective of mosteconomical?”2) Ask the student to compare the plan with another plan that hasn’t been fully discussed. For example,“Hey xx, you have proposed plan #, and xx has proposed plan #. What do you think are the pros and cons of thetwo plans from your perspective of #?”When the person does show reasoning towards a certain plan, there are two possible promptingbehaviors from the agent as well:1) Ask someone else who has proposed a different plan that hasn’t been fully discussed to compare thetwo plans. “Hey xx, you have proposed plan #, and xx has proposed plan #. Can you compare the two plansfrom your perspective of #?”2) Ask someone else to evaluate this plan, for example: “Hey xx, can you evaluate xx’s plan from yourperspective of #?”When there’s nobody talking for 3 minutes, the agent will pick the person who has talked the least andprompt: “Hey xx, which plan do you prefer from your perspective of xx?”We went through an iterative design process to keep the amount of support at a reasonable level, andavoid over-scripting. We added additional rules, including 1) One person will not be prompted twice. 2) If aplan has already been fully discussed, it will not be prompted again. 3) The elaboration prompts will wait afterhaving been triggered before being inserted into the conversation. In particular, the agent will only prompt if thestudent doesn’t talk in the next 10 seconds. After adding the constraints, there will be no more than 3 prompts inthe 15-minute collaborative task. For most groups, there are 1 or 2 prompts.In addition to the micro-level adaptive prompts that are only used in the explicit support condition, wealso provide a starter prompt and a finishing-up prompt as macro-level support in all conditions.CSCL 2017 Proceedings28© ISLSMeasurement of learning and group productTo measure individual learning gains, we administered a pair of identical pre-test and post-test activities. In bothcases, it is an open-ended question that asks the student to write an 80-120-word energy proposal for a citybased on some basic information we provided about the city. We developed a coding manual to grade the openended proposal. Students can learn about energy from all steps in the task, including reading the article, andcommenting in the discussion forum. There are two ways students can improve in their ability to articulate aplan from their experience in the collaborative task. In particular, they may learn new pros and cons about anindividual energy source, which we consider conceptual knowledge. Or they may acquire new tradeoffs betweenenergy sources, each related to a specific perspective, for example, coal is economical, but hydroelectric supportis less so, and nuclear is even less so. We thus introduce two constructs to measure individual learning. 1)concept learning and 2) multi-perspective knowledge learning respectively.Concept learning refers to learning of correct concept points, such as “coal is very cheap andeconomical” or “wind is a renewable energy source”. We counted incorrect knowledge points and removedthese from the total. Multi-perspective knowledge learning refers to learning of comparisons between differentenergy types and tradeoffs of one energy type from different perspectives. For example, “nuclear is very reliablefor hospitals, whereas wind is very unreliable.” or “Although wind is very environmentally friendly, it can beharmful for bird habitats.” We also took off incorrect comparison/tradeoff points from the total.To measure group product quality, we graded the team proposals using the same rubric. The inter-raterreliability between two independent coders on a sample of the dataset is Kappa = 0.74. The two coders split upand then coded the remaining pre/post tests and group proposals without knowing which condition they camefrom. In addition to these outcome measures, we also introduced process measures to measure the quality of thecollaboration process. More specifically, we assessed each team’s chat logs, using metrics including 1) numberof contributions, 2) number of words, 3) number of reasoning contributions, 4) number of transactivecontributions, 5) number of reasoning contributions that are aligned with each member’s assigned role. Asmentioned in the scaffolded adaptive scripting section, we trained a machine learning model to automaticallypredict whether a contribution contains reasoning. We used the same model to compute the number of reasoningcontributions in each team’s chat log. Among these labeled logs, we labeled contributions as transactive or notmanually. In addition to general reasoning and transactivity, we also looked into how effective our interventionis in eliciting role-aligned reasoning. For example, a student represents coal energy, and he is supposed to arguefrom the perspective of which energy types are economical; if the student’s contribution either reasons aboutcoal energy, or reasons about other energy types from an economical perspective in a contribution, it isconsidered as role-aligned reasoning.Participant assignment and manipulation checkWe ran the study on Amazon Mechanical Turk from June to August in 2016. We ran the experiment in batches,with each batch associated with one or the other condition of the implicit group composition manipulation. Thus,each batch is assigned either to the Transactivity maximization condition or the control condition, so that allstudents within a batch are assigned to a team using the same process. In the rest of the paper, we refer to thismanipulation as the Transactivity factor. Within each batch, teams are randomly assigned to an explicit supportcondition, i.e., either having adaptive scaffolding from Bazaar as micro-scripting in the experimental condition,or no explicit micro-level support in the control condition. In the rest of the paper, we refer to this manipulationas the Bazaar factor. We ran 14 batches in total. Because 3 batches did not end up including at least 16 students,we removed them from our dataset. This is to guarantee that at least two teams are generated in each four of theconditions in each batch. Among the 11 batches, we have 4 batches of random grouping and 7 batches oftransactivity grouping. They generated 63 teams total, the distribution among conditions is displayed in Table 1.Table 1. Number of teams in each conditionAdaptive support: Without BazaarAdaptive support: With BazaarGroup composition: Random Group composition: Transactivity14181318We first did a manipulation check to make sure our grouping assignment manipulation successfullyassigned students to groups such that they had a higher history of prior transactive exchange than expected bychance based on the distribution of transactive exchanges in the whole batch. We used one-way ANOVA tocompare the average transactivity score during deliberation discussion within groups between those in controlcondition and those in Transactivity maximization condition and found a significant difference (F(1, 61) =8.19,p=0.006), with random assigned groups having a lower transactivity score (M = 8.56, SD = 5.87) compared toCSCL 2017 Proceedings29© ISLSTransactivity maximization groups (M = 13.28, SD = 6.91). The effect size value computed by Cohen’s D is0.73, suggesting a moderate to high practical significance. We then checked to make sure the randomassignment of students across the four conditions was successful in terms of ability to contribute to the task. Asa proxy, we evaluated the length of the individual proposal each student wrote prior to the deliberation phaseand did not find any systematic difference between conditions. (F(3, 59) = 1.25, p = 0.3)ResultsThe results in correspondence to the hypotheses are summarized in Table 2. As a summary of our results, ourfinding is that, consistent with prior results of accountable talk prompts on conceptual learning, the explicitsupport intervention increases acquisition of multi-perspective knowledge (as measured by trade-offs). It doesnot impact collaborative product quality. Conversely, consistent with earlier studies of the implicit groupcomposition manipulation, we observe here an impact on collaborative product quality, but not learning.However, an observed interaction effect reveals that the biggest impact on the collaborative product is achievedwhen both explicit and implicit interventions are combined.Table 2. Hypotheses testing and resultsHypothesis(1) The composition manipulation will increase learning, and a key process variable willbe transactivity(2) The dynamic support manipulation of accountable talk will increase collaborativeproduct quality.(3) The dynamic support we provide that scaffolds collaborative processes aligned withstudents’ perspectives will lead to increased acquisition of multi-perspective knowledge(4) There is a synergistic effect on group product if accountable talk designed to scaffolda structured reasoning process is combined with a manipulation designed to intensifycollaboration in a more organic way, such as the composition manipulation.Support or not?Not supportedPartly supportedSupportedSupportedIn response to Hypothesis (3), we built an ANCOVA model, using comparison/tradeoff points in posttest as the dependent variable, Transactivity grouping and Bazaar as main effects, and comparison/tradeoffpoints in the pre-test as a covariate, while also including group ID as a random intercept, to control for the factthat students in the same group may be correlated. We found Bazaar has a significant effect on the learning ofmulti-perspective knowledge, as represented by comparison/tradeoff points (F(1, 230) = 5.135, p = 0.024),which is consistent with our Hypothesis (3). The effect size value computed by Cohen’s d is 0.30, suggesting amoderate practical significance. In response to Hypotheses (1), we didn’t find an effect of Transactivitygrouping on either concept learning or multi-perspective knowledge learning. Thus hypothesis (1) is notsupported. And there was not an interaction effect between Transactivity and Bazaar on individual learning.In response to Hypotheses (2) and (4), we evaluated the two factors on the score of group proposals.We first built an ANCOVA model using group proposal score as the dependent variable, Transactivitygrouping, Bazaar, and the interaction term as independent variables, as well as the total length of individualproposal of each group as a covariate. We found an interaction effect between the two factors (F(1, 62) = 5.240,p = 0.026). We then recoded the two main factors Transactivity and Bazaar into one variable indicating 4conditions. As a planned contrast analysis we compared the group proposal scores across the four conditions.Based on Dunnett t-test, the average score of the condition where both explicit and implicit support were presentis significantly higher than the other three conditions (with p = 0.015, 0.043 and 0.001 respectively). The otherthree conditions were not different from one another. This partially supports our Hypothesis (2) that Bazaar ishelpful for group product when transactivity is also present. And this confirms our Hypothesis (4) that there is asynergistic effect between the scaffolded adaptive support and the team’s composition on group product quality.In terms of impact on process variables, our finding is that both manipulations influence collaborativeprocesses, but in different ways. In chat logs, Bazaar groups have a marginally higher percentage of reasoningcompared to control condition groups. (F(1, 61) = 3.213, p = 0.078) In addition to general reasoning, we alsolooked at whether our intervention leads to more role-aligned reasoning, which is a direct result of theintervention. We found for Bazaar groups, students displayed marginally significantly more reasoning behaviorconsistent with students’ assigned Jigsaw roles. (F(1, 61) = 0.09, p = 0.098) The effect is more salient forstudents in the random grouping condition. (F (1, 25) = 4.49, p = 0.044) We don’t see a difference on otherprocess measures between the experimental and control conditions. We see that Bazaar increases theconcentration in chat, and also increases students’ explanation aligned with their perspectives and roles. We alsotested whether these process measures had a mediating or moderating effect on outcome measures. Among theCSCL 2017 Proceedings30© ISLSprocess measures, we only see the percentage of role-aligned reasoning has a moderating effect on both groupproduct and multi-perspective knowledge learning.DiscussionFrom the above analysis, we found that the explicit adaptive support we provide in the chat is helpful forstudents’ multi-perspective knowledge learning. But the group composition manipulation, which offers implicitsupport, increases transactivity in the chat, but doesn’t show an effect on individual learning. On the other hand,the group composition manipulation has a significant positive effect on group product quality. Thus, inconnection with group product quality, we see both manipulations having a synergistic effect. Based on theseresults, the recommended intervention would depend upon whether acquisition of multi-perspective knowledgeor collaborative product quality is the primary target. If multi-perspective knowledge learning is the target,explicit support such as scaffolded accountable talk prompts should be emphasized, which reifies the value ofincluding an integration of perspectives in the discussion. Both manipulations should be used together as theyhave been observed to work well in tandem for achieving impact on the collaborative product quality.From the analysis of process measures, we found that the explicit support for transactive exchangeencourages students to focus their most sophisticated articulation of domain reasoning in the chat rather than inthe collaborative product. The responses to the Bazaar prompts increased the effort required on average percontribution (in particular when students were responding directly to the prompts), which dampened thetendency of the group composition manipulation to increase amount of discussion and integration in thecollaborative product. Thus, while the Bazaar prompts improved discussion processes and learning, we do notsee this value reflected in the collaborative product quality. On the other hand, it is important to consider that inthis task, where effort cannot be simultaneously expended towards the discussion process and the productproducing process, a manipulation that intensifies the discussion process may draw attention away from theproduct producing process. This is true when collaborative discussion and work on collaborative productsoccurs simultaneously. That is a difference between our setup and many phased collaboration setups in earlierstudies. Nevertheless, it reflects the reality of many collaborative setups both in learning contexts and in theworkplace. It is possible that if we required a more strict phasing structure, so that discussion occurred strictlybefore the collaborative work, we could employ both manipulations without any interference or dampening onthe learning effect. We leave this for future studies.ConclusionIn this paper we reported on an experiment to contrast the effect of implicit support through manipulation ofgroup composition and explicit support through providing scaffolded accountable talk prompts duringcollaboration. This high internal validity investigation motivates subsequent work where we will implementboth interventions in future team-based MOOCs, as done with the same study paradigm in earlier work (Wen,2016). In addition to practical implication for team-based learning in MOOCs, the theoretical contributions ofthis study are five fold: First, we investigated a novel form of accountable talk prompt that focuses ontransactivity from a specific knowledge-based specialization, which was found to be helpful for multiperspective learning and shows promise to be provided in future project-based courses to reinforce the roles andperspectives of team members. Second, we investigated explicit dynamic collaboration support in the form ofaccountable talk prompts in connection with a new form of learning (i.e., including multi-perspectiveknowledge as a learning measure rather than conceptual knowledge alone, which was the target in earlier studiesof Accountable Talk prompting). Third, we investigated the generality of the impact of dynamic support in theform of accountable talk prompts to collaborative product quality and found that although the dynamic supportis helpful for learning, it wasn’t observed to improve collaborative product quality when provided alone. Fourth,we investigated whether the effect of the group composition manipulation demonstrated to be effective forimproving collaborative product generalizes to learning. We found although group composition was effective inencouraging team members to chat transactively, it wasn’t helpful for either of our learning measures. Finally,we investigated the extent to which the respective effects of the group composition and explicit micro-levelscaffolding manipulations, which are assumed to be similar in that they are both grounded in the concept oftransactivity, are synergistic or redundant. Consistent with our hypothesis, we found both them to be synergistic.ReferencesAdamson, D., Dyke, G., Jang, H., & Rosé, C. P. (2014). Towards an agile approach to adapting dynamiccollaboration support to student needs. International Journal of Artificial Intelligence inEducation, 24(1), 92-124.Elliot Aronson. (1978). The jigsaw classroom. Sage.CSCL 2017 Proceedings31© ISLSAzmitia, M., & Montgomery, R. (1993). Friendship, transactive dialogues, and the development of scientificreasoning. Social development, 2(3), 202-221.Baker, M., & Lund, K. (1997). Promoting reflective interactions in a CSCL environment. Journal of computerassisted learning, 13(3), 175-193.Berkowitz, M. W., & Gibbs, J. C. (1983). Measuring the developmental features of moral discussion. MerrillPalmer Quarterly (1982-), 399-410.Coetzee, D., Lim, S., Fox, A., Hartmann, B., & Hearst, M. A. (2015). Structuring interactions for large-scalesynchronous peer learning. In Proceedings of the 18th ACM Conference on Computer SupportedCooperative Work & Social Computing (pp. 1139-1152). ACM.De Lisi, R., & Golbeck, S. L. (1999). Implications of Piagetian theory for peer learning.Gahgene Gweon. Assessment and support of the idea co-construction process that influences collaboration. PhDthesis, Carnegie Mellon University, 2012Kumar, R., & Rose, C. P. (2011). Architecture for building conversational agents that support collaborativelearning. IEEE Transactions on Learning Technologies, 4(1), 21-34.Kumar, R., Rosé, C. P., Wang, Y. C., Joshi, M., & Robinson, A. (2007). Tutorial dialogue as adaptivecollaborative learning support. Frontiers in artificial intelligence and applications, 158, 383.Michaels, S., O’Connor, M. C., Hall, M. W., & Resnick, L. (2002). Accountable talk: classroom conversationthat works. Pittsburg: University of Pittsburgh.Schellens, T., Van Keer, H., De Wever, B., & Valcke, M. (2007). Scripting by assigning roles: Does it improveknowledge construction in asynchronous discussion groups?. International Journal of ComputerSupported Collaborative Learning, 2(2-3), 225-246.Strijbos, J. W., & Weinberger, A. (2010). Emerging and scripted roles in computer-supported collaborativelearning. Computers in Human Behavior, 26(4), 491-494.Ronaghi, F., Saberi, A., & Trumbore, A. (2014). NovoEd, a Social Learning Environment. Massive OpenOnline Courses: The MOOC Revolution, 96.Rosé, C. P., & Ferschke, O. (2016). Technology Support for Discussion Based Learning: From ComputerSupported Collaborative Learning to the Future of Massive Open Online Courses. International Journalof Artificial Intelligence in Education, 26(2), 660-678.Teasley, S. D., Fischer, F., Weinberger, A., Stegmann, K., Dillenbourg, P., Kapur, M., & Chi, M. (2008).Cognitive convergence in collaborative learning. In Proceedings of the 8th international conference onInternational conference for the learning sciences-Volume 3 (pp. 360-367).Weinberger, A., Fischer, F., & Mandl, H. (2002). Fostering computer supported collaborative learning withcooperation scripts and scaffolds. Proceedings of the conference on computer support for collaborativelearning (pp. 573–574). Boulder, CO.Weinberger, A., Ertl, B., Fischer, F., & Mandl, H. (2005). Epistemic and social scripts in computer–supportedcollaborative learning. Instructional Science, 33(1), 1-30.Weinberger, A., Stegmann, K., & Fischer, F. (2007). Knowledge convergence in collaborative learning:Concepts and assessment. Learning and Instruction, 17(4), 416-426.Weinberger, A., Stegmann, K., & Fischer, F. (2010). Learning to argue online: Scripted groups surpassindividuals (unscripted groups do not). Computers in Human behavior, 26(4), 506-515.Wang, X., Yang, D., Wen, M., Koedinger, K., & Rosé, C. P. (2015). Investigating How Student's CognitiveBehavior in MOOC Discussion Forums Affect Learning Gains. In proceedings of the 8th InternationalConference on Educational Data Mining.Wang, X., Wen, M., & Rosé, C. P. (2016). Towards triggering higher-order thinking behaviors in MOOCs.In Proceedings of the Sixth International Conference on Learning Analytics & KnowledgeWen, M. (2016). Investigating Virtual Teams in Massive Open Online Courses: Deliberation-based VirtualTeam Formation, Discussion Mining and Support (Doctoral dissertation, Carnegie Mellon University).Wen, M., Maki, K., Wang, X., Dow, S. P., Herbsleb, J., & Rose, C. (2016) Transactivity as a Predictor of FutureCollaborative Knowledge Integration in Team-Based Learning in Online Courses. In Proceedings ofthe 9th International Conference on Educational Data Mining.Yeager, C., Hurley-Dasgupta, B., & Bliss, C. A. (2013). cMOOCs and Global Learning: An AuthenticAlternative. Journal of Asynchronous Learning Networks, 17(2), 133-147.AcknowledgementsThis work was funded in part by NSF grant ACI-1443068 and funding from Google.CSCL 2017 Proceedings32© ISLS