Designing for and Analyzing Productive Uncertaintyin Science InvestigationsEve Manz, Boston University, eimanz@bu.eduAbstract: This paper explores methods to design and analyze learning environments in whichuncertainty is incorporated into students’ activity to support the development of sciencepractices and content understandings. I describe how a second grade landforms investigationwas designed to incorporate productive uncertainty about the relationships betweenphenomenon, empirical investigation, evidence, and explanation. I then describe, apply, andreflect on an analytic method to trace uncertainty through (1) instantiation in the learningenvironment (2) recognition and introduction into conversation, and (3) conversations inwhich uncertainty supports participation in science practices.A major question in current research in science education is how to engage young students in the epistemicpractices of science in ways that are meaningful to them and powerful for the development of scienceunderstandings. Making progress on this challenge will involve (1) understanding what forms of practice aremost appropriate targets for young students, (2) developing principles for designing learning environments thatsupport meaningful engagement in practices, and (3) understanding the forms of support that allow teachers toorchestrate these learning environments.Recently, scholars have stressed the importance of establishing a need for science practices in learningenvironments. Researchers have argued that unless students participate in science practices in the context of“figuring something out,” those practices are likely to have little scientific meaning (Berland and Hammer,2012). They have stressed that learning environments should highlight disciplinary forms of uncertainty andallow students to grapple with them (Engle, 2011; Reiser, 2004). From this perspective, science practices areemergent from the learning environment, in the sense that students engage in and develop science practices fortheir own science activity (Cobb & Yackel, 2006). These approaches focus on the purposes of science practices,ask when those purposes are meaningful to young students, and use methods to analyze the local developmentof practices in classroom communities. This paper seeks to make a contribution to emergent approaches toscience practices: first by exploring how forms of uncertainty that are under-represented in learningenvironments can be productively built into young students’ science investigations, and second, by developing amethod for tracing the relationship between uncertainty and the emergence of science practices.Incorporating uncertainty into elementary science investigationsThe work reported here draws from socio-cultural and emergent approaches (Cobb & Yackel, 1996; Saxe, 2002)that treat practices as constituted and adapted in communities to solve shared problems. Scientific activity isdriven by the need to manage uncertainty; uncertainty not only about how to explain the world, but how torepresent the world in the form of an experiment, what to measure, and how to convince peers to see what thescientist wants them to see. These uncertainties manifest for scientists as decisions about what to do (e.g., whatthe best experimental design is), as push-back from empirical work (for example, in the form of surprisingexperimental results), and as critique from an audience (e.g., the disagreement of a peer about whether ameasure is appropriate) (Knorr-Cetina, 1999; Pickering, 1995). For scientists, uncertainties constitute sites forargumentation, explanation, and the development of new understandings. From this point of view, students needto experience some of this uncertainty if they are to engaging meaningfully in scientific practices and developan understanding of what those practices are for (Ford & Forman, 2006; Manz, 2015).Productive uncertainty in classroom learning environmentsWhen I refer to scientific uncertainty, I mean an aspect of scientists’ work that is non-obvious and contingent,which must be figured out by the scientist and negotiated in response to feedback from peers and the materialworld (Pickering, 1995; Rouse, 1999). I use the term productive uncertainty as a pedagogical construct todescribe an approach where students might profitably engage with scientific uncertainty, in the sense that bygrappling with some of the decisions scientists must make, students would make progress on scientific practicesand consent understandings. Constructs that I draw on include research on productive disciplinary engagementthat stresses the need to “problematize” content (Engle, 2011; Reiser, 2004), the use of “cognitively demandingtasks” (Henningsen & Stein, 1997), and “productive failure” (Kapur, 2008). I draw from these literatures toidentify three sets of principles for incorporating productive uncertainty in learning environments.ICLS 2018 Proceedings288© ISLSUnderstanding what to make uncertainStudents should engage in tasks designed to open up decisions or problems that are important from adisciplinary point of view, without so much ambiguity that the learner cannot engage with key uncertainties.Helping students experience, and make public, moments of uncertaintyStudents must recognize and engage with disciplinary uncertainties: there must be a moment where students feelpuzzled, see a conflict, or disagree with a member of the classroom community. These moments establish aneed to engage with disciplinary practices and content.Helping students resolve or learn from uncertaintyThere needs to be support to resolve or learn from the uncertain experience, in the form of tools that scaffoldstudents’ engagement and teachers guiding discussions where strategies and solutions are compared, and, whennecessary, introducing and unpacking next steps or canonical procedures and ideas.Empirical uncertainty as an under-leveraged resource in elementary classroomsDrawing from the Science Studies Literature (e.g., Gooding, 1990; Pickering, 1995), I conceptualize importantforms of uncertainty as emerging for scientists as they manage the transitions between the complex and materialphenomena they seek to understand, the empirical investigations that they use to “get a grip on” the world, theobservations and evidence that the investigations generate, and the explanations and explanatory models ofphenomena that are the targets of scientists’ work (Manz, 2015). The default assumption, represented in manycurricula and research-based interventions, is that the easiest entrée to scientific practice is to ask students toengage in highly simplified investigations so that they can learn to support claims with evidence, then laterproblematize what counts as evidence. The result is that forms of uncertainty that are central to scientific workare often obliterated or made invisible in elementary science investigations. For example, elementary studentsrarely are asked to consider how to design an experiment to represent a phenomenon, determine what to countas evidence, or consider misfits between the experiment and phenomenon as they apply their results tounderstand the world. Several studies have demonstrated that young students can recognize these forms ofuncertainty and productively grapple with them, but we know little about how to systematically design, andsupport teachers to orchestrate, environments that use empirical uncertainty to support scientific practices andunderstandings.Central conjectureDrawing from the three principles for productive uncertainty described above, I conjecture that forms ofempirical uncertainty that are typically removed from elementary students’ experience with experiments can beproductive for students’ development of scientific practices and content understandings. However, I alsoconjecture that for uncertainty to be productive, it must be strategically designed into the learning environmentand carefully managed by teachers.In particular, the conjecture that drives this study is that engaging students in a rich phenomenon andchoice in how to investigate it can generate variability in students’ methods, claims, and evidence; thisvariability can in turn be recognized and made public by students as they present and compare findings, in turneliciting sense-making discussions in which teachers support students to engage in science practices andconsider important content understandings. In previous work (Manz, 2015), I have explored this conjecture inone instantiation of students using a plant growth experiment to understand plant needs and growth patterns in awild backyard area. In this study, I sought to apply this conjecture to working with a small group of teachers, inorder to better understand the design elements in the learning environment and teacher discussion moves neededto support the implementation of productive uncertainty in empirical investigations. Below, I describe thecontext in which I enacted the study and the analytic methods developed to further test and refine the conjecture.Study ContextThis work was conducted in a suburban district in the Northeastern United States that had recently adopted newmaterials to better align to the state’s new standards, which are modeled on the Next Generation ScienceStandards (Achieve, 2013). The district elementary science leader approached the researchers to help her adaptthe curriculum materials to support deeper sense-making opportunities for young students. She recruited fivesecond-grade teachers to work with the research team on adapting one of their investigations. The teachersvaried in their years of teaching experience from 2 to more than 15 years of experience, in their science contentunderstandings, and in their comfort teaching science, as is typical of elementary teachers in the United States.ICLS 2018 Proceedings289© ISLSThe research team first supported the teachers to conduct an investigation that involved scientificuncertainty (in the sense that teachers had to make decisions about how to represent the phenomenon, what touse as evidence, and how to interpret their findings) and debrief how the need to make decisions and thedifferent decisions made supported sense-making, explanation, and argumentation. We then worked withteachers to adapt an investigation from the science kit used in their district to incorporate scientific uncertaintyas an opportunity for student sense-making. The focal investigation comprised two lessons from a landformsunit. In the investigation, students sprayed soil, sand, and gravel with water and blew on the materials through astraw to understand how wind and water can shape land. The kit did not provide direction for teachers tosupport students to think about how to represent wind and water, how to design an informative comparison,what data to collect, or how their findings allowed them to understand how wind and water might shape land.We worked with teachers over five meetings to create a shared set of lesson plans that spannedapproximately six 45 minute lessons. In the re-designed lessons, students examined photographs and discussedhow wind and water might shape land by moving earth materials; examined earth materials and madepredictions; designed investigations in groups using a straw and spray bottle to test their ideas; developed andsupported claims in small groups; presented and critiqued claims and evidence; and discussed the phenomenonagain based on their investigations. Table 1 shows how the sets of design principles for incorporating productiveuncertainty in learning environments were instantiated in this design.Table 1: Productive uncertainty design principles as instantiated in the landforms investigationDesign principleWhat to make uncertainHelping students experience andmake public moments of uncertaintyHelping students resolve and learnfrom uncertaintyAs instantiated in this design- Focus on allowing students to experience uncertainty about how torepresent a phenomenon in an experiment, how to constructevidence, how to interpret evidence, and how to use theirinvestigation to explain the phenomenon.- Bound uncertainty so that students make a limited number ofchoices (e.g., give students materials to use but allow them todecide how to use them)- Students design experiments in small groups- Allow student groups to come to different conclusions aboutwhether and how wind and water move the earth materials- Student presentations and student questions after experiments arecompleted- Examining original and new phenomena after experimentcompleted: share examples of movement (e.g., boulder in a field)that cannot be explained by investigation findings.- Teacher facilitation of discussion of differences in findings- Beginning and ending set of lessons with the same phenomenonMethodsA team of two researchers collected data over the course of the investigations, from the initial introduction ofthe phenomenon to the discussion of the phenomenon after students’ experiments were concluded. Four teachersconsented to videotaping. In these classrooms, one video camera was used to film whole group discussion andstudent groups during small group work. All classroom artifacts and student work were collected. In the fifthclassroom, researchers attended all lessons, took close field notes, and photographed artifacts.We next developed a method to test and refine the conjecture, which we represented as:Rich phenomenon + Choice in how to represent and investigate it  Variability in students’ initialideas, methods, claims, and evidence  Recognition and discussion of variability  Development ofpractice and conceptual understandings.This paper focuses on our initial development and application of methods to analyze the instruction intwo of the classrooms. We chose to begin with these two classrooms because we had complete records for themand because the teachers were the most likely to allow students to make decisions and then to discuss thosedecisions. Therefore, these data sets provided the richest opportunity for developing and refining analyticmethods. Because of the short time frame of the investigation, the data was used to support inferences aboutICLS 2018 Proceedings290© ISLSopportunities to participate in practices and consider content, rather than to detail development. Data analysisoccurred in four phases.Phase 1: Activity mapIn the first phase, we used field notes and classroom artifacts to create an activity map for each classroom thatsummarized the major shifts in activity and the video, artifacts, and student work associated with each activity.For example, activities for both classrooms during the first two days were discussing pictures of thephenomenon, examining earth materials and making predictions about whether wind and water can move them,whole group predictions, introducing the investigation, and small groups planning investigations. We organizedthe activities into three major stages: (1) Examining the phenomenon and making predictions, (2) Planning,conducting, and making claims in small groups, and (3) Sharing findings and discussing implications.Phase 2: Cataloguing and summarizing activityIn this phase of analysis, we moved systematically and sequentially through all video and classroom artifacts foreach classroom investigation. We developed focal categories for each stage of the investigation, independentlycoded and refined categories based on a sample of the data, then exhaustively sampled and coded the data for allepisodes or artifacts related to the focal categories.Phenomenon and predictions: How did students make sense of the phenomenon?For this stage, our focus was describing the aspects of the situation that students thought were relevant as theyexamined the phenomenon and the earth materials. These included: the size of the particles, the strength of thewind or water, explanations for how and why materials move (e.g., water makes soil heavier and harder tomove, water loosens dirt and then allows rocks to move). In addition, the predictions, and variability inpredictions, made by the class were summarized (e.g. all students agreed that wind could move sand, studentsdisagreed about water moving sand because some thought that sand might clump and not move).Conducting investigations: What forms of uncertainty were realized in the learning environment?For this stage, we focused on what forms of scientific uncertainty were realized in the learning environment.Following the study conjecture, we defined focal forms of uncertainty as decisions that students made abouthow to represent a phenomenon in an experiment, how to construct evidence, how to interpret evidence, andhow to use investigation to explain phenomenon. As indicators of students making decisions, we documentedteacher and student questions, variability in how groups made decisions, and evidence of disagreement anddiscussion during small group planning. For example, in each classroom, we documented the following forms ofuncertainty: the angle and distance that the straw was held in relation to the materials, what to use as evidence ofmovement, and what claim to make.Discussion: What forms of uncertainty were brought up and how were they addressed?In this investigation stage, students and teachers presented and discussed findings, agreed on a conclusion aboutthe investigation, and discussed the implications for understanding phenomena in the “real-world.” Wedocumented how the forms of uncertainty in Stage 2 were introduced by teachers and students in thesediscussions and analyzed when and how the introduction of the uncertainty supported moments where studentsengaged in science practices and explored new or deeper science content.Phase 3: Tracing uncertainty through each investigationIn this third phase of analysis, we developed a summary table for each classroom in which we followed eachform of uncertainty that students and teachers grappled with through the course of the investigation, with an eyetoward understanding: (1) how the uncertainty was realized in the learning environment, (2) how it wasintroduced into whole group conversation, and (3) whether and how it supported opportunities for whole-groupsense-making. Table 2 shows one row from this table for one teacher, following decisions generated around thestrength of the spray of the water bottle (as operationalized in distance the water bottle was held from thematerials, nozzle setting, and amount of water sprayed). Each sub-row refers to one instance of strength of spraythat was brought up in whole group conversation.ICLS 2018 Proceedings291© ISLSTable 2: Example row for forms of uncertainty summary table: strength and amount of water in Ms. A’s classForm ofuncertaintyStrength ofwatersprayed bythe spraybottle(How tooperationalizethephenomenon inan informativecomparison)Evidence that wesee theuncertaintyrealizedDifferent groupschoose differentnumbers ofsquirts in theirinvestigations.There is talkabout strength ofspray in groups(though nozzlesetting is set inMs. A’s class).Students seem tobe usingdifferentdistances invideo of groupsperforminginvestigations.How it was brought up in whole classdiscussionWhat happened170526_V3 [00:07:53.27]During a group’s presentation,student asks if the presenters plannedthe number of sprays they used.When group answers five, Tr.directs students to identify thatthis controlled the amount ofwater across conditions.170526_V3 [00:09:17.27] Researcherpoints out that class disagrees aboutclaims.Student notes that they might havedifferent ideas because somegroups sprayed harder.170526_V3 [00:12:12.23] Whenstudents are asked to generate awhole-class experiment, a studentpoints out amount and strength ofsprays as something to control.170526_V4 [00:02:13.08] Researcherasks why it matters that sand and soilget the same number of sprays.Tr asks why that’s important andevaluates the idea as important toexperimental design.170526_V4 [00:06:57.20]Tr. draws students’ attention to thespray bottle spraying less hard as itruns out of water.170526_V4 [00:07:53.15]When Tr. sprays, the bigger rocksmove. Tr. asks why they moved forher and not in group investigations.Student answers with control ofvariables response – experimentdoesn’t work the same if youchange the sprays, obviously thesand would move farther. Tr.briefly asks other students if theyagree.No student response invited.A student says that in herexperiment, they did rocks lastand maybe the bottle didn’t sprayas much.Phase 4: Developing themesIn this phase, the two researchers separately reviewed the summary forms for each of the two teachers anddeveloped memos to summarize the forms of uncertainty that emerged in each classroom, the ways that thesewere introduced into whole group conversation, and the kinds of conversations that emerged. We wereparticularly interested in understanding whether students or teachers were bringing up uncertainty, how teachersresponded to different forms of uncertainty, which forms of uncertainty appeared to be productive for sciencepractices and content understandings, and challenges that teachers and students faced. We then worked togetherto compare, discuss, and refine themes.FindingsTable 3 shows the forms of uncertainty that were realized in the learning environment, and the ways that thesewere introduced into classroom conversation. I first describe these columns more fully. I then share findingsabout how the introduction of these forms of uncertainty supported conversations that allowed students toengage in science practices and explore or deepen content understandings, and document challenges thatemerged as teachers guided these conversations.We documented similar investigation choices in each classroom; however, the choices that studentsgrappled with differed somewhat across the two classrooms. These differences appeared to be related to teacherchoices about how to introduce and guide the investigation. In each classroom, students made different choicesin how they positioned the straw and water bottle, how they arranged the earth materials (e.g., leaving them inthe petri dish, placing them in a mound out of the dish), and what they used as evidence of movement (e.g., aqualitative comparison of distance, measuring distance, separation in the petri dish, materials floating).ICLS 2018 Proceedings292© ISLSHowever, we also saw differences in the choices that were realized in students’ investigations acrossclassrooms. For example, in both classrooms, our videotape records provided evidence that at least one groupconsidered using the water bottle to make a pool of water. However, in Ms. B’s classroom this strategy was nottaken up; in fact, a classroom assistant working with the group redirected them to use the bottle to spray. In Ms.A’s class, a researcher intervened to make space for and amplify a student’s proposal to use the spray bottle tofill the petri dish, then put the materials into the dish and see how they moved when the water was moved. Incontrast, in Ms. B’s class, methods for marking and measuring distance were highlighted and encouraged, and agreater variability in measurement strategies was generated.Table 3: Forms of uncertainty realized in the learning environment and introduced into whole class discussionUncertaintyHow wind and watershape landWhat to use torepresent wind &waterHow to use straw:strengthClassMs. A,Ms. BMs. A,Ms. BWays introduced into whole class discussionStudents make different predictions about earth materials and draw ondifferent experiences; teachers highlight disagreement.Teacher asks students to consider, then introduces and provides rationalefor decision to use spray bottle and straw.MS. A,Ms. BHow to use straw:angle/directionHow to use spraybottle: form of water(rain vs. pool)How to use spraybottle: strengthMs. A,Ms. BMs. A,not fullyin Ms. B.Ms. A,Ms. BTeacher highlights as something to consider, students bring upspontaneously when asked how they are planning as something toconsider and control, students bring up as something to question eachother about, students bring up as accounting for different results, studentbrings up as something that the experiment doesn’t represent well aboutthe real world.Teachers highlight as something to consider.How to use spraybottle:angle/directionEarth materials invs. out of dishHow materials arearrangedOrder wind andwater are testedForm of evidencegenerated for windMs. A,Ms. BClaims about windMs. A,Ms. BForm of evidencegenerated for waterMs. A,Ms. BClaims about waterMs. A,Ms. BICLS 2018 ProceedingsPresenting students use different methods, students question each otherabout method, teacher introduces alternative (pool) as a method for wholeclass, students disagree about how alternative can generate evidence.Teacher points out as something to consider, students question each other,students generate as explanation of different results, students bring up assomething to consider when planning, teacher draws attention todifferences in joint experiment.Students ask questions, students bring up to explain different results,student disagreement about angle to use in joint test.Ms. A,Ms. BMs. A,Ms. B--Teacher brings up as something to consider and ask about; Students bringup as not representing world.Students bring up as something to ask each other about; students use toexplain different results (clumping materials, big vs. small rocks).Ms. A,Ms. BStudents introduce different evidence into conversation, students ask eachother about evidence, students ask to define what counts as evidence (e.g.,what counts as moving), teacher introduces and ratifies particular forms ofevidence (measuring distance), students disagree about evidence in jointinvestigation.Students introduce different claims into whole group discussion, studentspoint out disagreement in claims and generate explanations fordisagreement.Teachers ask about evidence in recaps, teachers ask student presentersabout evidence, students introduce different forms of evidence intoconversation, students ask each other about evidence and clarify evidence,students spontaneously compare evidence.Students introduce different claims into whole group discussion, studentsnote that their claims were different from other groups and seek to explain.293© ISLSIn the two classrooms, investigation choices were introduced in whole group conversation in ways thatpositioned students as making and justifying decisions; that is, as grappling with scientific uncertainty. First,teachers highlighted differences in what students were doing, probed student methods, and in one classroomasked students to make and justify decisions to develop a joint experiment. Students were positioned in theseconversations as navigating uncertainty about the angle and distance of the spray bottle and straw, how theyarranged materials, what they paid attention to in order to determine whether the earth materials moved, andwhat claims to make. In addition, these forms of uncertainty were introduced into conversation by studentswhen asked to talk about investigation decisions, suggesting that students were taking them up as legitimatedecisions that required sense-making. Importantly, we also noted that students brought up these decisions toaccount for different results, to question their classmates about, or to disagree with methods proposed by others.For example, students in Ms. A’s class quickly suggested that they likely used the straw differently after theyparticipated in a gallery walk that made visible that they had come to different conclusions. In addition, whengroups presented their claims and evidence, students asked each other about the angle and strength of blowingand spraying, clarified how far different materials had moved, and (most rarely) explicitly disagreed that amethod could be used to support a claim, as when a student disagreed that moving the materials in the petri dishshowed that they moved with water, because the tester was moving the dish, and therefore moving the materials.Analysis of the discussions demonstrated several teacher responses to the introduction of uncertainty.One response when teachers heard variability in decisions that might affect results was to ask questions to probewhat students had done and make differences visible to other students. Another was to highlight an idea that astudent brought up (for example, asking to compare the nozzle setting used by another group) as important,perhaps noting it on the board as something to consider or ask others about, then moving on. A third responsewas to open up a question or disagreement to talk by multiple students. A fourth was to effectively dismiss orargue against the concern: this was rarer, but informative, as it was most likely to occur in one classroom and attimes where the teacher was focusing on bringing the class to a joint conclusion, for example about how toconduct their joint investigation or to develop a conclusion that wind and water can move rocks, sand, and soil.Finally, we closely analyzed conversations to understand what opportunities they provided for studentsto participate in science practices and develop content understandings. Analysis suggested that when teachersmade space for student questions and for multiple turns of student talk, students had opportunities to engage inpractices related to investigations, in that they made decisions about and brought up the importance ofcontrolling variables, of considering the level of variables used in their experiments (e.g. the strength of theforce of the wind or water), and of considering how an investigation did and did not represent the phenomenon.They engaged in practices of argumentation they considered why their claims were different and probed eachother’s evidence. In addition, the investigation provided opportunities for students to engage in explanation asthey explored the reasons for their results, tried to understand differences in results (for example, there was alengthy conversation in Ms. B’s room about why a downward spray might exert force that moved rocks morethan sand), and explored why the investigation could not fully help them explain phenomena of wind and waterchanging land, often proposing new mechanisms for movement or making new connections to phenomena.We also noticed several challenges across both classrooms. First, during presentations, teachers ofteninterjected so often that students were actually able to ask each other relatively few questions. Second, we notedthat in discussions teachers only very rarely helped students relate the forms of uncertainty that they wererecognizing to the goal of trying to agree on a shared conclusion about the experiment or understand thephenomenon. That is, they were more likely to name something to consider (“We have to control that,” “you’rethinking about the real-world”) than to ask “Why would that matter?” or “Could that explain why…” Finally,we noted that students’ consideration of ways that the experiment might not represent the phenomenon of windand water shaping land appeared both to be particularly rich for the development of explanation and contentunderstandings, in that students were beginning to make visible the mechanisms by which wind and water shapeland, as well as particularly difficult for teachers to take up and guide, especially in the cases that theseconsiderations were at odds with either controlling variables or using evidence to support a shared conclusion.DiscussionThe conjecture that drove this work was that incorporating forms of empirical uncertainty that are typically leftout of elementary students’ empirical investigations can generate variability in ideas and methods that, whenrecognized and introduced into classroom conversation, can support productive episodes of sense-making inwhich students engage in scientific practices and make progress on content understandings. In this paper, Idescribed and applied an analytic method for cataloguing and following uncertainty to explore this conjecture.The analytic method is one that our research team is finding productive. In particular, we are finding ituseful to separately consider and relate the three related aspects of (1) uncertainty as realized in the learningICLS 2018 Proceedings294© ISLSenvironment through variability in student choices and thinking, (2) uncertainty as recognized by students andintroduced into conversation as a decision that requires sense-making and that might account for differences inresults, and (3) uncertainty as grappled with in conversation, potentially supporting science practices and sensemaking about content. Here, engaging in these three forms of analysis allowed us to document rich variability instudent decisions, show that students could recognize the importance of investigation decisions and initiateconversation about them, and explore opportunities and challenges in the ensuing conversations. I expect that allthree forms of analysis will be essential to generating learning environments where uncertainty is productive.We plan to more closely analyze the investigation as taught in all five classrooms to understand whichforms of uncertainty appeared most productive and which appeared at odds with each other (e.g. a focus oncontrolling variables and representing the phenomenon of wind and water shaping land) to inform the nextiteration of designing the investigation. We will then refine what is made uncertain (productive uncertaintydesign principle 1 above) to focus attention on those decisions that appeared to most productively support sensemaking and to help teachers attend to and draw out those uncertainties as a resource for science practices andunderstandings. I suspect that such a step; that is, generating more opportunities for uncertainty in the firstinstantiation in a design in order to understand which offer the greatest potential for student learning, is a fruitfulmove to make in designing for science practices and understandings.In addition, the similarities in the decisions that students grappled with suggest that certain forms ofuncertainty might be predictably generated and recognized by students in this investigation; this finding will befurther tested with the remaining three teachers, and if stable, could support the development of an investigationthat is legitimately uncertain for students but somewhat predictable for teachers. If this is the case, we couldbetter draw from practices used in mathematically cognitively demanding tasks, where teachers anticipate,select, and juxtapose different solution strategies (Stein, Engle, Smith, and Hughes, 2008) to support productivediscussion. Differences across instantiations (e.g., that in one classroom, where the teacher used gallery walksand highlighted disagreement, student were more likely to bring up variability in methods to account forfindings) can support the refinement of design principles for productive aspects of the learning environment andteacher moves that elicit and support uncertainty. Similarly, the consistent challenges that we noted, e.g.,teachers not discussing the implications of surfaced forms of uncertainty, can be used to refine conjectures andmethods of working with teachers, for example, by developing teacher moves. This work can support theimportant goal of moving past cookbook elementary school investigations while developing the supports thatteachers and students need to manage this more complex instantiation of scientific work.ReferencesAchieve, 2013. Next Generation Science Standards. Washington, D.C.: Achieve, Inc.Berland, L. K., & Hammer, D. (2012). Framing for scientific argumentation. Journal of Research in ScienceTeaching, 49(1), 68-94.Cobb, P., & Yackel, E. (1996). Constructivist, emergent, and sociocultural perspectives in the context ofdevelopmental research. Educational Psychologist, 31(3), 175-190.Engle, R. A. (2011). The productive disciplinary engagement framework: Origins, key concepts, anddevelopments. In D. Dai (Ed.), Design research on learning and thinking in educational settings:Enhancing growth and functioning. New York, NY: Routledge.Ford, M. J., & Forman, E. A. (2006). Redefining disciplinary learning in classroom contexts. Review ofResearch in Education, 30(1), 1-32Henningsen, M., & Stein, M. K. (1997). Mathematical tasks and student cognition: Classroom-based factors thatsupport and inhibit high-level mathematical thinking and reasoning. Journal for Research inMathematics Education, 28(5), 524-549.Kapur, M. (2008). Productive failure. Cognition and Instruction, 26(3), 379-424.Knorr-Cetina, K. (1999). Epistemic cultures: How the sciences make knowledge. Cambridge, MA: HarvardUniversity Press.Manz, E. (2015). Resistance and the development of scientific practice: Designing the mangle into scienceinstruction. Cognition and Instruction, 33(2), 89-124.Pickering, A. (1995). The mangle of practice: Time, agency, and science. Chicago, IL: University of ChicagoPress.Saxe, G. B. (2002). Children's developing mathematics in collective practices: A framework for analysis.Journal of the Learning Sciences, 11(2-3), 275-300.Stein, M. K., Engle, R. A., Smith, M. S., & Hughes, E. K. (2008). Orchestrating productive mathematicaldiscussions: Five practices for helping teachers move beyond show and tell. Mathematical Thinkingand Learning, 10(4), 313-340.ICLS 2018 Proceedings295© ISLS