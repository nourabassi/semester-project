Technology and Applications for Collaborative Learningin Virtual RealityScott W. Greenwald (co-chair), MIT Media Lab, scottgwald@media.mit.eduAlexander Kulik (co-chair), Bauhaus-Universität Weimar, kulik@uni-weimar.deAndré Kunert, Bauhaus-Universität Weimar, andre.kunert@uni-weimar.deStephan Beck, Bauhaus-Universität Weimar, stephan.beck@uni-weimar.deBernd Fröhlich, Bauhaus-Universität Weimar, bernd.froehlich@uni-weimar.deSue Cobb, University of Nottingham, sue.cobb@nottingham.ac.ukSarah Parsons, University of Southampton, s.j.parsons@soton.ac.ukNigel Newbutt, University of the West of England, nigel.newbutt@uwe.ac.ukChristine Gouveia, McGraw-Hill Education, christine.gouveia@mheducation.comClaire Cook, McGraw-Hill Education, claire.cook@mheducation.comAnne Snyder, McGraw-Hill Education, annie.snyder@mheducation.comScott Payne, McGraw-Hill Education, scott.payne@mheducation.comJennifer Holland, Google Inc., jennifermiller@google.comShawn Buessing, Google Inc., sbuessing@google.comGabriel Fields, MIT Media Lab, gabef@mit.eduWiley Corning, MIT Media Lab, wileycorning@gmail.comVictoria Lee, MIT Sloan School of Management, vylee@mit.eduLei Xia, MIT Sloan School of Management, leixia@mit.eduPattie Maes, MIT Media Lab, pattie@media.mit.eduAbstract: In this symposium we explore the immense potential for virtual reality to be appliedin educational settings. We discuss recent technological developments against a backdrop ofseveral decades of research. Six presentations, including four from academic authors and twofrom the commercial sector, will explore user requirements, new technologies, and practicalissues in collaborative VR applications for learning.Focus and issues addressedVirtual reality has long been touted for its potential to revolutionize education, with myriad advantages cited:access to remote experts, access to experiences that depend on scarce or access-limited resources (e.g. going tothe moon), and access to experiences that are physically impossible (e.g. such as standing inside a molecule), toname a few. A new generation of consumer hardware has made this vision more in-reach than ever. In thissymposium our interest is to understand what advantages of virtual reality in an educational context could orshould bring it into practice in the classroom, and what factors will determine when and how this will happen.Advantages named for collaborative virtual environments fall into two broad categories: those focusedon the interaction with other humans, and those focused on the environment. The human interaction may be novelbecause of who one can interact with (e.g. remote people), or how one can interact (e.g. taking on a differentphysical appearance). The environment may be novel because it is based on a physical place that only few peoplecan go, or because the experience it provides is inherently virtual (e.g. standing inside a molecule). In thissymposium we present research that sheds light on past, present, and future efforts to realize these advantages indifferent contexts. The first presentation will provide a brief history of virtual reality and its applications tolearning, culminating in the most recent wave of technology. The presentation of Cobb et al. will describe theapplication of non-immersive collaborative virtual environments to education of students with autism. In this case,the virtual environment provides a novel kind of interaction that is "safe" and structured in ways that the physicalworld is not, and this is leveraged in order to train social competencies such as collaboration. The presentation ofGouveia et al. will center around the successful introduction of a different kind of interactive technology in theclassroom -- namely simulation-based virtual labs -- that provide a novel non-immersive virtual environment.Parallels will be drawn in order to shed light on what factors may determine the success of introducing virtualreality in the classroom in the coming years. The presentation of Kulik et al. will discuss technology-basedresearch around multi-user interactions in novel immersive environments. This research has attempted to identifyand support the most important attributes of collaborative group work in these settings. The presentation ofHolland and Buessing will share early results from a large-scale effort to bring immersive collaborative virtualreality to the classroom. Finally, the presentation by Greenwald et al. will present technology-based research thatexplores non-verbal communication, collaborative creative expression, and the learning of abstract physicalCSCL 2017 Proceedings719© ISLSconcepts in an immersive virtual environment. By bringing all of these threads of research together in asymposium, we hope to gain a clearer understanding of the landscape of challenges and opportunities related tovirtual reality in formal and informal learning settings.Then and now: Positioning a new wave of research on VR and learningScott W. Greenwald, Victoria Lee, and Alexander KulikThis presentation provides a brief history of the technology and applications of virtual reality in the past severaldecades, including many involving training, education, and collaboration. The first wave of modern virtual realitytook place during the 1960s. Philco Corporation created the first head-mounted display named “Headsight” whichhad a screen and tracking system and was linked to a closed-circuit TV. The intent behind “Headsight” was totrain military personnel in tasks such as landing a high-speed aircraft, chemical and hazardous tests which couldbe watched from afar, or controlling a highly maneuverable submarine (Philco Corp, 2016). Although it was notconnected to a computer, “Headsight” pioneered the practice of leveraging virtual reality technology for learningand training purposes. Soon thereafter, Ivan Sutherland developed the first head mounted stereo display to linkwith a computer instead of a camera to display images (Sutherland, 1968).In the mid-1970s Myron Krueger created an interactive physical environment called “Videoplace”(Krueger). Instead of head-mounted displays, “Videoplace” used projectors and video cameras to supportinteraction, through the onscreen silhouettes of users. “Videoplace” demonstrated the potential of virtualenvironments for artistic and creative expression. Around the same time, the Wright-Patterson Air Force Base inOhio continued what “Headlight” had begun, experimenting with virtual reality simulations for training andeducation. By the late 1980s, they had launched the “Super Cockpit” program, a virtual cockpit to train pilots(Lowood, 2016). Shortly after “Super Cockpit”, NASA’s Johnson Space Center began using head mounteddisplay-based VR simulations to prepare astronauts. Although virtual reality was not widely adoptedcommercially following projects such as these, it played a crucial role in learning and training in these and severalother niche areas, including further military applications, medical research, and other academic research.Collaborative virtual environments (CVE) have a long history as well. Churchill and Snowdon publisheda thorough introduction to the topic in 1998 (Churchill 1998). They detailed the nature of collaborative andcooperative activities, and analyzed the realization of such behavior within networked virtual environments, usingseveral examples from the time. Referring to research on behavioral psychology, they emphasized the relevanceof nonverbal communication and indicated how this could be achieved in shared virtual environments - even usingdesktop-based systems with third-person viewpoints. Apparently, many learning goals can be effectively achievedin such settings (Dede, 1995; Cobb et al. 2010). Dede even argued that the synthetic and anonymous qualities ofthese early CVEs could have a positive effect on constructivist learning. However, this type of system was adoptedmore widely in entertainment rather than learning applications. Puppeteering a 3D avatar and monitoring otherson a computer screen is less direct and intuitive than equivalent activities in an immersive 3D space. Theattentional load required to operate the interface ties up cognitive resources that could otherwise be used forprimary activities, such as learning. However, early collaborative immersive VR systems generally did not supportembodied interaction and head-tracked egocentric viewing. One reason was that head-mounted displays hinderedthe perception of one’s own body and those of others, while large 3D displays generally supported only a singlestereo view.A few early research prototypes implemented collocated collaborative augmented reality systems, wherethe virtual 3D content is spatially aligned with the physical interaction space. The “Studierstube”, for example,used see-through head mounted displays for this purpose. A group of users could see the same 3D model andinteract with it in context of their real environment (Szalavari et al., 1998; Schmalstieg et al., 2002). Hua et al.equipped multiple users with head-mounted projectors (Hua et al. 2003). The walls of their interaction space werecovered with retroreflective materials such that each user saw their own personal perspective. Both projects alsoexplored the use of multiple independent viewing windows to support varying levels of collaborative coupling.Projection-based 3D display technology provides a different approach that has been extended forcollaborative use as well. The two-user “Responsive Workbench”, for example, showed four different images insequence on a CRT projector at 144Hz (Agrawala et al., 1997). Barco combined time sequential image separationwith polarization for two users with individual views at their “Virtual Surgery Table”. The approach was laterimproved with shuttered LCD-projectors supporting up to four users (Fröhlich et al., 2005) and more recentlywith a DLP-based system supporting up to six users (Kulik et al., 2011). Moreover, several special-purpose multiviewer displays have been proposed, based on separate display regions for each user’s stereo view (Arthur et al.,1998; Kitamura et al., 2001; Bimber et al., 2001; Mulder and Boschker, 2004). The drawback of this approach isthat it leads to a very small collaborative interaction space.CSCL 2017 Proceedings720© ISLSThese and other systems have powered more recent studies that seek to better understand humanbehavior, learning, and collaboration. A few examples include: how a virtual learning environment benefitseducation (Huang et. al.; 2010), how virtual reality encourages helping behavior and interpersonal understanding(Ahn et. al., 2013), or the effectiveness of virtual reality and overcoming phobias (Garcia-Palacios et al., 2002).In the past several years, virtual reality technology has experienced a resurgence. Innovations in thedesign and manufacturing of the relevant devices has led to the availability of cheap and robust VR hardware,including wide field-of-view, high-resolution headsets and submillimeter precision tracking technology. As of2016, there were 43 million active users of virtual reality and that number is forecasted to grow, reaching 171million by 2018 (Statista, 2016). When the era of personal computing expanded in the 1990s, a new generation ofusers, developers, and researchers emerged, and we propose that there is a parallel with what is happening nowwith virtual reality. Given the prior success of virtual reality in education and training for niche applications, webelieve that the broader exploration of use cases, enabled by the new generation of hardware coupled with thepower of the internet, will result in many more successes. It will empower educators and learners with new toolsand a new medium, improving communication, collaboration, and co-creation.Collaborative virtual reality for joint learning experiencesAlexander Kulik, André Kunert, Stephan Beck, Bernd FröhlichVirtual reality systems promote situated learning through the immersive experience of interactive objects,environments and processes. Egocentric 3D viewing supports self-paced data exploration and bears the potentialto increase the users’ identification with the topic at hand. However, head-mounted displays also decouple users’from the perception of their own body and their immediate physical and social environment. This in turn canhinder the comprehension of the displayed content. For example, it is commonly understood that depth perceptionis disturbed in virtual environments. However, representations of self and the immediate physical environmenthave been shown to ameliorate this effect (Interrante et al., 2008; Mohler et al., 2010; Phillips et al., 2010).Perhaps, comprehension can be understood as the establishment of robust relations between oneself and the topicof interest.Moreover, learning is largely driven by exchange with peers. This can be particular relevant, if it comesto the interpretation of complex and ambiguous information. The immediate exchange between students can helpto consider multiple perspectives and also to confirm the most probable interpretations. Direct interaction andmixed-initiative communication promote the ongoing discourse on a topic. We also learn by doing. Therefore,virtual environments for learning should be highly interactive. Ideally, multiple learners can interact jointly withthe virtual environment and thereby reinforce their understandings. Support for joint action, however, mustconsider several planned and emergent coordination processes, all of which build on the spatiotemporal coherencyof the shared interaction space (Knoblich et al., 2011). Gutwin and Greenberg highlighted how people achieve thenecessary workspace awareness in physical environments through consequential communication, feedthrough,and intentional communication (Gutwin & Greenberg, 2002).We believe that the unmitigated perception of self and others is a prerequisite for effectivecomprehension, learning and exchange. Therefore, we developed projection-based virtual reality systems that donot limit the users’ perception of their immediate surroundings (i.e. workspace awareness), but that additionallyprovide them with multiple individual viewpoints towards a shared 3D scene (Kulik et al., 2011). The result is acoherent mixed reality of virtual objects, environments, and multiple collaborating users. We observe that directmutual exchange about the digital content increases their relevance for users and supports mutual confirmation(Figure 1). Our studies show that users can build on body language and deictic gestures just as they do with realworld objects and that collaborative visual search increases the understanding of all involved users (Salzmann etal., 2009; Kulik et al., 2011).More recently, we extended these systems with support for remote collaboration of groups (Beck et al.,2013). Our group-to-group telepresence system captures users in real-time with clusters of color and depthcameras. The data is then transmitted over the network and the users can be reconstructed at life size in the sharedvirtual environment. These 3D video avatars are far from perfect, but they are perceived as an authentic dynamicrepresentation of the remote collaborators’ activities and appearances, which does not seem to induce uncannyfeelings among participants. Our study showed that body language, in particular, deictic gestures and those tomanage turn taking can be well supported with such a system. However, in direct comparison with collocatedcollaborators, the perceived co-presence of these avatars is limited (Figure 2). We are planning to study the effectsof such mediators on social behavior and the effectiveness of collaborative learning with remote participants invirtual environments.CSCL 2017 Proceedings721© ISLSFigure 1. Two users discussing details of acombustion engine using a box-shaped cross sectionview.Figure 2. Collaborative wayfinding in a telepresencesetting. The remote user is captured and representedas a 3D video avatar in the virtual environment.(Vianden Castle model courtesy of ArcTron 3D)As most collaborative actions, also learning requires certain levels of individual autonomy. It has been shown, forexample, that brainstorming sessions can be ineffective if the setting does not allow participants to work aloneand take individual responsibility (Sawyer, 2008, pp. 64-66). Therefore, interfaces for multi-user cooperationshould support fluent transitions between individual activities and varying levels of collaborative coupling. Loosecoupling can increase the diversity of contributions, while tight coupling is required to achieve mutual agreementand convergence towards intermediate resolutions. Support for territoriality as an emergent social behavior seemsto be a pragmatic, yet powerful, design principle in that regard (Scott et al., 2004). User interfaces for collaborativelearning should thus provide multiple interaction areas and support dynamic spatial restructuring (Figure 3; Kunertet al., 2014).Figure 3. A large 3D powerwall (back) and amultitouch 3D tabletop (front) serve as independentmulti-user 3D viewports into a shared virtual world.A virtual 3D display, or portal (center, with whiteframe), offers additional perspectives. The physicaland virtual viewports serve for private interaction andgroup exchange.Their combination in a coherent workspace supportsfluent transitions between tightly and loosely coupledcooperation. Here, a multi-scale 3D scan ofprehistoric rock art and its environment(Valcamonica, Italy) is explored.Designing collaborative virtual environments for interaction and learning inchildren with autism.Sue Cobb, Sarah Parsons, Nigel NewbuttThis presentation will use examples drawn from projects where we have developed applications using virtualreality technologies (VRTs) for children with autism. We plan to provide a context to the work we have completedin addition to a critical reflection and evaluation of involving stakeholders (teachers, students, relatedprofessionals) in the co-design and production of the materials, which are intended to be used in schools. The firstproject, COSPATIAL (2009-2012), developed collaborative virtual environments to encourage participation insocial communication and collaboration amongst young people with autism. We focus on the Block Challengegame designed specifically to support student pairs in communicative perspective-taking and reciprocal cooperation in a collaborative block building task [Figure 1 and Figure 2] (Cobb et al. 2010) and present findingsfrom an intervention study which suggest that CVEs can provide an educational context for learning and rehearsalof social communication, perspective-taking and reciprocity that can be effectively scaffolded by teachers(Parsons, 2015). The second project, VIRTAUT (2010-2013), sought to design a virtual world that would enablesocial skill opportunities, collaboration and participation in a virtual world via avatars and was implemented in aclassroom-based setting [Figure 3 and Figure 4] (Newbutt, 2014). We will draw out specific examples whereCSCL 2017 Proceedings722© ISLSstakeholder involvement shaped the design and practice of using the virtual worlds in the classroom, was built inand the nature of working with autistic children.Figure 1. Each payer has a separate screen interfacedisplaying their own avatar perspective within thevirtual environment and the target block towerpattern that they need to build.Figure 3. The VIRTAUTcollaborative virtual world provideda safe context for social interactionand communication between players.Figure 2. Building the tower to satisfy the differenttarget patterns for each player requirescommunication, negotiation and collaborativeinteraction between the players.Figure 4. Involvement of educational stakeholders including both theschool and local educational authority was important to identifycontextual considerations to inform effective design.In each of the projects the design process involved a variety of stakeholders each with different perspectives andobjectives for the project outcomes. We will describe and reflect on the application of the 3T model of learnercentred design that determines CVE design based upon relevant learning Theory, Technology affordances andThoughts (stakeholder-informed requirements) as a suitable framework to inform the design and development ofeducational technologies (Parsons and Cobb, 2014). In addition, the process of co-design identified varioustechnological challenges with applying VRTs in situ (Newbutt, 2013). We will consider the opportunities andchallenges of designing innovative technologies for special education, and specifically the affordances of VRTsfor autistic user groups. In doing so we will consider ways to navigate these challenges and some best practice wehave identified in design CVEs across the projects identified above. We hope to also highlight aspects of thedesign process that led to supporting interactions and learning in VR spaces. Future directions and priorities forresearch in this area will be presented.“Nice to Have” to “Can’t Do Without”: Aligning simulations and VR with currentneeds in the K-12 classroomChristine Gouveia, Claire Cook, Anne Snyder, and Scott PayneHow can immersive VR technologies be meaningfully and effectively incorporated into K-12 classroominstruction? To explore this question, we turn to a recent innovation that is closely related to immersive VR -simulation-based lab activities for science instruction -- as an example of a technology that has been successfullyintegrated. Using these simulations as a case study, we examine the factors that have led to this success, andconsider how they may inform the future of immersive VR technologies in a classroom context (Merchant et al.,2014; De Jong et al., 2013; Rutten et al., 2012; Toth et al., 2014).For example, we ask: what learning experiences can a given technology enable that would not otherwisebe possible using traditional approaches? Simulations and VR both have the potential to serve, not just as adequatesubstitutes for traditional / low-tech counterparts, but often as superior substitutes, when deployed in appropriatecontexts and implemented in the right ways. We discuss the learning sciences research that both motivates andconfirms the pedagogical value of simulations (and VR) for science learners; and we dig deeper into the practicalconsiderations which help to propel its growing adoption among teachers. Among those practical considerationsCSCL 2017 Proceedings723© ISLSare those which bear on equity and access for K-12 learners. We argue that it is this parallelism between thepedagogical and practical which is key for an innovative alternative to take hold broadly and have staying powerin a classroom context.As developers continue to create and extend more sophisticated VR technologies, we survey the essentialrealities of the K-12 classroom that are important to consider, in order to ensure that emerging and evolving VRtechnologies solve a problem for users -- such that they will be broadly embraced and viewed as enabling essentiallearning experiences, rather than as fringe “add-ons” to more traditional curricula. We then invite participants tojoin us in examining what is perhaps the most important question of all: what problems can immersive VRtechnologies solve for K-12 teachers?Principles, challenges, and lessons learned through developing a commercialplatform for virtual reality in the classroomJennifer Holland and Shawn BuessingGoogle Expeditions is a virtual reality teaching tool that lets you lead or join immersive virtual trips all over theworld — get up close with historical landmarks, dive underwater with sharks, even visit outer space! Built for theclassroom and small group use, Google Expeditions allows a teacher acting as a “guide” to lead classroom-sizedgroups of “explorers” through collections of 360° and 3D images while pointing out interesting sights along theway. We’ll talk specifically about:● Principles of educational content that we are finding effective for teachers of students● Talk through why it’s not easy to just repurpose legacy educational content into VR form and whymany traditional educational publishers will have to rethink how they approach it● Share specific examples and usage patterns in schools and countries● Talk about specific hardware challenges with large group use of VRExploring same-time, same-place collaboration in room-scale virtual realityScott W. Greenwald, Wiley Corning, Gabriel Fields, Lei XiaThis presentation will summarize our explorations of same-time, same-place interaction in room-scale virtualreality with a focus on learning. As a baseline form of interaction, users are represented using minimal avatars inthe virtual space in positions exactly corresponding to their actual physical positions. The avatars consist of semirealistic representations of the headset and handheld controllers. The positions and orientations of these areupdated to match their physical ones at 90Hz, giving their movement a very life-like appearance. My team hasexplored two different research questions related to this style of interaction. Firstly, we seek to understand thecapacity of this medium (as described) to carry symbolic and emotive signals, typically carried not only by bodygestures and movement, but also facial gestures and expressions. Second, we explore how one or more users caninteract with and learn from simulation-based environments. This combination of questions is driven by thehypothesis that the combination of social and exploratory learning is particularly powerful in virtual reality.We are currently developing an application, CocoVerse, which provides users with a suite of capabilitiesfor creation and expression in a shared virtual environment. For example, users can draw volumetric shapes, addvirtual objects and images to the environment and position them in space, write with speech-to-text, and takevirtual snapshots and selfies. We structure this range of functionality within a set of discrete, easily-accessibletools, helping users to quickly learn and mentally compartmentalize the affordances available to them. In alearning application, teachers can lecture in 3D space for a live audience of students. Users can learn by interactingwith simulated dynamics, or by exploring and annotating datasets or captured environments. Initial tests haveshown the design to be learnable and usable. The modular codebase allows the application to be easily extendedand customized to create domain-specific experiences, and we are collaborating with developers, instructors, andresearchers to expand the set of use cases covered by our feature set, and identify cross-cutting design principles.In order to explore how social learning works in a simulation-based environment, we selected a concreteuse case -- a virtual reality physics environment, focused on university-level electricity and magnetism. Theenvironment allows one or more people to explore the interaction of charged particles. In doing so, they gaininsight into the dynamics of these interactions, as well as how these relate to the exact shape, form, andsignificance of the electric field generated by the particles. One of the general challenges in multi-user interactionswith simulations is the sharing of control. In this case, where both users are free to place or drag charged particlesin space, there are few conflicts to be concerned with -- the nature of the simulation lends itself to parallelCSCL 2017 Proceedings724© ISLSinteraction. One shared capability is the play/pause button that allows users to freeze the action of the systemtemporarily.In our informal pilot studies, we identified some requirements related to the usage of such systems as acentral element of curricular education. Although it is motivating and fun to interact with such a "playground,"learners often require guidance in order to discover noteworthy phenomena or principles. We are exploring howto build scaffolding to balance guidance with self-direction for this use case.ReferencesAgrawala, M., Beers, A. C., McDowall, I., Fröhlich, B., Bolas, M., & Hanrahan, P. (1997, August). The two-userResponsive Workbench: support for collaboration through individual views of a shared space. InProceedings of the 24th annual conference on Computer graphics and interactive techniques (pp. 327332). ACM Press/Addison-Wesley Publishing Co..Ahn, S.J., Le, A.M.T., & Bailenson, J.N. (2013). The effect of embodied experiences on self-other merging,attitude, and helping behavior. Media Psychology, 16 (1), 7-38.Arthur, K., Preston, T., Taylor, R., Brooks, F., Whitton, M., & Wright, W. (1998, May). Designing and buildingthe pit: a head-tracked stereo workspace for two users. In 2nd International Immersive ProjectionTechnology Workshop (pp. 11-12).Beck, S., Kunert, A., Kulik, A., and Fr ̈ohlich, B. (2013). Immersive group-to- group telepresence. Visualizationand Computer Graphics, IEEE Transactions on Graphics, 19(4):616–625.Bimber, O., Fröhlich, B., Schmalstieg, D., & Encarnação, L. M. (2006, July). The virtual showcase. In ACMSIGGRAPH 2006 Courses (p. 9). ACM.Churchill, E.F. & Snowdon, D. Virtual Reality (1998) 3: 3. doi:10.1007/BF01409793Cobb, S, Millen, L, Glover, T, Hawkins, T, Patel, H, Eastgate, R, Parsons, S and Garib-Penna, S. . (2010).Collaborative VE: Experience Report and Prototypes. FP7 Deliverable report 4.1.2 for the COSPATIALproject. Available at http://cospatial.fbk.eu/deliverables [last accessed 23.10.15]Dede, C. (1995). The evolution of constructivist learning environments: Immersion in distributed, virtual worlds.Educational technology, 35(5), 46-52.De Jong, T., Linn, M. C., & Zacharia, Z. C. (2013). Physical and virtual laboratories in science and engineeringeducation. Science, 340(6130), 305–308.Fröhlich, B., Hochstrate, J., Hoffmann, J., Klüger, K., Blach, R., Bues, M., & Stefani, O. (2005). Implementingmulti-viewer stereo displays.Garcia-Palacios, A., Hoffman, H., Carlin, A., Furness, T., & Botella, C. (2002). Virtual reality in the treatment ofspider phobia: a controlled study. Behaviour Research And Therapy, 40(9), 983-993.http://dx.doi.org/10.1016/s0005-7967(01)00068-7Gutwin, C. and Greenberg, S. (2002). A descriptive framework of workspace awareness for real-time groupware.Comput. Supported Coop. Work, 11(3):411–446.Huang, H. M., Rauch, U., & Liaw, S. S. (2010). Investigating learners’ attitudes toward virtual reality learningenvironments: Based on a constructivist approach. Computers & Education, 55(3), 1171-1182.Interrante, V., Ries, B., Lindquist, J., Kaeding, M., and Anderson, L. (2008). Elucidating factors that can facilitateveridical spatial perception in im- mersive virtual environments. Presence: Teleoperators and VirtualEnvi- ronments, 17(2):176–198.Kitamura, Y., Konishi, T., Yamamoto, S., & Kishino, F. (2001, August). Interactive stereoscopic display for threeor more users. In Proceedings of the 28th annual conference on Computer graphics and interactivetechniques (pp. 231-240). ACM.Knoblich, G., Butterfill, S., and Sebanz, N. (2011). Chapter three - psycholog- ical research on joint action: Theoryand data. In Ross, B. H., editor, Advances in Research and Theory, volume 54 of Psychology of Learningand Motivation, pages 59 – 101. Academic Press.Krueger, M. (1991). Artificial reality II (1st ed.). Reading, Mass.: Addison-Wesley.Kulik, A., Kunert, A., Beck, S., Reichel, R., Blach, R., Zink, A., & Froehlich, B. (2011). C1x6: a stereoscopic sixuser display for co-located collaboration in shared virtual environments. ACM Transactions on Graphics(TOG), 30(6), 188Kunert, A., Kulik, A., Beck, S., and Fr ̈ohlich, B. (2014). Photoportals: Shared references in space and time. InProceedings of the 17th ACM Conference on Computer Supported Cooperative Work & SocialComputing, CSCW ’14, pages 1388–1399, New York, NY, USA. ACM.Merchant, Z., Goetz, E. T., Cifuentes, L., Keeney-Kennicutt, W., & Davis, T. J. (2014). Effectiveness of virtualreality-based instruction on students’ learning outcomes in K-12 and higher education: A meta-analysis.Computers & Education, 70, 29–40.CSCL 2017 Proceedings725© ISLSMulder, J. D., & Boscker, B. R. (2004, March). A modular system for collaborative desktop vr/ar with a sharedworkspace. In Virtual Reality, 2004. Proceedings. IEEE (pp. 75-280). IEEE.Mohler, B. J., Creem-Regehr, S. H., Thompson, W. B., and Bu ̈lthoff, H. H. (2010). The effect of viewing a selfavatar on distance judgments in an hmd-based virtual environment. Presence: Teleoperators and VirtualEn- vironments, 19(3):230–242.Newbutt, N. (2013). Exploring Communication and Representation of the Self in a Virtual World by YoungPeople with Autism. PhD Assistive Technology, University College Dublin, Education.Newbutt, N. (2014). Representations of self in a classroom virtual world: A case-study of pupils on the autismspectrum. In: Felicia, P (Ed) Game-Based Learning: Challenges and Opportunities, Cambridge ScholarsPublishing, p. 165.Parsons, S and Cobb, S (2014). Reflections on the role of the ‘users’: challenges in a multidisciplinary context oflearner-centred design for children on the autism spectrum. International Journal of Research and Methodin Education. 37 (4), 421-441.Parsons, S (2015). Learning to work together: Designing a multi-user virtual reality game for social collaborationand perspective-taking for children with autism. International Journal of Child-Computer Interaction, 6,28-38.Philco Corp,. (2016). Remotely controlled remote viewing system. United States.Phillips, L., Ries, B., Kaeding, M., and Interrante, V. (2010). Avatar self- embodiment enhances distanceperception accuracy in non-photorealistic immersive virtual environments. In 2010 IEEE Virtual RealityConference (VR), pages 115–1148. IEEE.Rutten, N., van Joolingen, W. R., & van der Veen, J. T. (2012). The learning effects of computer simulations inscience education. Computers & Education, 58(1), 136–153.Salzmann, H., Moehring, M., and Froehlich, B. (2009). Virtual vs. real-world pointing in two-user scenarios. In2009 IEEE Virtual Reality Conference, pages 127–130. IEEE.Sawyer, K. (2008). Group genius: The creative power of collaboration. Basic Books.Schmalstieg, D., Fuhrmann, A., Hesina, G., Szalavári, Z., Encarnaçao, L. M., Gervautz, M., & Purgathofer, W.(2002). The studierstube augmented reality project. Presence: Teleoperators and Virtual Environments,11(1), 33-54.Sebanz, N., Knoblich, G., and Prinz, W. (2003). Representing others’ actions: just like one’s own? Cognition,88(3):B11–B21.Statista. (2016). Number of active virtual reality users worldwide from 2014 to 2018 (in millions).http://www.statista.com/statistics/426469 (retrieved 11/19/2016).Sutherland, I. E. (1968). "A head-mounted three dimensional display". Proceedings of AFIPS 68, pp. 757-764Szalavári, Z., Schmalstieg, D., Fuhrmann, A. et al. Virtual Reality (1998) 3: 37. doi:10.1007/BF01409796Toth, E. E., Ludvico, L. R., & Morrow, B. L. (2014). Blended inquiry with hands-on and virtual laboratories: therole of perceptual features during knowledge construction. Interactive Learning Environments, 22(5),614–630.Vpl Research, Inc,. (1991). Computer data entry and manipulation apparatus and method. US.CSCL 2017 Proceedings726© ISLS