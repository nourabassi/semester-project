Connected Biology: A Usability Study of Web 2.0 ToolsSilvia d’Apollonia, Dawson College, sdapollonia@place.dawsoncollege.qc.caSuzanne Kunicki, Dawson College, skunicki@place.dawsoncollege.qc.caMurray Bronet, John Abbott College, murray.bronet@johnabbott.qc.caAbstract: We incorporated traditional conceptual knowledge in an introductory Biologycourse into a Web2.0 learning environment, which we called Connected Biology. Wesubsequently investigated whether faculty and students using it for 15 weeks found it useful.We used Crazy Egg (a commercial tracking site) to track students’ use of Connected Biologyand their use of Web 2.0 tools. Students found Connected Biology useful (learnable,memorable, satisfying, and error-free) but not efficient. Although they accessed ConnectedBiology over 15 weeks, they tended to use it primarily to get feedback on their understandingof course content and not for exploratory activities. Interviews with faculty teachingintroductory science courses indicated that most hold to a prescriptive learning model. Thepaper argues that we need to attend to the prevailing culture of introductory science courses(both student and teacher) before introducing Web 2.0 tools. Only then will the affordances ofWeb 2.0 tools be attained.Keywords: web 2.0 tools, usability, data-mining, data-trackingIntroductionSteve Hargadon (2009) summarizes the belief held by many educators that the expectation that computers wouldrevolutionize education has not happened. Computers have made the delivery and assessment of learning easier;but if they were suddenly to disappear from our classrooms, teaching would not change by much. One reasonfor this, somewhat surprising conclusion, is that until recently, the technology used, Web 1.0, used a traditionalone-way information flow, with content flowing from the source (educational media and teacher) to thestudents. In other words, it used a “push” technology with information being “dumped” on the student accordingto the goals and scheduling constraints determined by the educator. However, this has radically changed withthe development of Web 2.0 (Brown, 2006). Web 2.0 technologies facilitate conversations around academicconcepts, artifacts (images and videos), and data collections (databases and spreadsheets) in which the “ThreeR’s have been supplanted by the “Three C’s: Contributing, Collaborating, Creating” (Hargadon (2009, p8)through tools such as Facebook, Twitter, Wiki’s, Voicethreads, etc.Canole and Alevizou (2010) conducted a literature review of the use of Web 2.0 tools in HigherEducation using both traditional and Web 2.0 methodologies. That is, in addition to accessing the usualacademic sources (peer-reviewed journals articles and books), specialized databases (ERIC, Informaworld, etc.)and GoogleScholar, they conducted an “open review” using the Cloudswork site (http://cloudworks.ac.uk/).They define the open review process as one that “uses a social networking space to aggregate and collectivelydiscuss an evolving body of literature around a set of core research questions” (Canole &Alevizou, 2010 p 6).They found that despite the affordances of Web 2.0 tools to promote radical transformation of learning, moststudents use technology for convenience (51%) and to facilitate course management (19%). The effectiveadoption of Web 2.0 tools into education practice by teachers also requires a change in the role of teachers andteaching. Overall, “only a minority of teachers, those with a research interest in the learning sciences,educational technology, or new media, have undertaken experimentation with new innovations in pedagogy”(Carole & Alevizou, 2010, p21). They cproposed several paradoxes to explain the low adoption of Web 2.0tools by post-secondary faculty. They may fear that the the huge expansion of knowledge devalues expertise,that the fragmented, multi-located structure of networks destroys the integrity of domain knowledge structures,that the blurring of boundaries promotes plagerism, and that the social nature of learning networks harmsindividual learning at the expence of “group think”.Williams, Karousou, and Mackness (2011) contrast two learning environments: emergent andprescriptive. They associate the use of Web 2.0 tools with emergent learning networks and argue that both arerequired in an integrated learning ecology. The challenge becomes to design an effective balance between thetwo.Many teachers, realizing the importance of incorporating active-learning participatory technologies intotheir teaching practices, do make the attempt; however, many, if not most, ultimately fail to sustain their efforts(Messina, Reeve & Scardamalia, 2003; Moreau, 2001). This has often been interpreted as a failure in theirCSCL 2015 Proceedings55© ISLSknowledge, effort, or available resources. However, an alternative interpretation is that features of the attemptedimplementation, per se, are at fault. That is, although the utility of the implementation is usually investigated,the usability of the implementation was not systematically tested. Usability in this context, is the degree towhich an implementation meets the needs of the users (both teachers and students) by being learnable, efficient,memorable, satisfying, and error-free (Usability Professionals Association, 2009).The goal of this paper is to investigate the usability of an implementation, herein called ConnectedBiology, incorporating Web 2.0 features.MethodsThis project used the methodology of a design-based research (Brown, 1992; Amiel & Reeves, 2008), toinvestigate the usability and utility of Connected Biology. Thus, we used ethnographic , questionnaire, andtracking methodologies. More specifically, we interviewed teachers, assessd students’ perception of theusability of Connected Biology, and useed Crazy Egg (https://www.crazyegg.com) , a commercial trackingservice similar to Google Analytics to track the number of visits and clicks made by students as well as wherethey clicke. Heat maps show where students stop scrolling and leave the page.ParticipantsThe participants were faculty and their students taking an introductory Biology course in a large urbancommunity college. The students were 17-19 years old, in the pre-university science program, with an equaldistribution of males and females (ie they're supposed to be digital natives.. Teachers were invited to participatein modifying and using Connected Biology in their courses.InterventionThe intervention, Connected Biology, consisted of a web site which is acessed via a home page which includes avideo, links to Science sites and an outline of the topics covered by the course. Each of the topics is linked to atopics page which includes the following elements: Pre-class Exercises (designed to prepare the students for theupcoming class), Classes (designed to outline the activities done in class), Consolidation exercises (designed tohelp students secure their learning), and the associated Learning Objectives (designed to guide students in theirstudying). The associated Web 2.0 tools associated with these elements are links to external sites, simulations,videos, images, a hot-linked glossary, on-line crossword puzzles, on-line concept mapping exercises, practicequestions providing immediate feedback, links to on-line quizzes, and summaries of the content. Classes wereheld in an Active Learning Classroom, containing 6 tables, each with a Smartboard. There were 6-7 students pertable. In addition, students used a class conference on First Class (a collaboration platform) to access theirteacher’s materials and communicate with each other and their teacher. The students were encouraged but notrequired to use any of these elements.AnalysisQuantitative analysisQuestionnaires and tracking data were analyzed using descriptive and inferential statistics.Qualitative analysisInterviews with teachers were transcribed and coded into pre-existing categories that reflected the researchinterest.FindingsStudent survey of usabilityWe collected data on students’ perception of the usability of Connected Biology after the unit on Cell Structureand Function, after the unit on Cell Division, and after the unit on Evolution. The maximum score on the surveywas 25. Table 1 shows the changes in students’ perception of usability over the three units.There was a significant difference in students’ perception of the usability of Connected Biology overthe three sessions (F = 10.57 df = 3,119 p = 0.0001). Students rated the usability of Connected Biology lowerfor the unit on Cell Division (Mean = 16.0) than they did for the units on Cell Structure and Function (Mean =18.1) and Evolution (Mean = 18.7).CSCL 2015 Proceedings56© ISLSTable 1: Descriptive statistics (mean and standard deviation) for students’ perception of usabilityUsabilityScoreCell Structure(N=32)meansdCell Division(N=31)meansdEvolution(N=32)meansd18.116.018.73.20.933.6The survey measured 5 aspects of usability; i.e., was the implementation Efficient, Free from Error,Learnable, Memorable, and Satisfying. Table 2 shows these aspects of usability over the three units.Table 2:Descriptive statistics (means and standard deviation) for students’ perception of aspects of usability.Usability AspectEfficientError FreeLearnableMemorableSatisfyingCell Structure(N=32)meansd3.60.823.40.643.90.813.90.843.30.75Cell Division(N=31)meansd2.90.433.10.493.30.353.10.283.60.34Evolution(N=32)meansd3.30.933.70.684.00.854.10.943.60.87There was a significant difference in students’ perception of the efficiency (p = 0.002), freedom fromerrors (p = 0.002), learnability (p = 0.001) and memorability (p = 0.0001) of Connected Biology over the threesessions (F = 6.6 df = 10, 178 p = 0.0001). Students rated these aspects of the usability of Connected Biologylower for the unit on Cell Division than they did for the units on Cell Structure and Function and Evolution.Moreover, their responses on the usability for the unit on Cell Division were much more consistent (see Figure1).Figure 1. Distribution of students’ responses to the efficiency of Connected BiologyTracking of students use of Connected BiologyStudents’ visits, clicks, and scrolls were collected by Crazy Egg, a commercial tracking site(http://crazyegg.com). Figure 2 illustrates the number of visits to the home page of Connected Biology duringthe intervention.Students visited Connected Biology between weeks 2 and 3, on week 12, and on week 15. Thereappears to be a novelty effect, in that students visited Connected Biology in large numbers at the beginning ofthe intervention; but less so as the semester progressed. Students may also have been tired at the end of thesemester since their workload may have increased over the semester. The data suggests that students began tovisit Connected Biology to prepare for the final exam on week 12 but stopped visiting it while they werepreparing for their lab test and presentation of their research project (neither of which was covered byConnected Biology).CSCL 2015 Proceedings57© ISLS- Cell Structure was covered in weeks 1 and 2- The first class test was given in week 3- Cell Division was covered in weeks 4 and 5- The second class test was given in week 10- Evolution was covered in weeks 11 and 12- The final exam was given in week 16Figure 2. Number of visits to Connected Biology by week.Figure 3 shows the number of visits to each topic over the semester. Students visited Cell Structure andFunction when the topic was covered in class and the week prior to the final exam. On the other hand, studentsvisited Cell Division when the topic was covered in class and the week of the second class test in which theirunderstanding of this material was assessed. They also visited this topic, week 12, perhaps when they receivedthe results of their second test after the Easter break (week 11). They did not visit this page to review prior to thefinal exam. Students visited Evolution when the topic was covered in class and to review for the final exam.Figure 3. Number of visits to Cell Structure and Function (a), Cell Division (b) and Evolution (c) by week.There were several elements across the three topics. Students’ accessed Connected Biology via a homepage which listed each topic and linked to topic pages for each unit. These topic pages included navigation linksto preclass exercise, the classes, consolidation exercises, links to external tutorials, and activity frames with theobjectives for each topic linked to a glossary. Each element had several Web 2.0 tools (e.g., on-line practicetests, immediate feedback questions, images/videos/animations, internal and external web activities, on-linecrossword puzzles, on-line concept mapping activities, etc.).Table 3 shows the number and percentage of visits to each element for each topic. The interactivityindex (number of clicks/number of visits) for the Cell Structure and Function, Cell Division, and Evolution unitswere 0.96, 0.84, and 1.37 respectively. This indicates that students were using the topics page primarily to linkto the elements. The students were surprisingly consistent in their visits to the elements. They rarely visited thelinked tutorials (1.1%) which were featured on these pages.Table 3: Number and student visits to Connected Biology elements.ElementObjective/GlossaryLink to TutorialsPreclass ExercisesClassesConsolidation ExercisesNavigation ButtonsCSCL 2015 ProceedingsCell StructureN%381662.58234.55322.34719.7125.0Cell DivisionN%13434.120.511228.54812.28421.4133.358EvolutionN%5414.730.813135.65514.910929.6164.3TotalN2261132515624041%22.61.132.515.624.04.1© ISLSHow did students use the Objectives and Glossary ElementThe interactivity indices (number of clicks/number of visits) were 0.1 and 0.3 for the Cell Structure andFunction and Cell Division units, respectively. Students visited these elements primarily to review the learningobjectives. In total they clicked on terms linking to the glossary 18% of the time.How did students use the Pre Class Exercises ElementTable 4 shows the number and percentage of visits to each tool in the preclass exercises element for each topic.The interactivity index (number of clicks/number of visits) for the Cell Structure and Function, Cell Division,and Evolution units were 4.9, 7.7, and 12.2 respectively. Thus, students used this element to interact with thematerial. They also increased their interactivity over the span of the intervention. They were consistent in theiruse of the Web 2.0 tools, primarily using the Pre Class Exercises element to click on the immediate feedbackquestions (60.3%) and the summary of the topics (32.7%). They accessed the images, animations, and videosrarely (5.1%), and almost never accessed the suggested activities (1.2%).Table 4: Number and percentage of student visits to Web 2.0 tools in the Pre Class Exercises element.ToolsInformationImmediate FeedbackQuestionsImages/Animations/VideosActivitiesNavigation/DownloadbuttonsCell StructureN%24727.159865.653775.80.80.8Cell DivisionN%59035.288452.714928258.91.71.5EvolutionN%60033.2116664.5201831.11.00.2TotalN%143732.7264860.322253355.11.20.2How did students use the Class ElementWe only collected data on how students used the Classes element for the Cell Structure and Function and CellDivision units. The interactivity indices were 0.4 and 1.6 respectively. Students visited these elements primarilyto review the learning objectives. In total, they clicked on terms linking to the glossary 18% of the time.How did students use the Consolidation ExercisesThe interactivity index for the Cell Structure and Function, Cell Division, and Evolution units were 0.90, 0.80,and 0.65 respectively. Thus, students did not interact with this element. That is, they went to the page, read it,and left (using the back arrows). Table 5 shows the number and percentage of visits that students made to thetools on the consolidation element of the three topics. Thus, students used this element primarily to do practicequizzes on the topics. They rarely accessed the tutorials, and almost never accessed the on-line crossword or online concept mapping tools.Table 5: Number and percentage of student visits to Web 2.0 tools in the Consolidation Exercises element.ToolsQuizzesOn-line Crossword PuzzlesOn-line Concept Map ToolLink to TutorialsCellStructureN%9198.911.100Cell DivisionN116008%93.56.5EvolutionN7000%100000TotalN214108%960.503.5Teacher views on integration of technology and Web 2.0 toolsAlthough 3 teachers (from a pool of 6 teachers teaching the Biology course) agreed to participate in the project,ultimately only 1 teacher did. Therefore, we could not conduct a usability study on teachers. Instead, weinterviewed 5 teachers in order to understand the teacher culture that might prevent teachers from volunteering.Teacher A believes that students need to see the relevance of the class content to their lives. He/ shespends a lot of time and resources collecting videos and research papers (suitable for students) and uses them inCSCL 2015 Proceedings59© ISLSclass to initiate interest and discussion. Teacher A directs students on what sections of the textbook to cover andmakes use of the on-line learning activities packaged with the textbook. However, he/she does not requirestudents to do any of the activities because not all students have access.Sometimes I bring in a YouTube documentary, but very short, and that starts the wholediscussions. I think it gets them really stimulated when they see it. So I usually show them 5minutes, and then that starts … a discussion on that topic.Teacher B believes that it is important to put together a perfect course (notes, learning objectives,quizzes, etc.) and make them available to students at the beginning. He/she focuses on the course content and on“figuring out” what and how to deliver it. Teacher B directs students to what material they need to know, whatreadings they should do (that will not be covered in class) and gives them some practice questions. He/shebelieves there is not enough time to cover all the content in class.I am still trying to put together the perfect course, to master the information that I want topresent, and … how I want to present it. And have all of my course materials ready to go,learning objectives, practice questions and all that stuff.I prepare [students] for the types of questions that I am going to ask them on class tests.Teacher C focuses on the text book and he/she does not deviate from it. He/she uses the on-linematerials (videos/activities/quizzes) packaged with the textbook in class because not all students have access tothem. Teacher C allows students to bring their laptops to class and gives them questions/problems to discuss insmall groups.The textbook pretty much does [it] all, the online activity, it’s because we mainly focus on thecontent of the textbook, so we don't really diverge ways from textbook. Like they can searchon their own for some of our topics but I didn't encourage them.Teacher D believes that students learn by doing and has designed activities for them to do in groups.He/she also believes that students need to be directed to the concepts they need to master, they need to comeprepared to class, and need to consolidate their learning. Teacher D uses the teacher resources packaged with thetextbook to design assessment questions at a higher cognitive level (analysis/synthesis). Teacher D focuses onhow students are learning and what misconceptions they may have.I’ve developed a lot of activities in class, educational activities, not just work sheets, butactivities so that the students have to work together to do the research in the classroom to find,or discover the answer …. and then present it to the rest of the class.[The website) is for pre-class preparation and post-class follow up, [for use] during the class,because there were links to videos, and other websitesTeacher E uses a suite of graded e-learning and problem-based learning activities which studentscomplete as groups. He/she also uses a web-page that has instructional videos (from YouTube), practicequestions, and the on-line materials packaged with the textbook to cover the course content.We have a smart board [in the classroom] so I used that as a tool, and the way I used it,actually almost never pick up a real pen any more… so everything goes on the smart board,everything gets recorded, everything gets saved, everything gets then saved as a PDF, andeverything gets posted for students to see. Then I created a … website for one of my courses, Ihave videos for theory, solutions, I have some assessment question and I have real questions,sort of quiz type questions, with objectives. And that’s my whole course covering every majortopic in the course.Conclusions and implicationsAlthough most students found Connected Biology satisfying, learnable, memorable, and error-free (but notefficient), they did not make much use of the embedded Web 2.0 tools. That is, they used the web-site as anCSCL 2015 Proceedings60© ISLSelectronic Study Guide. They used it when the topic was covered in class and prior to being tested on thecontent. They made little or no use of the enrichment tools (videos, activities, tutorials). Science students have aheavy workload, taking on average 3 science courses, a language course, a physical education course, ahumanities course, and a complimentary course. They are very strategic in how they study. They made a greateffort to complete the pre-class exercises, focusing on the acquisition of the content and testing theirunderstanding. This had a positive effect on the class in that students came to class prepared. They were thusable to profit from the in-class activities and discussions. Thus, the prevalent student culture is: do the requiredwork, participate in class, and prepare for tests. In other words they have a prescriptive model (Williams,Karousou, & Mackness, 2011) of learning biology where learning is predictable albeit complicated, theorganization of knowledge is hierarchal, verification and correction is provided by the experts and notnegotiable. This view may in fact reflect the reality of formal post-secondary science education, at least at theintroductory level. That is, in most science domains knowledge is “created and applied to give control”(Williams, Karousou, & Mackness, 2011, p 43).The teacher interviews also reveal a teacher-centered pedagogy in which most teachers “stuck” closelyto the textbook and associated materials. For example, the common course outline specifies the pages in the textbook that for which the students are responsible. All teachers, even those teachers that made use of Web 2.0tools held a prescriptive learning model. This may reflect both the nature of science (as taught at theintroductory level) and the assessment practices. Unless work is graded, students do not do the work. However,“the traditional interpretation [of assessment] becomes problematic [in emergent learning networks]” (Romer,2002 quoted by Williams, Karousou, & Markess, 2011).The Biology course is a multisection course with a common final which includes more than 85%multiple choice questions. This drives students to adopt a learning approach that discourages exploration andpromotes focusing on practice questions. In addition, it discourages teachers from adopting more studentcentered pedagogies. Given that this context is not likely to change, several questions arise: Is there a place foremergent learning in introductory science courses? If so, what is the optimal balance of emergent andprescriptive learning? Are there certain topics that are more suited to emergent learning and what are they?How do we “open up” assessment practices so that emergent learning is encouraged? How do we designemergent learning environments that are time-efficient for students? Many of these questions will have to beanswered before the affordances of Web 2.0 tools can be realized in introductory science courses.ReferencesAmiel, T., & Reeves, T. C. (2008). Design-based research and educational technology: Rethinking technologyand the research agenda. Educational Technology & Society, 7(4), 167-175.Brown, A. L. (1992). Design Experiments: Theoretical and Methodological Challenges in Creating ComplexInterventions in Classroom Settings. Journal of the Learning Sciences, 2, 141–178.Brown, J.S., (2006, March) Learning in the digital age (21st Century). Paper presented at the Ohio DigitalCommons for Education (ODCE) 2006 Conference retrieved on December 10th, 2009, fromhttp://www.oln.org/conferences/ODCE2006/papers/jsb-2006ODCE.pdfConole, G., & Alevizou, P. (2010). A literature review of the use of Web 2.0 tools in Higher Education. A reportcommissioned by the Higher Education Academy.Hargadon, S.(2009). Social Networking in Education: A white paper retrieved January 10th, 2010 fromhttp://www.scribd.com/doc/24161189/Educational-Networking-The-Important-Role-Web-2-0-WillPlay-in-Education.Messina, R., Reeve, R. & Scardamalia, M (2003). Collaborative structures supporting knowledge building:Grade 4. Paper presented at the Meeting of the American Educational Research Association, Chicago.Moreau, M.J. (2001). Knowledge Building Pedagogy: One Teacher's Journey. Paper presented at the Meeting ofthe American Educational Research Association, Seattle.Usability Professionals Association. Resources: About Usability, http://www.upassoc.org/usability_resources/about_usability/, Retrieved December 12th, 2009.Williams, R., Karousou, R., & Mackness, J. (2011). Emergent learning and learning ecologies in Web 2.0. TheInternational Review of Research in Open and Distance Learning, 12(3), 39-59.AcknowledgmentsWe wish to thank the Programme d'aide à la recherche sur l'enseignement et l'apprentissage (PA2010-012) aMinstry of Education in the Province of Quebec (MELS) program, for its support. We also wish to thank thestudents that helped with the data analysis. Lastly, we thank our colleagues and the students who participated inthe study. For a copy of the complete report please contact the first author.CSCL 2015 Proceedings61© ISLS