Resolving Disagreements in Evaluating Epistemic andDisciplinary Claims in Middle School ScienceSihan Xiao, East China Normal University, shxiao@kcx.ecnu.edu.cnWilliam A. Sandoval, University of California, Los Angeles, sandoval@gseis.ucla.eduAbstract: Supporting argumentation that fosters not only students’ disciplinary engagement butalso their epistemological development is of great importance in science education. Due toconstraints of resources and designs, building “productive moments of uncertainty” (Manz,2015) into the classroom to facilitate argumentation is challenging. This study addresses suchchallenge by analyzing how 6th graders resolve disagreements when evaluating epistemic anddisciplinary claims. Preliminary findings suggest that talking about epistemic concerns withoutdisciplinary engagement is not productive. Embedding epistemic practice in resolvingdisciplinary disagreements, however uncomplicated it may seem, would foster productiveargumentation. Understanding what disagreements are challengingly resolvable and how bothepistemic and disciplinary practices play a role in evaluating claims thus sheds needed light ondesigning effective learning environments that foster deep learning.IntroductionArgumentation in the classroom empowers science learners. Through arguing with each other, students not onlymake sense of what they learn and gain conceptual understandings of science in a deeper way (Driver, Newton,& Osborne, 2000; McDonald & Kelly, 2011), but they are also appropriated into ways of talking andcommunicating about science (Lemke, 1990). Further, defending one’s own ideas and persuading others exercisestudents into epistemic practices of coordinating evidence and claims and evaluating information, which is criticalin learning science (Sandoval, Sodian, Koerber, & Wong, 2014; National Research Council, 2012).As argumentation and epistemological development are highly intertwined, supporting argumentationabout epistemic concerns is of great importance in science education. It is not easy, though, as science has longbeen taught as a set of established facts (Millar & Osborne, 1998). Manz (2015, p. 28) thus proposes that teachersshould build “productive moments of uncertainty” into classroom activities to facilitate their epistemic practices.It is still a challenge due to constraints of resources and designs (e.g., Berland & McNeil, 2010).We report here on an ongoing study that addresses such challenge. Drawing on Manz’s (2015) frame ofcontesting and resolving disagreements, we analyze science learning in a 6th-grade classroom geared towardscoordinating claims and evidence to understand how arguing with different claims and resources shape students’perceptions of uncertainty and their epistemic practices. Two research questions guided our analysis: Whatdisagreements do students face when evaluating claims? How do they resolve these disagreements?MethodsParticipants and data sourcesThis study took place in a 6th-grade classroom in a K-6 laboratory school at a public university in metropolitanLos Angeles during the 2013–2014 school year. This classroom has 48 students (21 boys and 27 girls), whoseethnicity largely mirrors the school demography: 36% Caucasian, 20% Hispanic, 9% Asian, 7% AfricanAmerican, and 28% Multi-ethnic. The student age is 11.4 years on average. A science teacher, Ms. Hill, taughttwo units during the school year in this classroom, one on earth science and another on astronomy. As we workedclosely with her throughout the year, the instruction was organized around a set of activities in which studentswere asked to evaluate claims or prompted to propose claims to be evaluated.We videotaped the entire year of science instruction, including 68 videos (approx. 80 hours). Whilevideotaping the lessons, we also observed the setting and took field notes in order to document the contextualinformation that could not be recorded through the camera.Analytic approachOur approach to understanding classroom practices was guided by principles of interaction analysis (Jordan &Henderson, 1995). First, we reviewed the science lessons entirely for several times to get a general sense of theclassroom ecologies. Major shifts of instructional topics and participant structures in each lesson were indexed.We then identified episodes that involve student-to-teacher or student-to-student argumentation. Third, weICLS 2016 Proceedings835© ISLStranscribed these episodes in ATLAS.ti. Codes focused on evaluating claims (e.g., “it is not accurate because”)and resolving disagreements (e.g., “do you agree with that”) were emerged from constant comparison. Finally,we brought these codes back to the videos to confirm the typicality or atypicality of the instances.Findings and discussionDisciplinary arguments in resolving epistemic disagreementsWe worked with Ms. Hill on organizing a series of discussion that focused on evaluating claims. We thought itwould be helpful to establish, from the onset, shared norms that guide students’ work (Ryu & Sandoval, 2012;Driver, Newton, & Osborne, 2000). We thus asked students how to prove a claim is accurate. Their initial criteriawere collected on a worksheet and sorted out by frequency. We then put highly frequent ideas (more than 10 times)into a category of methods that can prove a claim is accurate, and the rest another category of those that cannot.Ms. Hill then launched a discussion in which students talked about whether one particular criterion should stay inthe “accurate” column or be moved to the “not accurate” column. The discussion lasted for three lessons, throughwhich students agreed upon a final list of criteria.The episode we present here took place in the second lesson when Ms. Hill guided students to discusswhether “using common sense” could prove a claim is accurate. The first three arguers talked about the usefulnessof common sense at a highly abstract level. The fourth student, Luke, used a concrete example, for the first timein this discussion, about unicorns to illustrate his idea. This “unicorns” example was picked up for several timesin the argumentation that followed, as shown in the following transcription segments (the line number are fromthe transcript of the entire discussion not included here, unicorns mentioned in bold).26272829303132Luke:Well, I disagree with you because when you said about how… Like youneed common sense to make an accurate claim, not necessarily because ifyou don’t have any sense, yes there’s chance you can… Like you can saythat, you know, unicorns are real. But there’s also a chance when youdon’t use your sense, you just go straight by evidence, you know like hard,tech evidence that will support your claim then you’re gonna get anaccurate one.73747576Gary:Eh, also I do agree with you also. ((Gary turns to look at Tina.))Em, because they do make pretty far-fetched ideas that like, em, like aretrue but also a lot, em, some of the time are also like not true. Like ascientist can say that like unicorns wearing flat hats.979899100101102103104Sarah:Well, I think that even though common sense is a little bit hazy and thereis a lot of ideas that come up, like every year, that seem out of blue, like,“no that can never happen” but… They sort of have gone through thoughtsto thoughts processes and being able to connect and see how that wouldwork. But like Gary said, like unicorns wear flat hats and run aroundEngland last year, that is not using common sense, because I meanthere’s history and there is no witnesses of unicorns running out lastyear and… Yeah.140141142143Melissa:You can use common sense that does not have to do with unicorns, Ican say like Pluto is a planet and use my common sense to reason thatout. But Pluto is not a planet, I mean, you know it makes sense to you, butit may not make sense to others.These four arguments provide an interesting lens into how students resolved epistemic disagreements.First, Luke used the unicorn as an example to back up his argument that common sense is not useful in proving aclaim is accurate. Gary picked it up to argue, contrarily, that even though scientists may make breakthroughs thatgo against common sense, sometimes discoveries that do not fit with common sense are actually not true, socommon sense can be a criterion. Sarah supported Gary and stated that common sense can be useful in evaluatingthe reliability of certain claims. Melissa, differing from the previous three, mentioned unicorn merely to shift thedisciplinary matter to Pluto. Second, although they used the unicorn for opposite positions, their arguments werebuilt upon that of each other. For example, Gary’s idea involved Luke’s “unicorns are real” and pushed it furtherinto “unicorns wearing flat hats” in order to exemplify his comment about scientists’ “pretty far-fetched ideas.”ICLS 2016 Proceedings836© ISLSSarah, moreover, gave the story a concrete context (“run around England last year”) to demonstrate her point thatusing common sense would work. Third, Melissa’s shifting from unicorns to Pluto is worth noting, becausewhether Pluto is a planet was actually a recent debate in science community. By inviting arguers to think about amore “scientific” problem that resulted in a surprising conclusion, Melissa rebutted Sarah’s idea that commonsense could be used to evaluate claim reliability.This example indicates the difficulty of dealing with stand-alone epistemic claims. When resolvingdisagreements in this episode, students tended to provide concrete cases to facilitate their discussion. The“productive” in Manz’s (2015) moments of uncertainty thus entails disciplinary engagement instead of talkingsolely about epistemics. It was “unicorns,” so to speak, that greatly advanced students’ arguments in this episode.As Hofer (2000) revealed that personal epistemologies are dependent upon disciplinary knowledge, we arguefurther, in line with Duschl (2008), that conceptual and epistemic understandings could not be separated.Epistemic arguments in resolving disciplinary disagreementsAfter the whole-class discussion described in the previous section, the students agreed upon a set of criteria abouthow to prove a claim is accurate (e.g., gathering information from multiple sources, experiment for multiple times,reasonable arguments that make sense). In order to exercise students into using these criteria for their own projects,Ms. Hill and I decided to show students an example. We used “how hot is Sun” as a leading question, and askedstudents to make a claim about it and finding evidence to prove its accuracy. We had doubts about whether thisquestion was too easy, as students all had their laptops in class with Internet access, while the answer to thisquestion was, we assumed, not controversial at all. But we still posed it because we merely wanted students to gothrough the procedures of using their own criteria to make and evaluate a claim.Students were asked to select evidence and make a claim as homework and reported and discuss theirclaims in a whole-class setting the next day. What surprised us in this discussion is, though we assumed that therewas little room for argumentation, as the question was easy to search a solid answer for, students did argue. Asthey reported different temperatures for parts of the Sun (e.g., the core, the surface, the chromosphere), when Ms.Hill pushed them to reach a consensus, they had conflicting ideas about which number(s) they should report intheir claim. The following transcript documents but one segment of a prolonged debate (about 16 minutes).94Susan:9596979899100101102Ms. Hill:Mike:Luke:Ms. Hill:108109110111112113114115116117118Ian:Ian:Ms. Hill:Ms. Hill:Ian:Ms. Hill:William:Gary:William:I think it should be the core because that is the Sun.((Talking to Luke)) The average? Okay…It can’t be the average!So it’s like the whole Sun together…Okay, hold on, now we have the average, all of them, and the highestand the lowest, okay, so…I think we should do the layers, atmosphere and stuff, and also we canaverage.So now we’re combining? How’s that sound?((Several lines omitted here.))I think we should say like, the core is this hot, the chromosphere is thishot…List all of them?And, and the average is this hot.Does everyone agree with that?I don’t know about the average now. I mean…we’ve already put all ofthe information.Yeah, well, but the average tells you what the whole Sun is.If you just say the Sun has multiple layers with varying temperatures,and you say nothing else, then you can put the average, but I don’t thinkyou need to put it now.In this interchange, six students were arguing about how to report the temperature of the Sun. Susanthought the core represented the Sun, so the temperature of the core should be enough (#94). Luke and Garyargued that the average should be reported as it represented the whole Sun (#97, #115). Ian proposed that theyshould report the temperature of each layer (#100–101, #108–109). William, lastly, doubted the value of reportingICLS 2016 Proceedings837© ISLSan average because it seemed to be redundant information (#113–114, #116–118). These students were arguingdirectly with each other, while Ms. Hill revoiced student ideas (#98–99) and pressed for consensus (#102, #106–107, #112) to advance argumentation (Michaels, O’Connor, & Resnick, 2008).Although the question may seem easy to answer, these arguments touched on some epistemic concernsthat are much more critical than knowing how hot the Sun exactly is. Susan, Luke, Gary and Ian were arguingabout what part (the core, the average of all parts, all the layers, etc.) represents the Sun and, more precisely, whatcounts as legitimate knowledge about the Sun. William’s doubt further tackle the validity of knowledgerepresentations (i.e. whether the average is redundant). All of these participating students were thinking about notonly what they knew, but also means of knowing and representing knowledge. This shows that seeminglyundemanding questions like “how hot is the sun” could yield productive argumentation provided that the teachermakes epistemic concerns explicit and students accountable for their ideas about them. Our study thus expandson Engle and Conant’s (2002) work and suggests that epistemic practice is useful in problematizing subject matterand creating resolvable uncertainty.Conclusions and significanceOur study addresses a problem in argument-based learning: how to create “productive moments of uncertainty”(Manz, 2015) to engage students in arguing with each other and resolving disagreements? The first example inthis paper suggests that talking about epistemic concerns without disciplinary engagement is not productive. Thesecond one, on the other hand, shows that embedding epistemic practice in resolving disciplinary disagreements,however uncomplicated it may seem, would foster productive argumentation.These findings join the conference theme and speak to the interests of ICLS members. Resolvingdisagreements that involve both disciplinary and epistemic practices empower students to evaluate not only whatthey know but also the means of knowing. Understanding what disagreements are challengingly resolvable andhow both practices play a role in the evaluation thus sheds needed light on designing effective learningenvironments that foster deep learning.ReferencesBerland, L. K., & McNeill, K. L. (2010). A learning progression for scientific argumentation: Understandingstudent work and designing supportive instructional contexts. Science Education, 94(5), 765–793.Driver, R., Newton, P., & Osborne, J. (2000). Establishing the norms of scientific argumentation in classrooms.Science Education, 84, 287–312.Duschl, R. A. (2008). Science Education in Three-Part Harmony: Balancing Conceptual, Epistemic, and SocialLearning Goals. Review of Research in Education, 32(1), 268 –291.Engle, R. A., & Conant, F. R. (2002). Guiding Principles for Fostering Productive Disciplinary Engagement:Explaining an Emergent Argument in a Community of Learners Classroom. Cognition and Instruction,20(4), 399–483.Hofer, B. K. (2000). Dimensionality and disciplinary differences in personal epistemology. ContemporaryEducational Psychology, 25(4), 378–405.Jordan, B., & Henderson, A. (1995). Interaction Analysis: Foundations and Practice. Journal of the LearningSciences, 4(1), 39–103.Lemke, J. (1990). Talking science: Language, learning, and values. Norwood, NJ: Ablex.McDonald, S., & Kelly, G. (2011). Beyond argumentation: sense-making discourse in the science classroom. InM. S. Khine (Ed.), Perspectives on scientific argumentation: Theory, practice, and research (pp. 265–281). Dordrecht, The Netherlands: Springer.Michaels, S., O’Connor, C., & Resnick, L. B. (2008). Deliberative Discourse Idealized and Realized: AccountableTalk in the Classroom and in Civic Life. Studies in Philosophy and Education, 27(4), 283–297.Millar, R., & Osborne, J. (Eds.) (1998). Beyond 2000: Science education for the future (the report of a seminarseries funded by the Nuffield Foundation). London: King’s College London.Manz, E. (2015). Representing Student Argumentation as Functionally Emergent From Scientific Activity.Review of Educational Research, 85(4), 553–590.National Research Council. (2012). Conceptual Framework for New Science Education Standards. Washington,DC: National Academy Press.Ryu, S., & Sandoval, W. A. (2012). Improvements to elementary children’s epistemic understanding fromsustained argumentation. Science Education, 96(3), 488–526.Sandoval, W. A., Sodian, B., Koerber, S., & Wong, J. (2014). Developing Children’s Early Competencies toEngage With Science. Educational Psychologist, 49(2), 139–152.ICLS 2016 Proceedings838© ISLS