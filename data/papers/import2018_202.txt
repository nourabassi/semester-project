Dynamic Exploration on Self-Explanation Prompts in ComplexTasksHyun Joo, Jinju Lee, Dongsik Kim, and Jihoon Songkoreaspy21@gmail.com, jinju.a.lee@gmail.com, kimdsik@hanyang.ac.kr, psu.jihoonsong@gmail.comHanyang UniversityAbstract: This study explored the effects of the focus (inference or inference followed byintegration) and assistance level (less vs. more) in self-explanation (“SE”) prompts on learningoutcomes measured by procedural- and conceptual knowledge and whether these improvementspersisted over time. A total of 129 South Korean students who enrolled in economic instructionwere randomly assigned to one of four conditions: IF-LA, IT-LA, IF-MA and IT-MA. Theresults revealed that there was an interaction effect of the focus and level of assistance of SEprompts on delayed conceptual knowledge. Prompts that focused on inference followed byintegration resulted in significantly higher immediate conceptual knowledge test scores thanprompts that focused only on inference. These findings indicated that SE prompt must bedesigned considering these two factors according to target knowledge.IntroductionBeing equipped with a highly systemized set of knowledge, (i.e. Economics), is in other words to be able to solvevarious problems in different situations in an equally systemized manner, (Feltovich, Prietula, & Ericsson, 2006),and this is only possible when the core concepts of such problem-solving process is understood completely (VanGog, Paas, & Van Merriënboer, 2004).SE is the generation of explanations for oneself to understand the principles of the learning material andeach problem-solving steps (Chi, Leeuw, Chiu, & LaVancher, 1994), and self-explanation prompts are best suitedto stimulate learning outcomes within certain domains. In their notable study, Berthold, Eysink, and Renkl (2009)developed assisting SE prompts that induce a focused processing of conceptual aspects of mathematicalprobability. While prompts were irrespective of procedural aspects, they could foster procedural knowledge. Theassisting SE prompts allows enough cognitive capacity to concentrate not only on the prompts-induced conceptualaspects but also on the problem-solving process. While it was expected for them to induce conceptual knowledge,self-explanation prompts seem to hinder the acquisition of procedural knowledge. Several scholars (Berthold,Röder, Knörzer, Kessler, & Renkl, 2011) argued that, under complex learning circumstances, prompts that attractlearner’s attention to a certain aspect would impede the deeper processing of other important aspects. Therefore,meticulously designed prompts are needed for facilitating both procedural and conceptual knowledge to solve acomplex task. This study explores the ways to design the focus and level of assistance of SE prompts in economicsfor enhanced learning outcomes (procedural and conceptual knowledge) and persistency of such improvements.SE promotes learning in two primary ways (Rittle-Johnson & Loehr, 2017). First, SE encouragesinference generation on a material that they do not fully understand. Nokes, Hausmann, VanLehn, and Gershman(2011) argued that gap-filling prompts are particularly efficient for the development of problem-solving schemas.Second, SE empowers learners to integrate pieces of new information and to combine them with prior knowledge.When studying texts with problem-solving examples, learners’ SEs often link solution steps with prior knowledgeor information in the text (Atkinson, Renkl, & Merill, 2003). In this study, we hypothesized that integration-basedprompts (i.e., generating inference followed by integration) would enhance performance for complex tasks. Sincelearners were not only required to generate inferences from simple tasks, but also needed to integrate theirinferences with prior knowledge to complete more complex tasks (Morrison, Bol, Ross, & Watson, 2015; VanMerriënboer & Kirschner, 2012). Chi et al. (1994) also suggested that the prompts were designed to reflect a rangeof difficulties (e.g., category 2 and 3 questions).Although prompting SE has been recognized as a way to improve learning process, sometimes, evenwhen prompted, learners are unable to generate reasonable explanations as they do not know how to engage inSE. Providing a structured SE format is an instructional technique for improving the quality of SE (Rittle-Johnson& Loehr, 2017). Yet, previous studies on various SE-assisting procedures have shown mixed results (, since anincomplete SE bears the risk of disturbing learners’ constructive activities. Thus, it is important to identify theappropriate level of prompting assistance that elicits SE and foster meaningful learning. As an alternative,Berthold et al. (2009) suggested that assisting SE prompts, like fill-in-the-blank followed by open-endedquestions, should be provided when assistance is necessary. However, learners should build their own schemasrather than relying on external resources to learn how to organize complex learning process (Van Merriënboer &ICLS 2018 Proceedings933© ISLSKirschner, 2012). This study attempted to see whether providing learners with keywords with open questionsfollowed by open-ended question prompts, or less assisting SE prompts, affected learning outcomes.As discussed above, previous research has demonstrated the effect of the focus and assistance level ofSE prompts independently. To date, little research has been done about the effect that the combination of the focusand assistance level of SE prompts have on learning outcomes for complex tasks. The main research questionsaddressed: 1) what are the effects of the focus and assistance level of SE prompts on procedural knowledge?(immediate and delayed test), and 2) what are the effects of the focus and assistance level of SE prompts onconceptual knowledge? (immediate and delayed test)MethodParticipants and research designThis study was conducted in a high school in Suwon, South Korea. The participants were 129 tenth grade students(female: 55%) who had already learned about the concept of exchange rates through their regular curriculum. A2×2 experimental study was conducted using the factors of (a) the focus of SE prompts – inference (“IF”) vs.inference-generating followed by integration (“IT”); (b) the assistance level of SE prompts - less assistance(“LA”) or an open question with keywords followed by open questions vs. more assistance (“MA”) or fill-in-theblank questions followed by an open question. Participants were randomly assigned to one of four conditions:LA-IF (n = 29), LA-IT (n = 26), MA-IF (n = 36), and MA-IT (n = 38).SE prompts embedded in learning materialsThe research team and economic teachers with 3 to 5 years of experience each developed experimental materialsbased on previous research (Van Gog et al., 2004). All learning materials were paper-based and provided processoriented worked examples because such examples showed learners the correct way to perform a complex taskwhile explaining why it was done that way (Van Merriënboer & Kirschner, 2012). Three examples of graduallyincreasing complexity that showed the participants how to determine the impact of exchange rate fluctuations onthe economy, were used: (Task 1) ‘Predict changes in international currency exchanges from an analysis ofdomestic economy.’ (Task 2) ‘Analyze the impact of exchange rate fluctuations on an export company.’ (Task 3)‘Analyze and evaluate an import company’s financial losses from exchange rate fluctuations.’ The solution stepwas omitted from example to execute the fading strategy. The prompts were given in place of the solution stepand the learners were required to answer one prompt for each step of the example (Fig. 1). The “IF” promptcorresponded to the one in the study of Conati and VanLehn (2000), and was focused on generating inferences tofill the gaps (e.g., ‘The answer is correct because...’). The “IT” prompt was adapted from another study (Chi etal., 1994), and was designed to facilitate an integration between prior knowledge and new information (e.g., ‘Whatis different from the previous task?’ or ‘How does it relate to what you have already seen?’). The “LA” promptwas again an open-question but with keywords for Task1 and 2 and more open-ended question for Task 3. The“MA” prompt was same as the one used by Berthold et al. (2009) and consisted of a fill-in-the-blank question forTask 1 and Task 2, and an open-ended question for Task 3.Figure 1. Description of learning materials.MeasurementThe pretest examined the participants’ knowledge on the concept of exchange rates through questions. Theposttests assessed both procedural and conceptual knowledge and conducted immediately after the learningsession and on the following week. The immediate test included 9 items for assessing procedural knowledge and3 items for conceptual knowledge, while delayed test included 3 and 5 items, respectively. Questions forprocedural knowledge included, “Calculate the change in export value of $30,000 when the exchange rate risesfrom 1,000 KRW to 1,200 KRW,” and for conceptual knowledge, questions such as “Look at trends in exchangerates and write reasons why certain trends would be favorable to exporters or importers” were asked.ProceduresThe experiment was composed of two sessions. The first session included a 7 minute-long pretest, the learningphase, and the immediate posttest. During the learning phase, the participants studied 3 complex tasks withICLS 2018 Proceedings934© ISLSprocess-oriented worked examples for 10 minutes each. The participants then completed their respective SEactivities for each prompt for 10 minutes each. The fist posttest lasted10 minutes, while the second session tookplace a week later for 15 minutes.ResultsTo ensure homogeneity among four experimental groups with regard to prior knowledge, a one-way ANOVA testwas conducted (F(3, 125)=1.626, p=.187). The group means, standard deviations were analyzed (Table. 1).Table 1: Means and standard deviations of learning outcomes across groupsAspectImmediatedelayedproceduralconceptualproceduralconceptualM4.504.643.087.53IF-LASD2.153.212.434.16M5.116.614.119.05IT-LASD2.392.992.023.30M5.315.244.149.76IF-MASD2.483.422.033.33IT-MAMSD5.461.776.423.244.382.117.232.93Two-way MANOVA was conducted to examine the effects of focus and assistance level of self-explanationprompts on learning outcomes. Box’s M test for homogeneity of covariance matrices (Box’s M=20.482, F=.642,p=.934) and Levene’s F tests of equality of variance matrices were not significant for learning outcomes (p rangedfrom .051 to .929). Utilizing Wilks’ Lambda criteria, the interaction effect was significant (Wilks’Λ =.917,F(4,122)=2.777, p=.030, ηₚ²=.083) and the main effect of the SE prompts’ focus was significant (Wilks’Λ =.894,F(4,122)=3.628, p=.008, ηₚ² =.106). However, the main effect of SE prompts’ level of assistance was notsignificant (Wilks’Λ =.963, F(4,122)=1.182, p=.322, ηₚ²=.037).Effects on Procedural knowledgeFollow-up ANOVAs, concerning immediate and delayed procedural knowledge, the main effect of the SEprompts’ focus was not signiﬁcant (F(1, 125) = .903, p = .344, ηₚ²= .007, F(1,125)= 2.703, p=.103, ηₚ²=.021,respectively). There was also no interaction between level of assistance and focus of SE prompts (F(1,125)=.326,p=.569, ηₚ²=.003, F(1,125)=1.009, p=.317, ηₚ²=.008, respectively).Figure 2. Interaction between focus and assistance level of SE prompts on delayed conceptual knowledge.Effects on conceptual knowledgeFollow-up ANOVAs, for immediate conceptual knowledge, the main effect of the SE prompts’ focus wassignificant (F (1,125) =7.60, p=.007, ηₚ²=.057), implying that IT prompts condition obtained significantly higherscores on immediate test than IF prompts condition (mean difference = 1.57, ES(d)= .49).Yet, there was nointeraction effect (F(1,125)= .472, p=.493, ηₚ²=.004). For delayed conceptual knowledge, there were no maineffect of the SE prompts’ focus (F(1,125)=.644, p=.424, ηₚ²=.005), but an interaction between the focus and levelof assistance of SE prompts (F(1,125)=10.516, p=.002, ηₚ²=.078), as shown in Fig 2. The simple main effectsshowed that focus and assistance level of SE prompts had a significant effect on delayed conceptual knowledgein the IF prompts group (F(1,125)= 5.484, p=.04), meaning that MA prompts group had higher score than LAprompts group (mean difference= 2.23, ES(d)= .61). On the other hand, focus of SE prompts had a significanteffects on delayed conceptual knowledge among LA prompts group (F(1,125)= 8.828, p<.001), implying that ITprompts group had significantly higher score than IF prompts group (mean difference=2.53, ES(d)=.69).DiscussionICLS 2018 Proceedings935© ISLSThe results reveal that the focus and assistance level of SE prompts affect learning outcomes depending on thetarget knowledge, and three conclusions can be drawn from these results. (a) There was an interaction effectbetween focus and assistance level of the SE prompts on delayed conceptual knowledge (See, Fig 2). Or, in usinginference-based prompts, a learner would establish a strong problem-solving schema and correct domainknowledge through generating inference with the help of more assisting self-explanation prompts in the initiallearning phase. In this case, despite increasing task complexity, a learner would have no need to compare orintegrate his/her understanding. In contrast, using the integration prompts that are less assisting in early stages oflearning, makes a learner to build a relatively weak problem-solving schema through the inference generation.Therefore, as learning phase progresses, a learner finds it necessary to integrate what is understood and revise anyincorrect knowledge. These results suggest that the focus of self-explanation prompts could be designed in variousways depending on the level of assistance of the self-explanation prompt. (b) Contrary to the hypothesis, thedifferent types of prompts showed no significant difference in their influence on procedural knowledge, and theresult is also contradictory to the aforementioned findings of Berthold et al. (2009). This could be due to lack oflearners’ prior knowledge, as the learners only had a very basic concept of exchange rate. In other words, thelearner could not spare his/her attention to the acquisition of other types of knowledge including proceduralknowledge, because the assisting prompts have drawn attention to a particular type of knowledge (Berthold et al.,2011).This research calls for further studies to address the following two limitations and to conduct moreexperiments, in order to broaden the universality of the implications presented so far. (a) This study excluded anexperimental condition of providing only structured SE prompts while some study proved their efficacy forlearning performance higher than open-question SE prompts (e.g., Gadgil, Nokes-Malach, & Chi, 2012). Thus,future research would need to include this condition. (b) The measures for learning consisted of a short list ofquestions. Further research would need to scrutinize procedural and conceptual knowledge with more extensiveset of tests to take a closer look at the impact of self-explanation prompts on learning outcomes.ReferenceAtkinson, R. K., Renkl, A., & Merrill, M. M. (2003). Transitioning from studying examples to solving problems:Effects of self-explanation prompts and fading worked-out steps. Journal of EducationalPsychology, 95(4), 774.Berthold, K., Eysink, T. H., & Renkl, A. (2009). Assisting self-explanation prompts are more effective than openprompts when learning with multiple representations. Instructional Science, 37(4), 345-363.Berthold, K., Röder, H., Knörzer, D., Kessler, W., & Renkl, A. (2011). The double-edged effects of explanationprompts. Computers in Human Behavior, 27(1), 69-75.Chi, M. T. H. (1996). Constructing self-explanations and scaffolded explanations in tutoring. Applied CognitivePsychology, 10, 33-49.Chi, M. T., Leeuw, N., Chiu, M. H., & LaVancher, C. (1994). Eliciting self‐explanations improvesunderstanding. Cognitive science, 18(3), 439-477.Chi, M. T. (2000). Self-explaining expository texts: The dual processes of generating inferences and repairingmental models. Advances in instructional psychology, 5, 161-238.Conati, C., & Vanlehn, K. (2000). Toward computer-based support of meta-cognitive skills: A computationalframework to coach self-explanation. International Journal of Artificial Intelligence in Education(IJAIED), 11, 389-415.Feltovich, P. J., Prietula, M. J., & Ericsson, K. A. (2006). Studies of expertise from psychologicalperspectives. The Cambridge handbook of expertise and expert performance, 41-67.Gadgil, S., Nokes-Malach, T. J., & Chi, M. T. (2012). Effectiveness of holistic mental model confrontation indriving conceptual change. Learning and Instruction, 22(1), 47-61.Rittle-Johnson, B., & Loehr, A. M. (2017). Eliciting explanations: Constraints on when self-explanation aidslearning. Psychonomic bulletin & review, 24(5), 1501-1510.Nokes, T. J., Hausmann, R. G., VanLehn, K., & Gershman, S. (2011). Testing the instructional fit hypothesis: thecase of self-explanation prompts. Instructional Science, 39(5), 645-666.Morrison, J. R., Bol, L., Ross, S. M., & Watson, G. S. (2015). Paraphrasing and prediction with self-explanationas generative strategies for learning science principles in a simulation. Educational Technology Researchand Development, 63(6), 861-882.Van Gog, T., Paas, F., & Van Merriënboer, J. J. (2004). Process-oriented worked examples: Improving transferperformance through enhanced understanding. Instructional Science, 32(1), 83-98.Van Merriënboer, J. J. G., & Kirschner, P. (2012). Ten steps to complex learning: A systematic approach to fourcomponent instructional design (2nd Rev. ed.). New York, NY: Routledge/Taylor & Francis Group.AcknowledgementsThis work is funded by the National Research Foundation of Korea(NRF) [grant number 201700000002601].ICLS 2018 Proceedings936© ISLS