Dual Gaze as a Proxy for Collaboration in Informal LearningKshitij Sharma, Faculty of Business and Economics, University of Lausanne; Computer Human Interaction inLearning and Instruction, EPFL, kshitij.kshitij@unil.chIoannis Leftheriotis, NTNU, Trondheim, Norway, iolef@acm.orgJama Noor, NTNU, Trondheim, Norway, jamawadi@gmail.comMichail Giannakos, NTNU, Trondheim, Norway, michailg@idi.ntnu.noAbstract: Interactive displays are increasingly employed in informal learning environmentsas a technology for enhancing students’ learning and engagement. Interactive displays allowstudents to collaborate and interact with the content in a natural and engaging manner. Despitethe increased prevalence of interactive displays for learning, we know very little about howstudents collaborate in such settings and how this collaboration influences their performance.In this dual eye-tracking study, with 36 participants, a two-staged within-group experimentwas conducted to investigate students’ collaboration and learning gains in an interactivedisplay. The results show that collaboratively, pairs who have high gaze similarity have highlearning outcomes. Individually, participants spending high proportions of time in acquiringthe complementary information from images and textual parts of the learning material attainhigh learning outcomes. We show that the gaze is an effective proxy to cognitive mechanismsunderlying collaboration not only in formal settings but also in informal learning scenarios.Keywords: interactive displays, informal learning, collaborative learning, dual eye-trackingIntroductionThere is growing interest in investigating the use of interactive displays in a plethora of domains, due to theirdecreasing cost and increasing commodity/availability. Interactive displays have been used for supportinginformal learning activities (Klopfer et al., 2005; Dillenbourg & Evans, 2010), among other purposes. However,little evidence exists on how to create and put into practice engaging, efficient, and highly collaborativeactivities on interactive displays. There have been numerous studies that point out that utilization of interactivedisplays proved to be an excellent tool to promote collaboration and cooperation while learning (e.g. Schäfer etal., 2013); and since work and interactive displays, such as a tabletop surface, can be considered as a ubiquitousfeature of learning, the software that accompanies such displays could be augmented to adapt to variousscenarios (Dillenbourg & Evans, 2010).There is an emerging literature on interactive displays for collaborative interaction and their use ineducational settings. In their review, Higgins et al. (2012) propose a typology of features of this technology andoffer an analysis of the pedagogic potential of these features. Researchers have to pay attention to two commonmistakes that have been repeated each time a new technology is introduced in education: over-generalizationand over-expectation (Dillenbourg & Evans, 2010). For instance, in Zaharias et al. (2013) empirical study,researchers assessed the learning performance and user experience between a group that followed the traditionallearning procedure in a museum and a group in which students interacted with a multi-touch applicationdedicated to the museum. Although their results show statistically non-significant differences in the learningperformance, the second group reported significantly higher levels of fun and engagement than the first group.Most studies are focused on the experience, fun, enjoyment and engagement of the users (e.g. Schneider et al.2012; Schäfer et al, 2013). It seems that in order to better understand the way that users learn and collaborate onan interactive displays, further tools and studies are needed.Based on recent studies regarding collaboration and learning, one important tool that could be used tounveil the cognitive mechanisms underlying collaboration is the dual eye-tracking (DUET). There are studiesexplaining the expertise (Jermann et. al. 2010), collaboration quality (Sharma et. al 2015), learning outcome(Jermann and Nueslli, 2012), and the task-based performance (Nuessli et. al., 2009) using dual eye-trackingdata. However, to the best of our knowledge, DUET has not yet been applied to investigate collaborative gazepatterns in a combination of physical and digital collaborative spaces. This was our main motivation behind thisstudy. In this contribution, we combine the two aforementioned research areas: interactive displays in informaleducational settings and DUET for collaborative learning. We designed an experiment where participants wereasked to go through a set of posters and play a game (both in collaborative and competitive ways) using contentfrom the area of Neuroscience. We recorded the gaze of the participants while they were watching the postersand while they were playing the game. In this contribution, we focus on how to explain the relation between theCSCL 2017 Proceedings183© ISLSlearning gains in an informal learning setting and collaboration, using DUET. Precisely, we address thefollowing research questions:1. How can the individual and collaborative gaze patterns explain the learning gains?2. What is the relation between the collaborative gaze patterns in two different contexts of the experiment(physical versus digital)?Related workIn this section, we will briefly report on the studies using the interactive displays in education, and the dual eyetracking studies in the collaborative settings. This section is not exhaustive in terms of the studies reported, butit contains the grounding necessary for this paper.Interactive displays in informal educational settingsOne of the first studies on touch technology applied to education was “Read-it”, a game-based application,designed to support the development of reading skills in children aged 5-7 years old (Sluis et al., 2004). Theresults of the pilot experiment showed that children enjoyed playing the game and that the technology was notan obstacle to learning. Different design practices like gamification elements (badges, achievements, points andlevels) (Lo et al., 2013) were used in interactive display applications that allow students to engage andcollaborate with the application. Schafer et al. (2013) developed a multi-touch learning environment anddesigned a game that consists of multiple learning and playing modes in which teams of students can collaborateor compete against each other. This multiplayer approach of supporting competition, collaboration andcooperation is perceived as motivating and "fun". Greater playfulness and enjoyment have been indicated whilestudents were working with the multi-touch display. In a more recent study, Ardito et al., (2013) proposed a neweducational format, inspired by the Discovery Learning Technique, which integrates educational games,designed to be played on large multi-touch displays, with other types of formal and informal learning. Ardito etal., (2013) showed that their proposed educational format is effective and that games on these novel multi-touchsystems engage users, stimulate collaboration and help consolidating knowledge.Antle et. al., (2011) developed the tabletop game Futura (reported effective and enjoyable by themajority of the general public), with a focus to identify and understand key design factors of importance increating opportunities for learning. In this study, some special affordances of a multi-touch display are depicted,for instance, the fact that the interface allows all the players to see how and what their co-players are doing.Besides, Watson et al. (2013) suggests that there may be something inherently more appealing about the directnature of multi-touch interaction, particularly when applied to a game. Kirriemuir and McFarlane (2004) claimthat before games can take on a meaningful role in formal or informal education, the education sector and thewider public and media need to better understand the potential and diversity of such ‘tools’. In this study weinvestigate these ‘tools’ with the use of dual eye-tracking.Dual eye-tracking (DUET)Previous research has shown the importance of DUET to unveil the cognitive mechanisms underlyingcollaboration. In a dual eye-tracking study concerning listening comprehension, Richardson and Dale (2007)showed that the pairs having high cross-recurrence (probability to look at the same object at the same time) havehigh comprehension results. Jermann and Nueslli (2012) showed similar results in a pair programcomprehension tasks. The pairs which had high cross-recurrence also had high understanding levels (Jerman &Nuessli, 2012). Nuessli et al. (2009) used DUET data to predict the task-based success in Raven matrices andBongard problems. The authors used gaze density and fixation dispersion of the pair to predict the success of thepair with an accuracy of 78%. In a collaborative version of Tetris, Jermann et al. (2010) predicted the pairconfiguration (expert-novice, novice-novice, expert-expert) using the DUET data with and accuracy of 75%.Sangin et al. (2008) used a Knowledge Awareness Tool (KAT) to inform the peers about their partner’sknowledge in a collaborative concept map task. The results show that the gaze on the KAT was correlated to therelative learning gain of the pairs. In a pair-programming task, Sharma et al. (2011) showed that the pairs with ahigh level of understanding look at the data flow of the program while the pairs with a low level ofunderstanding read the program as if it was English text. In another DUET experiment with collaborativeconcept map, Sharma et al (2015) showed that the gaze similarity (the probability to look at the same set ofobjects in the same time-window) is higher for the pairs with a high collaboration quality than that for the pairswith a low collaboration quality.All the aforementioned studies show that using dual eye-tracking data, one can explain the expertise,collaboration quality and the task-based performance. In the present study, we utilize dual eye-tracking toexplain pairs’ learning gains in an informal learning context.CSCL 2017 Proceedings184© ISLSExperimentIn this section we will present the details of the experiment and the variables involved in the analysis. In theexperiment, the participants were asked to fill in a pretest about the content they were going to learn. Then theywent through five posters about the structure of neurons, different areas of the brain and their functions, threeneurological disorders, and the limbic system (two examples are shown in Figures 3.a and 3.b). The next phasewas the first individual posttest. The next phase was a gamified quiz application played in an interactive displayand focusing on the same content as the posters. The game had two modalities: in one modality the team playedcollaboratively while in the second, the members of a team played against each other (the interfaces for thecollaborative and the competitive versions of the games are shown in Figures 1.a and 1.b respectively). Theorder of the game modalities was balanced among the teams. Finally, the participants individually took a secondposttest. All the tests and the quizzes in the games were multiple-choice questionnaires. The poster phase was12-15 minutes long and each modality of the game (collaborative/competitive) was 6-7 minutes long. The gazeof the participants was recorded during the poster phase and the game phase using SMI and TOBII eye-trackingglasses at 60 Hz.Figure 1. Interfaces for the (a) collaborative, and (b) competitive versions of the game. The elements for the twoversions were identical except in the collaborative version there was only one set of buttons to select the correctanswer, while in the competitive version there were two different sets of buttons for each player.Figure 2. Experiment screenshots, (a) Teams are watching the posters as they would do in a museum, and (b)Teams are playing gamified quizzes (collaborative/competitive) on interactive display.Participants and procedureThere were 36 university students (18 randomly formed dyads), who participated in the experiment; there were13 females among the participants. The average age was 24.4 years (SD = 5 years). Upon their arrival in the lab,they filled in a pretest about the poster content; afterwards, they watched the five posters. The simple instructionfor the poster phase was “go through all the posters as if you were visiting a museum with your friend”. Theparticipants were allowed to discuss the content of the posters with their partners (figure 2.a). The dyads werenot mandated to stick to each other, however, most of them went through the posters together. Once theyfinished watching and discussing the posters, the participants individually filled the first posttest. Further, theyplayed the gamified quiz (collaborative/competitive) where they received one of the three power ups for eachcorrect answer: “double xp”, “pause time”, and “hint” (figure 2.b). During the game phase, the participants hadCSCL 2017 Proceedings185© ISLSa maximum of 30 seconds to answer each question; they were allowed to go back to the posters and look for theanswers. Once they finished both the modalities of the game, they filled in a final second posttest. All theparticipants were rewarded an equivalent of $10.Dependent variablesWe normalized test scores to be between 0 and 1. The two dependent variables are the scores in the first and thesecond posttests. We do not consider the learning gain in this experiment, as we observed a floor effect on thepretest scores (Mean = 0.2, Median = 0.1).Figure 3. Examples of the posters, (a) Neurological Disorders, and (b) The Limbic System.Process VariablesPerformance in the game: The participants received individual experience points (xp) during the game (bothcollaborative and competitive) when they replied correctly to a question. We consider the xp value as their gameperformance index.Individual Gaze - AOI Transitions: We divided the posters into different Areas of Interests (AOIs), forexample, text blocks and image blocks. Next, we computed the proportions of the gaze transitions from theimages in the poster to the corresponding text and also the proportions of the gaze transitions from the text tothe corresponding images. For example, in the Figure 3(a), an image to text transition would be a shift of gazefrom the top left image to any of the first three paragraphs and the opposite for the text to image transitions. Anytransition from the top-left image to any paragraph other than the first three ones would not be counted as avalid image to text transition. The opposite is also true for the text to image transitions.Collaborative Gaze - Gaze Similarity: To compute the metric for the collaborative gaze patterns, we used thesame measure as used by Sharma et al., (2012 and 2015). This measure is called the gaze-similarity and iscomputed as the cosine similarity of the proportionality gaze vector. The proportionality gaze vector is thevector denoting the proportion of the time spent by each participant looking at the different elements of thevisual stimulus for a small window of time (in our case 10 seconds). A gaze similarity value of 1 will depict thatthe two peers spent exactly the same proportions of 10 seconds on different AOIs. Whereas, a gaze similarityvalue of 0 will depict that the two peers were looking at completely different elements during a given timewindow of 10 seconds.ResultsCSCL 2017 Proceedings186© ISLSIn this section, we will present the various relations we find among the process and dependent variables. Weobserve the following relations:Improvement in the knowledge from pretest to the first posttest: we observe a significant improvementfrom the pretest score to the first posttest score for all the participants (t (69.96) = -7.91, p < .0001). The scoresin the first posttest are significantly higher than the pretest scores (Figure 4).No improvement in the knowledge from the first to second posttest: however, we do not observe significantimprovement from the first to second posttest (t (69.88) = 0.39, p > .05). The scores in the two posttests weresimilar for almost all the participants (Figure 4).Correlation between the game score, the first and the second posttest: we observe three significantcorrelations: 1. The scores in the first and the second posttests are correlated (r (34) = 0.69, p < .0001). Theparticipants who score high in the first posttest also score high in the second posttest (Figure 5.a). 2. The scorein the game is correlated to the score in the first posttest (r (34) = 0.42, p = .01). The participants who score highin the first posttest also perform well in the game (Figure 5.b)). 3. The score in the game is correlated to thescore in the second posttest (r (34) = 0.34, p = .04). The participants who perform well in the game also scorehigh in the second posttest.Figure 4. Comparison of scores from the pretest, the first and the second posttest. All values are normalizedbetween 0 and 1. The points show the mean values among all the participants and the blue bars show the 95%confidence intervals.Figure 5. Scatter Plots for (a) first and second posttest score, (b) game score and the first posttest score, and (c)game score and the second posttest score. In all the plots the blue line shows the linear model for the variable ony-axis given the variable on the x-axis. The grey area shows the 95% confidence interval.CSCL 2017 Proceedings187© ISLSAOI transitions and the first pretest score: next, we consider the individual gaze patterns during the posterphase. We observe a significant correlation between the transitions from image to text and the first posttestscore (r (34) = 0.47, p = .003). The participant having high proportion of the image to text transitions, score highin the first posttest (Figure 6.a). Moreover, we also observe a significant correlation between the transitionsfrom the text to image and the first pretest score (r (34) = 0.48, p < .002). Participants that have high proportionof the text to image transitions score high in the first posttest (Figure 6.b).Gaze similarity and the first pretest score: further, concerning the collaborative gaze patterns, we observe asignificant correlation between the gaze similarity during the poster phase and the first posttest score (r (16) =0.51, p = .03). The pairs having high gaze similarity have high average first posttest score (Figure 7.a).Gaze similarity during posters and during the game: moreover, we also observe a significant correlationbetween the gaze similarity during the poster phase and the gaze similarity during the game phase (r (16) =0.49, p < .04). The pairs having high gaze similarity during the poster session also have high gaze similarityduring the game phase (Figure 7.b).Figure 6. Scatter Plots for the individual transitions (a) image to text, and (b) text to image; and the score in thefirst posttest. In all the plots the blue line shows the linear model for the variable on y-axis given the variable onthe x-axis. The grey area shows the 95% confidence interval.Discussion and conclusionsThe results presented in the previous section represent two behavioural gaze patterns (individual AOI transitionsand collaborative gaze similarity), both of which are correlated to participants’ learning outcomes (Question 1).The first behavioural gaze patterns we report on are the individual transitions to and from the imagesand the text chunks. The results show that the participants having more such transitions have a higher score inthe first posttest than those who have fewer images to text and text to image transitions. One plausibleexplanation for this relation is that the image to text and text to image transitions translate to the behaviour ofcombining the information present in the images and the text. The complementarity of the two informationsources is necessary to understand the content. Those participants who understood the relation between the twoinformation sources got high first posttest scores. This result is inline with an eye-tracking study by Shrama etal. (2015) where the authors showed that the understanding the complementarity of the graphical and textualelements in a video lecture was a key process to attain high learning gain.The second behavioural gaze patterns we report on are the collaborative gaze patterns. The gazesimilarity denotes the proportion of time the peers spent looking at the same set of objects within the given timewindow. While looking at the same areas, the peers reflect together on the content of the posters and thus buildupon a mutual understanding about the learning material; hence attain higher learning outcomes than the pairswho have lower gaze similarity. This result was also found by Richardson and Dale (2005), Jermann andNuessli (2012) and Sharma et al. (2013 and 2015). In different contexts, these contributions have shown that theCSCL 2017 Proceedings188© ISLSgaze similarity (or gaze cross-recurrence) is correlated to the task-based performance and/or learning outcomesin collaborative settings.Figure 7. Scatter Plots for (a) collaborative gaze similarity during the poster phase and the first posttest score,and (b) collaborative gaze similarity during the poster phase and the game phase. In all the plots the blue lineshows the linear model for the variable on y-axis given the variable on the x-axis. The grey area shows the 95%confidence interval.The fact that there is no significant improvement from the first posttest scores to the second posttestscores has its roots in the level of scores the participants attained in the first posttest (Mean = 0.70, SD= 0.24).This leaves a small room for improvement in the second posttest. However, we see a slight (statistically nonsignificant) improvement in the second posttest (Mean = 0.72, SD = 0.23). We also see a correlation betweenfirst and second posttest scores, suggesting that the interactive application did not hinder the learning process.This is inline with the results found by Sluis et. al (2004) and Zaharias et al. (2013) who also found thatinteractive displays were not an obstacle for the learning processes. We also found that the learning outcomewas correlated with task-based performance (game xp). This is also inline with the findings of Sangin (2009)who found that task-based performance was correlated to learning gains in a collaborative concept-map task.Finally, considering the relation between collaborative gaze patterns during the two experimentalphases (Question 2), we find a positively significant correlation (Figure 7.b) between the gaze similarity duringthe poster phase (physical) and the gaze similarity between the game phase (digital). The two phases were quitedifferent from each other: in the poster phase the participants collaborated voluntarily while in the game phasethey were told to collaborate. Despite this fact, pairs with high gaze similarity during the poster phase, also havehigh gaze similarity during the game phase. This supports the interaction style hypothesis of Sharma et. al.(2015), which states that there are two different interaction styles in collaborative settings: “Looking AT” and“Looking THROUGH”. The former appears when the peers are interacting with the content only, while the laterappears when the peers are using the content as a medium to interact with their partners. In the present study, wefind the same two profiles: the pairs having low gaze similarity during both the poster and game phases appearto interact with the content only (looking AT), while the pairs having high gaze similarity during both thephases appear to use the content as the medium to interact with their partners (looking THROUGH).In this contribution, we showed that there are individual and collaborative gaze patterns, which canexplain the learning outcomes of the participants in a collaborative informal educational setting. Theseexplanations are coherent with studies conducted in more formal educational settings. This motivates us tointerlace these findings with dialogues and actions on the touch technology and interactions to understand moreabout pairs’ collaborative dynamics. Moreover, these results will also lead us to design more hands-on activitieswith interactive displays within the informal settings to study their influence on the learning outcomes.ReferencesAntle, A. N., Bevans, A., Tanenbaum, J., Seaborn, K., Wang, S. (2011). Futura: design for collabo-rativelearning and game play on a multi-touch digital tabletop. In Procs. of the fifth international conferenceon Tangible, embedded, and embodied interaction, ACM, 93-100.Ardito, C., Lanzilotti, R., Costabile, M. F., & Desolda, G. (2013). Integrating traditional learning and games onlarge displays: an experimental study. Journal of Educational Technology & Society, 16(1), 44-56.CSCL 2017 Proceedings189© ISLSDillenbourg, P., & Evans, M. (2011). Interactive tabletops in education. International Journal of ComputerSupported Collaborative Learning, 6(4), 491-514.Higgins, S., Mercier, E., Burd, L., & Joyce‐Gibbons, A. (2012). Multi-touch tables and collaborative learning.British Journal of Educational Technology, 43(6), 1041-1054.Jermann, P., Nüssli, M.-A. and Li, W. (2010) Using dual eye-tracking to unveil coordination and expertise incollaborative tetris. In Procs. of the 24th BCS Interaction Specialist Group Conference, pages 36–44.British Computer Society.Jermann, P., and Nüssli, M.-A. (2012) Effects of sharing text selections on gaze cross- recurrence andinteraction quality in a pair programming task. In Procs. of the ACM 2012 conference on ComputerSupported Cooperative Work, pages 1125–1134. ACM.Kirriemuir, J., & McFarlane, A. (2004). Literature review in games and learning. A NESTA Futurelab Researchreport – report 8.Klopfer, E., Perry, J., Squire, K., Jan, M. F., & Steinkuehler, C. (2005). Mystery at the museum: a collaborativegame for museum education. In Procs. of the conference on Computer support for collaborativelearning. 316-320.Lo L.-J., Chiang C.-D., & Liang R.-H. (2013) HexDeck: Gamification of Tangibles for Brainstorming.Consilence and Innovation in Design – In Procs. of the 5th IASDR 2013 Tokyo. 3165-3175.Nüssli, M.-A., Jermann, P., Sangin, M., and Dillenbourg, P. (2009) Collaboration and abstract representations:towards predictive models based on raw speech and eye- tracking data. In Procs. of the 9thinternational conference on Computer supported collaborative learning-Volume 1, pages 78–82.International Society of the Learning Sciences.Richardson, D. C., and Dale, R (2005). Looking to understand: The coupling between speakers’ and listeners’eye movements and its relationship to discourse comprehension. Cognitive science, 29(6):1045–1060.Sangin, M., Molinari, G., Nüssli, M.-A., and Dillenbourg, P. (2008) How learners use awareness cues abouttheir peer’s knowledge: insights from synchronized eye-tracking data. In Procs. of the 8th internationalconference on International conference for the learning sciences-Volume 2, pages 287–294.International Society of the Learning Sciences.Schäfer, A., Holz, J., Leonhardt, T., Schroeder, U., Brauner, P., & Ziefle, M. (2013). From boring to scoring–acollaborative serious game for learning and practicing mathematical logic for computer scienceeducation. Computer Science Education, 23(2), 87-111.Schneider, B., Strait, M., Muller, L., Elfenbein, S., Shaer, O., & Shen, C. (2012). Phylo-Genie: engagingstudents in collaborative'tree-thinking'through tabletop techniques. In Procs. of the SIGCHI Conferenceon Human Factors in Computing Systems. 3071-3080.Sharma, K., Jermann, P., Nüssli, M. A., & Dillenbourg, P. (2012). Gaze Evidence for different activities inprogram understanding. In 24th Annual conference of Psychology of Programming Interest GroupSharma, K., Jermann, P., Nüssli, M. A., & Dillenbourg, P. (2013). Understanding collaborative programcomprehension: Interlacing gaze and dialogues. In Computer Supported Collaborative Learning.Sharma, K., Caballero, D., Verma, H., Jermann, P., & Dillenbourg, P. (2015). Looking AT versus LookingTHROUGH: A Dual Eye-Tracking Study in MOOC Context. In Procs. of 11th InternationalConference of Computer Supported Collaborative Learning, Gothenburg, Sweden, CSCL.Sharma, K., Caballero, D., Verma, H., Jermann, P., & Dillenbourg, P. (2015). Shaping learners’ attention inMassive Open Online Courses. International Journal of Technology in Higher Education. 12(1-2).Sluis, R.J.W., Weevers, I., Schijndel, C.H.G.J.V., Kolos-Mazuryk, L., Fitrianie, S., & Mar-tens, J. B. O. S.,(2004). Read-It: Fiveto-seven-year-old Children Learn to Read in a Tabletop Environment, In Procs. ofInternational Conference on Interaction Design with Children, ACM, 73-80.Watson, D., Hancock, M., Mandryk, R. L., & Birk, M. (2013). Deconstructing the touch experience. In Procs. ofthe ACM international conference on Interactive tabletops and surfaces. 199-208.Zaharias, P., Michael, D., & Chrysanthou, Y. (2013). Learning through multi-touch interfaces in museumexhibits: An empirical investigation. Journal of Educational Technology & Society, 16(3), 374-384.AcknowledgementsThe project has been recommended by the Data Protection Official for Research, Norwegian Social ScienceData Services (NSD), following all the regulations and recommendations for research with children. This workwas funded by the Norwegian Research Council under the projects FUTURE LEARNING (number:255129/H20), the Centre for Excellent IT Education (ExcITEd http://www.ntnu.edu/excited) and by theGEMINI Center in Technology Enhanced Lifelong Learning (http://www.tellgemini.org/).CSCL 2017 Proceedings190© ISLS