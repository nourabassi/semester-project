Negotiating Epistemic Agency and Target Learning Goals:Supporting Coherence from the Students’ PerspectiveAliza Zivic, John F. Smith, Brian J. Reiser, Kelsey D. Edwards, Michael Novak, and Tara A. W. McGillalizazivic@u.northwestern.edu, jfsmith@u.northwestern.edu, reiser@northwestern.edu,kelsey.edwards@northwestern.edu, mnovak@ccl.northwestern.edu, tara.mcgill@northwestern.eduNorthwestern UniversityAbstract: A tension in designing classroom learning involves balancing the questions andinterests of students with the goals of teachers and standards. One approach to navigating thistension in science classrooms is to simultaneously support and constrain students’ questionsabout an observable natural phenomenon in the classroom and then take up those questionsthroughout a unit of instruction. Analyses of students’ questions at the start of a middle schoolscience unit and their responses to surveys throughout the unit suggest that students perceivethat their questions are indeed driving learning, suggesting the promise of supporting students’epistemic agency through co-construction of questions, ideas, and investigations in storylines.IntroductionA core commitment of education reforms across disciplines is to bring disciplinary practices into classrooms. Inscience education, the focus is on making learning more meaningful by supporting students as they construct anduse knowledge rather than learn about ideas that others have built (Duschl, 2008). An emphasis on scientificpractices, like those articulated in the U.S. by the National Research Council (NRC, 2012), shifts the goal ofscience classroom from learning about ideas to figuring out those same ideas by engaging in practices similar tothose used by scientists. This, in turn, shifts the role of students in science classrooms from passive, recipients ofknowledge to agentive, constructors of knowledge (Berland et al., 2016). In particular, students engage in thecommunal construction of scientific understandings through scientific practices such as designing investigations,developing explanatory models, and arguing from evidence (McNeill & Pimentel, 2010; NRC, 2012).Catalyzing and sustaining a shift from learning about science to doing science requires supporting thedevelopment of students’ epistemic agency—students’ involvement in directing and monitoring knowledgebuilding processes (Damşa et al., 2010; Stroupe, 2014). In the science classroom, this means that students need tobe a part of identifying problems to work on, deciding how to pursue these investigations, and partnering withteachers to reach consensus about what has been figured out (Edelson, 2001; Reiser et al., 2017). This active rolefacilitates coherence from the students' perspective, where students are aware of why they are doing what they aredoing, as teachers guide them in building ideas based on questions and problems they have identified (Reiser etal., 2017). However, it is one thing for students to be aware of where they are going and why; it is another forthem to feel like they the power to decide where to go next.Attempting to support students’ development of epistemic agency does not guarantee that students willembrace this potential role. Jaber and Hammer (2016a, 2016b) argue that this essential shift depends on epistemicaffect, or the emotions felt as students do science, such as fascination with scientific phenomena, the unease thatcomes from discovering an inconsistency in a scientific explanation, and the joy in making a successful argument(Jaber & Hammer, 2016a, 2016b). They argue that these emotions motivate students to assume the role ofepistemic agents and actively engage in the science classroom. This idea is central to epistemic agency. Creatinga classroom where students have epistemic agency depends on students feeling like they can and should be doingthe intellectual work of science knowledge construction. Therefore, it is critical not only to look at what studentsare doing in the classroom, but also to understand how students feel about what they are doing in order to createlearning environments where students are truly directing the knowledge building.At the same time, we are in an era of high accountability. Teachers, curriculum designers, and schoolsare responsible for addressing particular standards which articulate core science ideas. Thus, there is an inherenttension between supporting epistemic agency for students while also meeting target learning goals. This tensionbetween externally mandated learning targets and student interests is not new, and goes back at least to Dewey(1902). With the articulation of the Next Generation Science Standards (NGSS) in the U.S. (NRC, 2012; NGSSLead States, 2013), this tension emerges as a fundamental concern.In this paper, we examine students’ responses to a curriculum unit designed to help teachers negotiatethis tension—guiding and supporting students as they meet target learning goals while they simultaneously partnerwith teachers in managing the focus and trajectory of investigations. The unit uses a storyline approach to optimizethese tradeoffs. While each storyline has target NGSS disciplinary core ideas (DCIs) and performanceICLS 2018 Proceedings25© ISLSexpectations (PEs) and so the general pathway of the unit is pre-written, each storyline explicitly supports teachersin drawing out students’ prior knowledge, working with students to identify questions and problems, and coconstructing next steps to investigate these questions and problems, engaging students as partners in theknowledge building (Reiser et al., 2017). This study examines students' experiences in a unit designed to bothtake up their questions and ideas about what to do and how to do it, as well as to develop core ideas and practicestargeted in the standards and curriculum. First, we consider whether the questions students raise in response toobserving an anchoring phenomenon align with the unit design. Further, while we, as researchers may recognizethat the unit addresses students’ questions, students’ responses to the unit matter as well. Thus, we also examinethe degree to which students perceive their epistemic agency, and the consequences of these perceptions for theiraffective reactions. As students move through the unit, do they see how their questions are being answered? Dothey feel they play a role in deciding where to go next? What are their affective responses to these experiences?Methods and analysisWe invited teachers from across the United States to apply to participate in the Learn While Teaching project. Weselected 27 middle school and high school science teachers from a pool of 86 applicants, 20 of whom agreed toparticipate in the program. Participating teachers were from urban, suburban, and rural school districts in CT, IL,MA, MI, OK and VT. All of the selected teachers had participated in previous professional development relatedto NGSS. Before the start of the school year, teachers participated in five days of in-person professionaldevelopment on supporting NGSS-aligned classroom learning in general and prepared to enact curriculummaterials for middle school physical science or high school biology. Teachers were supported during theirenactment of the curriculum materials through biweekly virtual meetings.This paper focuses on data collected from five of the middle school teachers using the Sound storylineunit designed by a team or teachers and researchers. The unit consists of 24 lessons across roughly 7 weeks. Fourcore questions drive the unit: (1) How is sound created? (2) How does sound travel? (3) How is sound detected?(4) How can technology store and recreate sound? The unit targets NGSS performance expectations that askstudents to develop models of waves in terms of amplitude and energy (MS-PS4-1) and that account for the waysin which waves are transmitted, reflected, or absorbed by different materials (MS-PS4-2) and can be transmittedby signals that encode information (MS-PS4-3).To support coherence from the students’ perspective, the unit organizes learning in a storyline, in whichstudents develop questions from phenomena that drives their knowledge building (Reiser et al., 2017). Ananchoring phenomenon helps elicit students’ initial questions, which are then used to uncover related questionsfrom students’ own experiences. At each step, pending questions or gaps students identify become the motivationfor the next investigation. In this particular unit, the anchoring phenomenon is a homemade record player thatplays music. The questions students generate about the anchoring phenomenon are organized on a driving questionboard (Figure 1; Singer et al., 2000), a public representation of student ideas (Windschitl et al., 2008).Figure 1. Example driving-question board (DQB) from a middle school sound classroom.We consider two sources of data: (1) photographs of student questions posted on the DQB following theanchoring phenomena, and (2) surveys examining students’ views of their own learning and engagement.Student questionsWe analyzed students’ questions from the DQBs from a sample of three teachers’ classrooms to examine howstudents’ questions aligned with the target science ideas. Analysis of DQBs from additional teachers is ongoing.Examining how the unit takes up students’ questions is an important first step in determining whether the unitsupports students in developing epistemic agency. Do students want to go where the unit will be taking them? Ifstudents raised a large number of questions that went unaddressed or did not ask questions at all, this could workICLS 2018 Proceedings26© ISLSagainst developing feelings of epistemic agency. The DQBs allowed us to examine whether the anchoringphenomenon precipitated questions that could be taken up in the classroom to drive learning.Each teacher took photographs of their DQBs during the first few weeks of the unit. A researchertranscribed all questions that were visible (i.e., not covered up by another piece of paper) and legible (i.e., focusof photograph was clear as was students’ handwriting). Three researchers, a designer who co-wrote the unit andtwo researchers who study the unit in classrooms, coded 265 questions from the DQBs across the three teachers'classrooms. Specifically, we considered each question in terms of two deductive codes: (1) Question Match, ifthe question asked was about a specific phenomenon and mechanism addressed explicitly in the lessons of theunit, and (2) General Mechanism, if the question could reasonably be expected to be answered mechanisticallyby the end of the unit as students have learned the relevant science ideas to be able to do so.Table 1 includes example questions from two students alongside questions and related phenomena fromthe unit. Both students’ questions require scientific explanations that address the creation and comparison ofdifferent pitches, which are the focus of Lesson 6. The first question, “How can peoples voices be different likedeeper and higher for example my pit bull has a deep bark and the Jack Russell has a high voice?” involves aphenomenon, dogs barking at different pitches and ranges of pitch. The specific phenomenon of dogs barking wasnot addressed in the unit materials, so researchers coded the question “0” for Question Match. However, becausethe first question about dogs’ barks could be at least partially explained by the general mechanisms uncovered inthe unit, we coded the question with a “1” for General Mechanism. Specifically, in Lesson 6 students are expectedto develop models for pitch and in Lesson 7 they read about human vocal cords. Therefore, the generalmechanisms and even an analogous case (humans) might be enough to support students in reasoning about dogsbarking at different pitches. In contrast, we awarded the second question in Table 1 about xylophones and pitchesa code of “1” for both Question Match and General Mechanism, because the specific phenomenon of how differentlength objects, including xylophones in particular, can make different pitches is directly addressed in the unit.Researchers separately coded the General Mechanism and Question Match categories and then compared each oftheir 265 scores in both categories to arrive at consensus. Discussion often involved returning to the writtencurriculum materials. Table 2 includes these same questions to illustrate the way the questions were coded. Wecoded the third question in Table 2, which asks about dogs barking and cats meowing, “0” in both categories.Table 1: Example questions and corresponding questions and phenomena investigated in the unitExample Student QuestionsHow can peoples voices bedifferent like deeper and higherfor example my pit bull has adeep bark and the Jack Russellhas a high voice?Why when you hit the largerkey on a xylophone the lowerthe pitch is?Related Unit QuestionsLesson 6: How do thevibrations from differentsound sources compare forhigher vs. lower pitchnotes?Related Phenomena Investigated in UnitGuitar string plucked with finger pressing on string atdifferent locations, xylophone bars of differentlengths hit with mallet, and music boxes that studentswind and play in their hands show patterns in pitch ofnote vs. length of object that is struck or plucked;patterns in effects on a long, thin wooden stick thatwe clamp down and strike and then, using a motiondetector, measure the position of the end of the stick.Table 2: Example questions and corresponding codesStudent QuestionHow can people’s voices be different like deeper and higher for example mypit bull has a deep bark and the Jack Russell has a high voice?Why when you hit the larger key on a xylophone the lower the pitch is?How come a dog barks and a cat meows?General Mechanism Question Match1 (yes)0 (no)1010Student surveysUnderstanding the alignment between students’ questions and the structure of the curricular unit is important, butwhat if students had aligned questions and they cared little about the answers? Or perhaps students might not havebelieved that their questions mattered and had little confidence they would be answered. Since we argue thatepistemic affect is a key part of students developing epistemic agency, we used student surveys to capturestudents’ thoughts and beliefs about their science classroom. The goal of these surveys was to better understandwhether students felt like they had epistemic agency in their science classrooms and to start to unpack what theconsequences of those beliefs were. Teachers administered the student survey, designed to take 10 minutes,approximately every other week during the curricular unit. Teachers had access to all of the responses in order toICLS 2018 Proceedings27© ISLSinform their teaching. Survey questions were adapted from previous work (Penuel et al., 2016). We developedthree categories of survey questions that attempted to capture three dimensions of epistemic agency: 1) theintellectual work, 2) the social dimensions of that intellectual work, and 3) students’ affective response to theirclassroom (see Table 3). While this study is ongoing, this paper examines 1119 completed student surveyresponses from 373 students from five teachers (21 class periods).Table 3: Student perceptions survey questions by categoryCategoryQuestions[Learning was student driven]On a scale from 1 – 5: “How did you learn today?”(1 = “The teacher told us everything we need to know”; 5 = “We figured everything outas a class, with the teacher helping but not telling us the answer.”)“I know why we did what we did in class today” (yes, no, unsure)Intellectual work“I figured out something today that helped us make progress on the DQB”(yes, no, unsure)“Do you think your class will figure out an answer to any of your questions”(yes, yes – at least part of one, no, other)“I know where we are going or what we are likely to do next time in class”(yes, no, unsure)“Today I shared my thinking out loud: 1) with people in my small group,2) in a whole class discussion, 3) with people in my group and in a whole classdiscussion, or 4) with no one” (choose one)Social dimensions“Listening to other students in my group helped me improve my thinking”(yes, no, unsure, I didn’t listen to another student today)“When other students shared their thinking out loud with the whole class today, Iunderstood their explanations” (yes – most of the time, yes – some of the time, no –didn’t understand, no – didn’t hear, no – no one shared their thinking)Affective response“What we did or learned about in class today matters to me, matters to the class, mattersto the community, none” (choose any)“Today’s science lesson made me feel: excited, bored, confused, like a scientist,confident, happy, sad, afraid, angry” (choose any)The first category addresses key aspects of the epistemic work that students were being asked to do inthe classroom such as who students thought was driving the learning and whether they believed that they wereand would continue figuring out their own questions. The second category looks at the social nature of communalknowledge building: how did students share their own thinking, did they listen to others, and did they find listeningproductive. The last category focuses on the students’ motivation: did they (or anyone) care about the work beingdone in their classroom, and what was their affective response to that work.FindingsOur findings consider the degree to which the unit, as designed, takes up questions students raised at the beginningof the unit as well as students’ reported experiences in classroom.Student questions41% of the questions students raised across the three classrooms examined in this part of the study (110 of 265questions) are directly addressed in the unit design. Specifically, students’ questions may be addressed by aninvestigation, uncovered in discussions guided by the teacher aimed at figuring out key ideas, and/or addressed inreadings in the unit materials. Both the curriculum and teacher provide support for students to connect and reflecton the answers to these questions. (It is an open question about teachers’ actual uses of these materials, a questionwhich we do not take up in this paper but will address in future research.) An additional 21% of students’ questions(55 of 265) can be figured out using a general mechanism that is at the core of the unit. Indeed, there is a range ofquestions and underlying phenomena that can be explained using the model that students co-create as part of theunit. Overall, 62% of students’ questions (165 out of 265) are directly or indirectly addressed in the unit design.The findings above support our design conjecture that the opening routine of the unit, which involvesstudents observing and attempting to explain an anchoring phenomenon, connecting to their own experiences, andICLS 2018 Proceedings28© ISLSuncovering questions they have, can provide support for focusing students’ questions on important learning goals,while also allowing for some freedom and heterogeneity of student questions. Furthermore, questions studentsraised in response to the anchoring phenomenon span all four sections of the unit: (1) How is sound created? (2)How does sound travel? (3) How is sound detected? (4) How is technology used to store and recreate sound?Thus, students’ questions can be taken up as motivators for each section of the unit.Some of the unanswered questions required mechanisms not addressed in the unit, such as questionsinvolving the speed of sound (e.g., “What is a sonic boom?” and “Can a plane be faster than sound?”). Howeverother questions reflect issues for which the unit may help students make partial progress. For example, consider“How do whales use echolocation?” coded as a “0” for both General Mechanism and Question Match. A numberof relevant pieces of this puzzle are addressed in the unit—how one type of animal (humans) produces sound,how humans perceive sounds, how sound travels through water, and how sound can be reflected. Thus, studentsmay be able to construct a more thorough (although still incomplete) explanation of this phenomena after the unit.In this analysis, however, we used the more conservative metric of full match on mechanism or specific question.Some of these unanswered questions may be productive questions to address in high school. However,in some cases, the purpose of NGSS was to cut down on the amount of science topics that would be addressed inschool curricula and focus on core explanations that address a broad of phenomena, a concern from even beforeNGSS (AAAS, 2001). Keeping concerns about unwieldly curricula in mind, looking closely at students’ questionsand whether that are answered as part of the classroom work using this unit allows designers to potentially expandand redesign the unit to incorporate questions that seem to be emerging across multiple classrooms in diversesettings. Indeed, we are seeing instances where teachers involved in this study are taking up questions andexpanding the unit on their own, presumably to continue to make the unit student-driven.Our next question is whether students actually recognize that the unit addresses the questions that theyhave or see how the general mechanism could be used to answer their questions. It is one thing for curriculumdesigners to assert that students’ questions are addressed in the unit; it is another for students to recognize this orfeel that science class matters to them. Students’ responses to surveys provide evidence to address this question.Student surveysWhen analyzing the student surveys, we were interested in students’ responses along the three dimensions ofepistemic agency outlined earlier and how these dimensions interacted with one another.Analysis 1: What were students’ perceptions of their learning experiences?When examining the survey questions targeting the intellectual work dimension, we found that many students hadsimilar responses. 93.2% of students (1030 out of 1105) rated their class as a 3 or higher when asked how studentdirected the learning was in their class (1 = teacher driven and 5 = student driven). 89.7% of students (996 out of1110) reported knowing why they did what they did in class. 73.6% of students (819 out of 1113) reported thatthey figured out something in class that would help them make progress on the DQB while 87.9% of students(950 out of 1081) reported that they believed that their class would figure out at least part of their questions.Additionally, 60.1% of students (656 out of 1092) responded that they knew where their class was going.This pattern continued when examining the questions relating to the social dynamics of the intellectualwork. 83.6% of students (929 out of 1111) reported sharing their thinking out loud with either their small groupor the whole class, 90.3% (1004 out of 1112) felt that they understood their peers’ ideas at least some of the time,and 79.4% (885 out of 1114) believed that listening to others helped them improve their thinking. Studentresponses were a little more varied with examining students’ affective response to the unit. 72.0% of studentsreported a positive affective response to their classroom (excited, happy or confident), 41.1% reported feeling likea scientist, 22.1% reported feeling bored, 16.8% reported feeling confused, and 3.24% reported negative emotions(angry, sad or afraid). Similarly, while 83.5% of students (879 out of 1053) reported that what they did in classmattered to the class, only 61.1% (643 out of 1053) reported that what they did in class mattered to them and only17.8% (187 out of 1053) reported that what they did in class mattered to the community.These frequencies of responses, as well as the high agreement, are powerful because they are consistentacross almost all of the three categories of questions. Students did not just like the unit, they also recognized thatthey were being asked to do the intellectual work in the classroom, participated in the class’ discursive knowledgebuilding process, had faith that their questions would be answered by the class, believed that listening to theirpeers would help them answer those questions, and overall recognized the coherence of the unit. What we canconclude from generally positive self-report responses, however, is limited. A more informative analysis needs toexamine whether variation in responses to these questions is diagnostic of meaningful differences in experience.To examine this, we analyze how these responses are related to one another.ICLS 2018 Proceedings29© ISLSAnalysis 2: How are students’ perceptions of these three dimensions related?There are many interesting correlations between different responses, but what we are most interested in is therelationship across categories. Is there a relationship between what students believe learning is like in theclassroom (i.e., the intellectual work), how students act in the classroom (i.e., the social dimension), and howstudents feel about their learning (i.e., the affective response)?Our analysis revealed a number of interesting correlations between these dimensions. When looking atthe relationship between questions about the intellectual work and the social dimension, for example, studentswho reported that “I know where we are going or what we are likely to do next time in class” were more likely tofeel that “listening to other students in my group helped me improve my thinking,” 𝜒𝜒 2 (1) = 20.42, p = 0.000.Similarly, students who reported that “I figured out something today that helped us make progress on the DQB”were more likely to feel that “listening to other students in my group helped me improve my thinking,” 𝜒𝜒 2 (1) =45.47, p = 0.000. These correlations are particularly promising because it shows a direct relationship between whohas epistemic agency in the classroom and how students engage in the classroom.There also is a relationship between the intellectual work and the affective response students have toclass. Students were more likely to feel happy, excited, or confident in class if they reported that class was morestudent driven (𝜒𝜒 2 (4) = 59.39, p = 0.000), if they knew where class was going (𝜒𝜒 2 (1) = 23.78, p = 0.000), or ifthey made progress on the DQB (𝜒𝜒 2 (1) = 31.88, p = 0.000). These correlations are particularly interesting becausestudents do not always respond positively when they are asked to take on a more active role in the knowledgebuilding of the classroom; in fact, students can become frustrated with their newfound responsibility (Zivic, 2016).Analysis 3: What questions influenced students reporting that what they did in class mattered to them?Our ultimate goal in this analysis is to begin to understand the development (or lack of development) of epistemicagency in these classrooms. We selected the response to “What we did or learned about in class today matters tome” as the most relevant indicator that students perceived ownership in their learning. This statement seems mostrelated to the ideas of epistemic agency, in which students see the learning as under their control and serving theirand their community’s interests. To investigate the impact of other aspects of the intellectual work, socialenvironment, and affective responses, we conducted a logit regression with the “class matters to me” as thedependent variable, and the other questions as predictors. Note that all independent variables were binary except“Class Learning was Student Driven” which was rated 1-5. Table 4 presents the results of this regression.Table 4: Effects of intellectual work, social dimension, and affective questions on students’ epistemic agencyOutcome: What we did in class matters to meAffectiveResponseFeels happy, excited, or confident1.116*** (0.177)Feels like a scientist0.610*** (0.152)Feels confused0.589** (0.202)Feels bored0.0912 (0.194)Feels angry, sad, or afraid-0.482 (0.443)Class learning was student drivenIntellectualWorkKnow why we did what we did in classMade progress on DQB0.283*** (0.0783)0.0662 (0.235)-0.0290 (0.170)My class will figure out my questions-0.256 (0.224)Know where we are going in class-0.161 (0.152)Shared my thinking in whole class discussionSocialDimensionCoefficient in Log Odds(n = 996)Shared my thinking with no oneListening to others helped improve my thinking0.208 (0.154)-0.290 (0.218)0.118 (0.194)Understood others when they shared0.124 (0.265)Note: Standard error in parentheses, * p < 0.05, ** p < 0.01, ***p < 0.001Interestingly, none of the survey questions in the social dimension had a significant effect on theoutcome. While these social dimensions should be present in a student-driven classroom, they are not unique tothis environment. That is, working with peers and helping one another might occur in a situation with work thatis assigned from external authority rather than a classroom where students feel ownership over their learning.ICLS 2018 Proceedings30© ISLSAmong the intellectual work questions, only the student driven nature of the class was a significantpredictor of “matters to me” judgments. Surprisingly, knowing why they were doing what they did and makingprogress on the DQB were not predictive of feelings of ownership. There were however significant relationshipsbetween several aspects of students’ affective response and students feeling that class mattered to them. It isinteresting that the class mattering to students was not only associated with positive affects (happy, excited,confident) but also with confusion. One possible interpretation is that confusion is more likely with the kind ofinvestment that comes with agency, and perhaps may be seen as a part of learning.Conclusion and implicationsThis study has explored an important tension. On the one hand, our education system is now organized aroundmeeting performance standards, which invites the development of common learning sequences. On the other hand,there is interest in encouraging meaningful disciplinary practices that empower learners with epistemic agency,which might suggest allowing learners to choose their directions and focus. This study has explored the promiseand challenges of a storyline approach (Reiser et al., 2017), in which curriculum designers aim to support teacherswith sequences of phenomena designed to raise questions that help students build the target disciplinary ideas.Initial data from classroom enactments of a middle school unit on sound reveal that the combination of anchoringphenomena, modeling tasks, and productive talk strategies to support rich engagement in science practices(Michaels & O’Connor, 2017) can support some degree of epistemic agency that helps students pursue the targetdisciplinary learning goals. We examined whether students were able to generate explanatory questions, andwhether these questions took them in directions productive for the learning goals. Analyses of students’ questionsfrom the driving question board revealed that students were indeed effective in generating a large number ofexplanatory questions that spanned the major subsections of the unit, reflecting the major components of theexplanatory model targeted in the unit. The majority of students’ questions were within the scope of theexplanatory models the unit is designed to help students develop. In the model students develop, students explainhow a vibrating object causes particles of a medium to collide and transfer energy to other particles, eventuallyreaching something that reacts to the vibrating particles (e.g., parts of an ear that detect changes in air pressure ora window that rattles due to vibrations in air). More than half of the students’ questions are indeed explainable bythis target model. In separate analyses, we are examining the extent to which students are successful in developingthis explanatory model across classrooms and the teaching approaches that support this learning.The analyses of student surveys then examined the consequences of linking students’ investigations totheir questions in the storyline. For example, it was possible that our analyses would uncover the potentialconnection of the units’ lessons with students’ questions, but that students would not see those connections orperceive them as important. It was also possible that even if students perceived these connections, they would notinfluence their affective response or feelings of agency. However, we found several strong positive relationshipsbetween the degree to which students perceived connections to their questions and their affective responses. Thedegree to which students perceived their role in the learning (figuring out vs. being told) influenced their likelihoodof indicating that “what we did in class matters to me.” Furthermore, these judgments of class mattering to thestudent were positively associated with positive affective responses (happy, excited, confident), and positivelyassociated with “feeling like a scientist.” There was also a positive association between reporting that class mattersto the student and reporting feeling confused. While we do not know the direction of this relationship (do studentsfeel that class matters more to them because they are confused or are they confused because they feel that classmatters to them?), there does seem to be a relationship between feeling that class matters to you personally andreporting intense emotions about the learning process. The results also revealed insight into the importance ofstudent perceived coherence (e.g., reporting an understanding of where the investigations should go next)—students who reported knowing “where we are going” were more likely to report positive affects. In general, thesefindings reveal a relationship between the intellectual aspects of coherence (knowing why we are doing what weare doing), and the affective underpinnings of the work (positive affect, feeling like a scientist).In summary, we strongly agree with the concern that Sikorski and Hammer (2017) raise that to supportscience as a meaningful practice for leaners, coherence needs to arise from the students’ perspective. We endorsetheir caution that “premeditated coherence, the kind of coherence that is planned and designed for students, mayinhibit students’ learning to seek coherence for themselves” (Sikorski & Hammer, 2017, p. 929). Our goal indeveloping storylines that are coherent from the students’ perspective is to support teachers in involving studentsas partners in managing the trajectory of the knowledge building. We agree there is a potential tension for students’questions to take them in a different direction from the target learning goals or from developing the canonicalscience ideas targeted in the NGSS disciplinary core ideas. However, we suggest there are strategies to addressthese challenges. We suggest that professional learning situated in teachers’ enactment of educative instructionalmaterials can provide teachers strategies for developing students’ questions and supporting their students’ICLS 2018 Proceedings31© ISLSengagement in modeling and argumentation. Empirical studies of candidate phenomena can help identifyphenomena for use in curriculum materials that can be effective contexts, with appropriate teacher probing, toelicit questions that, if investigated and explained, would help develop the DCIs. The present study suggests thatthese types of iteratively developed storylines, co-designed with teachers, can help navigate this tension betweenempowering students with epistemic agency and designing to support common disciplinary learning goals.ReferencesAAAS. (2001). Unburdening the curriculum Designs for science literacy (pp. 211-236). New York, NY: OxfordUniversity Press.Berland, L. K., Schwarz, C. V., Krist, C., Kenyon, L., Lo, A. S., & Reiser, B. J. (2016). Epistemologies in practice:Making scientific practices meaningful for students. Journal of Research in Science Teaching, 53(7),1082-1112.Damşa, C. I., Kirschner, P. A., Andriessen, J. E. B., Erkens, G., & Sins, P. H. M. (2010). Shared epistemic agency:An empirical study of an emergent construct. Journal of the Learning Sciences, 19(2), 143-186.Dewey, J. (1902). The child and the curriculum. Chicago, IL: University of Chicago Press.Duschl, R. A. (2008). Science education in three-part harmony: Balancing conceptual, epistemic, and sociallearning goals. Review of Research in Education, 32(1), 268-291.Edelson, D. C. (2001). Learning-for-use: A framework for integrating content and process learning in the designof inquiry activities. Journal of Research in Science Teaching, 38(3), 355-385.Jaber, L. Z., & Hammer, D. (2016a). Engaging in science: A feeling for the discipline. Journal of the LearningSciences, 25(2), 156-202.Jaber, L. Z., & Hammer, D. (2016b). Learning to feel like a scientist. Science Education, 100(2), 189-220.McNeill, K. L., & Pimentel, D. S. (2010). Scientific discourse in three urban classrooms: The role of the teacherin engaging high school students in argumentation. Science Education, 94(2), 203-229.Michaels, S., & O’Connor, C. (2017). From recitation to reasoning: Supporting scientific and engineeringpractices through talk. In C. V. Schwarz, C. M. Passmore, & B. J. Reiser (Eds.), Helping students makesense of the world through next generation science and engineering practices (pp. 311-336). Arlington,VA: NSTA Press.National Research Council. (2012). A framework for K-12 science education: Practices, crosscutting concepts,and core ideas. Washington, DC: National Academies Press.NGSS Lead States. (2013). Next Generation Science Standards: For states, by states. Washington, DC: TheNational Academies Press.Penuel, W. R., Van Horne, K., Severance, S., Quigley, D., & Sumner, T. (2016). Students’ responses to curricularactivities as indicator of coherence in project-based science. In C. K. Looi, J. L. Polman, U. Cress, & P.Reimann (Eds.), Transforming learning, empowering learners: The international conference of thelearning sciences (ICLS) 2016 (Vol. 2, pp. 855-858). Singapore: ISLS.Reiser, B. J., Novak, M., & McGill, T. A. W. (2017). Coherence from the students’ perspective: Why the visionof the framework for K-12 science requires more than simply “combining” three dimensions of sciencelearning. Board on Science Education workshop “Instructional materials for the NGSS.” Retrieved fromhttp://sites.nationalacademies.org/cs/groups/dbassesite/documents/webpage/dbasse_180270.pdfSikorski, T. R., & Hammer, D. (2017). Looking for coherence in science curriculum. Science Education, 101(6),929-943.Singer, J., Marx, R. W., Krajcik, J., & Chambers, J. C. (2000). Constructing extended inquiry projects: Curriculummaterials for science education reform. Educational Psychologist, 35, 165-178.Stroupe, D. (2014). Examining classroom science practice communities: How teachers and students negotiateepistemic agency and learn science-as-practice. Science Education, 98(3), 487-516.Windschitl, M., Thompson, J., & Braaten, M. (2008). Beyond the scientific method: Model-based inquiry as anew paradigm of preference for school science investigations. Science Education, 92(5), 941-967.Zivic, A. (2016). Transitioning to the reform science classroom: Connecting student beliefs to student engagementLearning Sciences, Northwestern University. [Unpublished manuscript].AcknowledgmentsThis research was funded by grants to Northwestern University from the Gordon and Betty Moore Foundation,the Carnegie Corporation of New York, and the US Department of Education, Institute of Education Sciences,(Grant Award # R305B140042). The opinions expressed herein are those of the authors and not necessarily thoseof these foundations or agencies. We are indebted to the teachers and students who participated in this study.ICLS 2018 Proceedings32© ISLS