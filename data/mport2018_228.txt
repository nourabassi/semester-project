Evidence-based Reasoning of Pre-Service Teachers:A Script PerspectiveKatharina Kiemer and Ingo KollarKatharina.kiemer@phil.uni-augsburg.de, ingo.kollar@phil.uni-augsburg.deAugsburg UniversityAbstract: Instead of using psychological knowledge, pre- and in-service teachers often referto everyday theories when faced with problematic pedagogical situations. This paper investigated to what extent such problems are caused by inadequate evidence-based reasoning scriptsthat guide pre-service teachers in the way they tackle pedagogical problems. We investigatedthe scripts of N = 103 beginning and N = 236 advanced students by asking them to analyzefictitious, but realistic problem cases in an open-answer format. Afterwards, they were askedto describe the cognitive activities they engaged in during problem analysis. Results showedthat advanced students more often than beginners reported identifying problems, while beginners more often reported setting goals. Students’ attitudes towards research on learning andinstruction positively predicted their engagement in these cognitive activities. Thus, it appearsthat the evidence-based reasoning scripts of both beginning and advanced pre-service teachersmight benefit from scaffolding, as well as supportive motivational-affective factors.Background and aimsTeachers are increasingly asked to ground their pedagogical decisions in scientific psychological and educational theories rather than on gut feeling (Slavin, 2008). Grounding one’s own pedagogical decisions in scientifictheories on learning and instruction has been termed ‘evidence-based reasoning’ (Timperley, Wilson, Barrar, &Fung, 2008). Yet, a number of studies have indicated that in many instances teachers have problems solvingpedagogical problems in agreement with scientific knowledge. For example, Franke and Wecker (2017) showedthat when faced with authentic classroom problems (e.g. students who seem to be unmotivated to follow thelesson) in-service teachers tend to rely on everyday theories and episodic evidence, rather than on scientifictheories and evidence. Similar results have been reported for pre-service teachers (Wagner, Klein, Klopp, &Stark, 2014). The reasons for pre- and in-service teachers’ deficits in evidence-based reasoning are manifold.For example, a study by Star and Strickland (2008) showed that deficits in teachers’ evidence-based reasoningwere caused by little knowledge about scientific theories on learning and instruction (see also Csanadi, Kollar,& Fischer, 2016). Furinghetti and Pehkonen (2002) demonstrated that even when teachers possess relevantscientific knowledge, they often have difficulties applying it. Further, Parr and Timperley (2008) demonstratedthat teachers often hold negative attitudes towards the usefulness of scientific knowledge on learning and instruction, which might be a further barrier for evidence-based reasoning.In this paper, we investigated whether a further reason for teachers’ problems regarding evidence-basedreasoning is that they might not (yet) have developed well-established schema about how to deal with problematic pedagogical situations. In line with Fischer, Kollar, Stegmann and Wecker (2013), we refer to suchknowledge as scripts, i.e. dynamic knowledge structures which guide a person’s behavior in specific situations(Schank, 1999). Based on prior research, we assumed that proficient solvers of pedagogical problem situationsengage in the following cognitive activities (scriptlets) as part of their evidence-based reasoning script: (1) identifying problems, (2) reconstructing problems, (3) developing an explanatory model, (4) defining goals, and (5)considering possible actions (cf. Sherin & van Es, 2009). It can be assumed that such scripts will graduallydevelop towards higher degrees of sophistication over the course of university-level teacher education. Yet,research on this issue is scarce. Therefore, our first aim was to investigate the differences between beginningand advanced pre-service teachers’ scripts for evidence-based reasoning when dealing with problematic pedagogical situations.A second aim of our study was to investigate the role that pre-service teachers’ attitudes towards research on learning and instruction play for the development of evidence-based reasoning scripts. While priorresearch has shown that negative attitudes are related to the extent to which teachers refer to scientificknowledge while solving pedagogical problems (Parr & Timperley, 2008), not much is known on the questionwhether this is also true for the relationship between these kinds of attitudes and teachers’ scripts for evidencebased reasoning.In sum, we investigated to what extent participants engaged in the five aforementioned cognitive activities when assessing a problematic pedagogical situation (RQ 1). Also, we investigated the role of pre-serviceICLS 2018 Proceedings1037© ISLSteachers’ attitudes towards research on learning and instruction for predicting the quality of their evidence-basedreasoning script (RQ 2).MethodologySampleThe full sample consisted of N = 339 university students enrolled in a teacher training program at a Germanuniversity. 77.3% of the participants were female. The mean age of the sample was M age = 22.0 years (SD =2.73). It fell into two subgroups based on the level of their studies; n = 103 (M age = 20.67, SD = 2.60, 79.6%female) were at the beginning of their studies (M semester = 1.66, SD = 1.24), while n = 236 were more advanced(M age = 22.59, SD = 2.58, 76.3% female, M semester = 5.58, SD = 1.67).The subgroups differed significantly regarding their prior pedagogical-psychological knowledge, number of educational courses and practical experience in teaching, supporting their perception as separate groupswith regard to their status as beginning and advanced students of education.DesignThe study followed a 2-group cross-sectional design. Both groups took part in a 90-min. computer-based learning environment as part of their course work. The test environment consisted of the presentation of two writtencase descriptions (vignettes) of a classroom situation. The presentation order was balanced across the sample.The vignettes described the practice of one particular teacher in a classroom. This teacher attempted to solvecommon pedagogical problems (e.g. motivating students, designing high-quality assessments), yet did not always fully succeed (problem-based learning, Hmelo-Silver, 2004.Participants were instructed to read the vignettes and provide their fictitious colleague with an analysisof the situation and feedback on their practice. Following the written analysis, participants were asked to reconstruct the cognitive activities they had just engaged in by selecting the relevant activities from a prepared listwhich was open to additions. Also, participants answered a questionnaire on their attitudes towards research onlearning and instruction as part of the learning environment.Variables, instruments, and statistical proceduresNumber of cognitive activities. These were measured by counting the number of cognitive activities that conformed to the five-step theoretical model described above when participants reconstructed their problem-solvingprocess. To test RQ 1, we ran an analysis of variance (ANOVA) to assess differences between beginning andadvanced students in the number of reported cognitive activities in line with the process model. Additionally,we used a multivariate ANOVA to investigate differences in the frequencies of the specific cognitive activities.Attitudes towards research on learning and instruction. We developed a Likert-type rating scale thatmeasured participants’ attitudes towards research on learning and instruction that consisted of 13 items. Theitems were answered on a five-point Likert-scale (1 = ‘fully disagree’; 5 = ‘fully agree’; sample item: ‘The findings of pedagogical-psychological research are helpful for the competent engagement in the teaching profession.’). The scale reached good internal consistency (Cronbach’s α = .88). We investigated the predictive powerof attitudes towards research on learning and instruction for the number of cognitive activities by way of linearregression analysis.ResultsOut of the five cognitive activities in the process model, on average participants’ mentioned M = 3.24 (SD =1.08) in the reconstruction of their problem-solving process. Beginning students mentioned M = 3.39 (SD =1.15), while advanced students mentioned M = 3.18 (SD = 1.05) cognitive activities. Regarding RQ 1, resultsshowed that overall, both groups engaged in activities congruent with our theoretical perspective to comparableamounts (F(1;334) = 2.77, p = .10). Nevertheless, significant differences emerged regarding specific cognitiveactivities (F(5; 333) = 3.54, p < .01, η² = .05): advanced students reported to engage significantly more often inproblem-identification (F(1;334) = 4.02, p = .05, η² = .01), while beginning students reported more goal-setting(F(1;334) = 7.39, p = .01, η² = .02). These effects were small however. All other differences did not reach statistical significance (F(1;334) = 2.87, p = .09 for reconstructing problems; F(1;334) = 1.80, p = 0.18 for developing an explanatory model; F(1;334) = 0.02, p = .96 for considering possible actions). Table 1 provides themeans and standard deviations for each cognitive activity.ICLS 2018 Proceedings1038© ISLSTable 1: Descriptive statistics for all cognitive activities.IdentifyingproblemsBeginningstudentsAdvancedstudentsReconstructingproblemsM0.83SD0.37M0.82SD0.390.910.290.730.45Developing anexplanatorymodelMSD0.500.500.420.49Defining goalsConsideringpossible actionsM0.55SD0.50M0.72SD0.450.390.490.720.45With regard to RQ 2, participants reported rather positive attitudes towards research on learning and instruction, with beginning students averaging on M = 3.33 (SD = .62) and advanced students on M = 3.34 (SD =.59). Consequently, no significant differences were found between groups (F(1;334) = .05, p = .83). The numberof reconstructed cognitive activities correlated significantly positively, but only to a small extent with students’attitudes towards research on learning and instruction (r = .12, p = .01). Students’ attitudes towards research onlearning and instruction predicted the number of cognitive activities reported by the participants significantlypositive (β = .12, t(334) = 2.27, p < .01). The amount of explained variance was small (R² = .02).DiscussionThis study showed that evidence-based reasoning in pre-service teachers cannot only be assessed from a contentperspective that looks at the knowledge (pre-service) teachers use when addressing and explaining pedagogicalproblems (e.g. Cook & Gorard, 2007; Franke & Wecker, 2017), but also from a process perspective that analyzes their cognitive activities during problem-solving. For this perspective, the script perspective as outlined byFischer and colleagues (2013) proved fruitful and promising.More specifically, our results indicated that pre-service teachers engaged in a number of cognitive activities which from a theoretical perspective make for good problem-solving in problematic pedagogical situations. Results indicated that while more advanced students focus on getting an understanding of the situationand possible critical incidents, beginning students jump more readily to conclusions and set goals for futureactions. Possibly, increased proficiency in identifying problems due to experience is the reason for this. Herein ahigher level of expertise in more advanced students can be assumed, as well as an increased understanding thatpedagogical situations are complex and need careful scrutiny and analysis. Both in expertise research (Berliner,2001) and in research on procedural knowledge and skills (Anderson, 1996), U-shaped developments in proficiency have been reported. Similar developments could be taking place in teachers’ evidence-based reasoning.To further investigate this possibility more career levels (e.g. beginning teachers and veterans) need to be analyzed and longitudinal research designs enacted. Furthermore, by coding participants’ written analyses for different aspects of evidence-based reasoning we seek to validate their self-report data and receive a more fullyfledged picture of their cognitive script for the analysis of pedagogical problem situations.In contrast to prior research (e.g. Parr & Timperley, 2008), our sample reported rather positive attitudestowards research on learning and instruction. Yet, in line with these investigations, we demonstrated that morepositive attitudes predicted the quality of students’ evidence-based reasoning significantly positive in the formof more cognitive activities from the model reported as part of their evidence-based reasoning script. Yet, thiseffect was rather small. Nevertheless, this finding provides support for the importance that attitudes towardsresearch on learning and instruction play not only for how often and how much pre-service teachers refer toscientific evidence during problem-solving, but also to the development of cognitive schemata on how to approach such problems in general.Limitations and conclusionsThis study is certainly not free of flaws. The cross-sectional design is limiting as the differences between beginning and advanced students might also be due to cohort effects. Also, the cross-sectional design does not allowderiving causal effects of their attitudes towards research on learning and instruction. Looking at differentgroups of (pre-service) teachers is a helpful proxy, yet additional career levels are needed to gather further insights into how evidence-based reasoning is enacted outside a university context. Field studies, looking at teachers’ actual classroom practice, would also increase the ecological validity of the findings. Lastly, it needs to benoted that the reported data is based on self-reports and warrants validation, e.g. by analyzing participants’ writ-ICLS 2018 Proceedings1039© ISLSten case analyses. This is currently done. However, we are confident in the usefulness of the script perspectiveand the scientific relevance of our results regarding (pre-service) teachers’ evidence-based reasoning.Overall, our investigation adds to previous findings that evidence-based reasoning is difficult for preservice teachers. In addition to previous studies that mainly attributed deficits in (pre-service) teachers’ evidence-based reasoning to structural problems such as a lack of knowledge or difficulties in its application, ouranalyses revealed that such deficits may also be due to insufficient cognitive processes. Our analysis furthershowed that non-cognitive factors such as attitudes need to be considered in addition to cognitive ones in research on evidence-based reasoning processes as they significantly predict their quality. Currently on-goinganalyses of the data indicate stronger application of scientific theories for students with more developed scripts.Herein, we see further support for the assumption that evidence-based reasoning scripts are important for (preservice) teachers’ evidence-based practice. Our results underscore the need to support pre-service teachers intheir development of high quality cognitive schema for tackling classroom problems (Klein, Wagner, Klopp &Stark, 2015). Research that systematically investigates evidence-based reasoning of pre-service teachers is desperately needed to enhance the professionalization of future teachers.ReferencesAnderson, J. R. (1996). ACT: A simple theory of complex cognition. American Psychologist, 51(4), 355–365.Berliner, D. C. (2001). Learning about and learning from expert teachers. International Journal of EducationalResearch, 35(5), 463–482.Cook, T., & Gorard, S. (2007). What counts and what should count as evidence. In Center for Educational Research and Innovation (Eds.), Evidence in education: Linking research and policy (pp. 33–49). Paris:OECD.Csanadi, A., Kollar, I., & Fischer, F. (2016). Scientific Reasoning and Problem Solving in a Practical Domain:Are Two Heads Better Than One? In Looi, C. K., Polman, J. L., Cress, U., and Reimann, P. (Eds.).Transforming Learning, Empowering Learners: The International Conference of the Learning Sciences(ICLS) 2016, Volume 1. Singapore: International Society of the Learning Sciences.Fischer, F., Kollar, I., Stegmann, K. & Wecker, C. (2013). Towards a script theory of guidance in computersupported collaborative learning. Educational Psychologist, 48(1), 56–66.Franke, U., & Wecker, C. (2017, August). The role of experience-based and research-based knowledge inteachers’ instructional decision-making. Paper presented at the 17th Biennial Conference of the European Association for Research on Learning and Instruction (EARLI), Tampere, Finnland, August 29th September 2nd, 2017.Furinghetti, F., & Pehkonen, E. (2002). Rethinking characterizations of beliefs. In Beliefs: A hidden variable inmathematics education? (pp. 39–57). Springer Netherlands.Hmelo-Silver, C. E. (2004). Problem-based learning: What and how do students learn?. Educational PsychologyReview, 16(3), 235–266.Klein, M., Wagner, K., Klopp, E. & Stark, R. (2015). Förderung anwendbaren bildungswissenschaftlichenWissens bei Lehramtsstudierenden anhand fehlerbasierten kollaborativen Lernens: Eine Studie zurReplikation bisheriger Befunde sowie zur Nachhaltigkeit und Erweiterung der Trainingsmaßnahmen.Unterrichtswissenschaft, 43(3), 225–244.Parr, J. M., & Timperley, H. S. (2008). Teachers, schools and using evidence: Considerations of preparedness.Assessment in Education: Principles, Policy & Practice, 15(1), 57–71.Schank, R. C. (1999). Dynamic memory revisited. Cambridge: Cambridge University Press.Sherin, M. G., & van Es, E. A. (2009). Effects of video club participation on teachers' professional vision. Journal of Teacher Education, 60(1), 20–37.Slavin, R. E. (2008). Perspectives on evidence-based research in education–What works? Issues in synthesizingeducational program evaluations. Educational Researcher, 37(1), 5–14.Star, J. R., & Strickland, S. K. (2008). Learning to observe: Using video to improve preservice mathematicsteachers’ ability to notice. Journal of Mathematics Teacher Education, 11(2), 107–125.Timperley, H., Wilson, A., Barrar, H., & Fung, I. (2008). Teacher professional learning and development: BestEvidence Synthesis Iteration (BES). Wellington, New Zealand: Ministry of Education. Retrieved from:http://educationcounts.edcentre.govt.nz/goto/BES (last access: 02.12.2018)Wagner, K., Klein, M., Klopp, E. & Stark, R. (2014). Instruktionale Unterstützung beim Lernen aus advokatorischen Fehlern in der Lehramtsausbildung: Effekte auf die Anwendung wissenschaftlichen Wissens. Psychologie in Erziehung und Unterricht, 61, 287–301.ICLS 2018 Proceedings1040© ISLS