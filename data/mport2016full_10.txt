Combining Exploratory Learning With Structured Practice toFoster Conceptual and Procedural Fractions KnowledgeNikol Rummel, Ruhr-Universit√§t Bochum, nikol.rummel@rub.deManolis Mavrikis, UCL Knowledge Lab, University College London, M.Mavrikis@ioe.ac.ukMichael Wiedmann, Ruhr-Universit√§t Bochum, michael.wiedmann@rub.deKatharina Loibl, University of Education, Freiburg, Ruhr-Universit√§t Bochum, katharina.loibl@rub.deClaudia Mazziotti, Ruhr-Universit√§t Bochum, claudia.mazziotti@rub.deWayne Holmes, UCL Knowledge Lab, University College London, W.Holmes@ioe.ac.ukAlice Hansen, UCL Knowledge Lab, University College London, A.Hansen@ioe.ac.ukAbstract: Robust domain knowledge consists of conceptual and procedural knowledge. Thetwo types of knowledge develop together, but are fostered by different learning tasks.Exploratory tasks enable students to manipulate representations and discover the underlyingconcepts. Structured tasks let students practice problem-solving procedures step-by-step.Educational technology has mostly relied on providing only either task type, with a majority oflearning environments focusing on structured tasks. We investigated in two quasi-experimentalstudies with 8-10 years old students from UK (N = 121) and 10-12 years old students fromGermany (N = 151) whether a combination of both task types fosters robust knowledge morethan structured tasks alone. Results confirmed this hypothesis and indicate that students learningwith a combination of tasks gained more conceptual knowledge and equal proceduralknowledge compared to students learning with structured tasks only. The results illustrate theefficacy of combining both task types for fostering robust fractions knowledge.Keywords: conceptual knowledge, procedural knowledge, exploratory learning environments,intelligent tutoring systems, mathematics educationIntroductionRobust domain knowledge consists of two types of knowledge, namely conceptual and procedural knowledge(Anderson, 1987; Rittle-Johnson, Siegler, & Alibali, 2001). Previous research has mostly focused on fosteringeither type of knowledge. This work explores how a combination of different types of instructional supportprovided by educational technology can foster both conceptual and procedural fractions knowledge.Conceptual knowledge can be defined as implicit or explicit understanding about underlying principlesand structures of a domain (Rittle-Johnson & Alibali, 1999). The focus of this type of knowledge lies onunderstanding why, for example, different mathematical principles refer to each other and on making sense ofthese connections. Procedural knowledge can be defined as knowledge about and application of procedures(Rittle-Johnson & Alibali, 1999). Procedures are an action sequence of, for instance, mathematical problemsolving steps (Rittle-Johnson & Alibali, 1999). The main aspect of procedural knowledge is in knowing how toapply a rule in order to solve a problem. According to Anderson‚Äôs ACT-R model (e.g., Anderson, 1982),procedural knowledge becomes implicit with increasing practice.Both types of knowledge develop over the same period of time (Canobi, Reeve, & Pattison, 2003;LeFevre et al., 2006) and evolve in a relationship of mutual dependence (Rittle-Johnson & Koedinger, 2009;Rittle-Johnson et al., 2001). Conceptual and procedural knowledge develop iteratively ‚Äúwith increases in one typeof knowledge leading to gains in the other type of knowledge, which trigger new increases in the first‚Äù (RittleJohnson et al., 2001, p. 347).While the development of these types of knowledge thus coincides (Rittle-Johnson et al., 2001), learningactivities are thought to differ in which type of knowledge they primarily foster (Koedinger, Corbett, & Perfetti,2012). Exploratory learning activities provide space for students to discover the underlying (mathematical)principles by abstracting concrete information and constructing schemata, thus primarily fostering conceptualknowledge. Structured practice activities introduce problem-solving procedures step-by-step and offer repeated(structured) practice opportunities for acquiring and deepening of these procedures (Anderson, Boyle, Corbett, &Lewis, 1990), thus primarily fostering procedural knowledge.Educational technology has mostly focused on supporting either one or the other type of learning activity.Exploratory learning environments (ELEs), often referred to as micro-worlds, allow students, for example, tomanipulate representations (e.g., Mavrikis, Guti√©rrez-Santos, Geraniou, & Noss, 2013) and crucially, to explorethe mathematical relationships between and within the representations and their underlying concepts (Hoyles,ICLS 2016 Proceedings58¬© ISLS1993; Thompson, 1987). ELEs can support students in these activities by encouraging reflection and selfexplanation (e.g., Mavrikis & Guti√©rrez-Santos, 2009). Intelligent Tutoring Systems (ITS) guide students throughsolving problems step-by-step, and offer immediate feedback so that students can automatize the problem-solvingprocedure bit by bit (Koedinger & Corbett, 2006; VanLehn, 2006). This feedback is typically directed more atproblem-solving rather than at understanding the underlying concepts.Given that conceptual and procedural knowledge develop in mutual dependence (e.g., Rittle-Johnson etal., 2001), it is somewhat surprising that prior work in the learning sciences and educational technology hasfocused on fostering either procedural knowledge with structured tasks (within ITSs) or conceptual knowledgewith exploratory tasks (within ELEs). One exception is Holmes (2013) who investigated a games-basedenvironment that provided both opportunities for children to discover numeracy concepts for themselves, usingauthentic problems that could only be solved using mathematics, and opportunities for them to practice relatedprocedures. While Holmes did not explicitly test this hypothesis, combining exploratory learning and structuredpractice tasks should be more effective for learning because it promotes the iterative development of conceptualand procedural knowledge: conceptual understanding that students can directly apply to problem-solving shouldin turn deepen the conceptual understanding.Some indirect evidence for this combination effect comes, for example, from research on productivefailure in physics education (Kapur, 2008) and iterative lesson sequencing in mathematics education (RittleJohnson & Koedinger, 2009). Kapur (2008) investigated whether attempting to solve ill-structured problemsbefore solving well-structured problems can be more productive than solving problems in the reverse order. Theproblems shared similarities with exploratory learning activities and structured tasks as defined above: illstructured problems required students to discover how to structure and solve them by abstracting concreteinformation, while the well-structured problems required the application of predictable rules and principles. Kapurfound that students who had solved ill-structured tasks first outperformed their counterparts later on in solvingboth ill-structured and well-structured tasks. However, students worked on these problems collaboratively andwithout educational technology, or support. Furthermore, there was no control condition where students learnedwith only one type of task. Rittle-Johnson and Koedinger (2009) investigated iterative lesson sequencing (lessonsthat alternate in focusing concepts or procedures) with an ITS. They found that the iterative lesson sequencefostered procedural knowledge more than a concepts-before-procedures sequence and that there was no differencein conceptual knowledge. However, the lessons that focused on concepts were heavily structured and did notprovide the affordances for discovery that ELEs offer. Taken these limitations in mind, these findings still suggestthat a learning environment combining exploratory and structured tasks could foster conceptual and proceduralknowledge, and more so than structured tasks alone which the majority of existing tutoring environments provide.In summary, while there is theoretical ground and indirect empirical evidence for combining exploratorylearning with structured practice to promote conceptual and procedural knowledge acquisition, this hypothesishas not yet been explicitly tested. We report on two studies which investigated this question in two countries(Germany and the UK), using a newly-developed learning platform for fractions learning: iTalk2Learn. It is theproduct of an interdisciplinary research project funded by the EC under the 7th FP (italk2learn.eu.). Fractions werechosen as the learning domain because this mathematical topic is particularly difficult and challenging for youngstudents (Charalambous & Pitta-Pantazi, 2007), and because students‚Äô fractions ability is a predictor for futuremath performance (Siegler et al., 2012)MethodsExperimental designThe two studies were part of a larger research design that also investigated the impact of using speech to adapt tolearners‚Äô needs. This paper reports data from two experimental conditions:(Full Platform)(No ELE)The full iTalk2Learn platform incorporating exploratory learning and structured practice.The iTalk2Learn platform incorporating structured practice, but not exploratory learning.Due to the readily observable differences in learning tasks between the conditions, it was not feasible torun multiple conditions in the same classroom. Therefore, the studies were run in a quasi-experimental design.ParticipantsParticipants in both countries were students who were just about to start or at the beginning of formal fractionsinstruction. Fractions are taught earlier in the curriculum in the UK than in Germany. Parental consent for theirinvolvement in the study was obtained for all participating students.ICLS 2016 Proceedings59¬© ISLSParticipants in the study in the UK were Year 4 and Year 5 primary school students aged between 8 and10 years from three schools. The schools were from a rural, suburban, and inner-city area. Seven students did notcomplete the study. Students were roughly stratified, according to previous teacher assessments of the children‚Äôsmathematical ability, in three groups per grade per school which were then randomly assigned to one of theconditions, resulting in the following distribution across conditions: NFull Platform = 61 and NNo ELE = 60.Participants in the study in Germany were fifth and sixth grade secondary school students aged between10 and 12 years from four schools from suburban areas. Participating students could not be stratified due totimetable constraints of the participating schools, so students participated within their class, and classes withinschools were randomly assigned to one of the conditions. Class sizes varied, and, due to a technical failure, datawas lost for one class of 33 students assigned to the No ELE condition, resulting in the following distributionacross conditions: NFull Platform = 100, and NNo ELE = 51.Dependent measuresParticipants completed an online and an offline fractions test, a questionnaire on attitudes to learning, mathematicsand fractions, a questionnaire on their experience using the platform, and questions on their experience of the taskthey had just completed. We recorded all participant interaction with the platform, including speech. For asubsample of participants, while they worked with the platform observers assessed their affect. This paper reportsdata from the online fractions test.For the online fractions test, two isomorphic versions were designed. Students were randomly allocatedone version at the first time of measurement and the other version at the second time of measurement. Twosubscales with three items each were constructed to measure procedural knowledge (see questions 22, 24, and 25in Figure 1) and conceptual knowledge (see questions 20, 21, and 23 in Figure 1). The students received one pointfor each correctly-answered item and consequently obtained two aggregated scores, one per subscale. Internalconsistency for the procedural scores at pre-test was Œ±UK = .40, Œ±Germany = .07, and at post-test Œ±UK = .53, Œ±Germany=.36. Internal consistency for the conceptual scores at pre-test was Œ±UK = .40, Œ±Germany = -.03, and at post-test Œ±UK= .36, Œ±Germany = -.06. The low internal consistency is addressed in the discussion.Figure 1. Online fractions test.ProcedureIndividual sessions were run with up to 15 students in the UK and up to 30 students in Germany. Each sessionlasted approximately 90 minutes including breaks. During the first 10 minutes, the students were introduced tothe study and to the iTalk2learn platform with the components being introduced depending on the experimentalcondition. To ensure that the introduction was as standardized as possible, it was scripted and was delivered bythe same researchers in each session. The students were then asked to complete several instruments. The onlinefractions test was presented following the questionnaire on attitudes to learning, mathematics and fractions, bothtogether in one browser window. Students were given 10 minutes total for these two instruments. Students thenworked with the iTalk2Learn platform for approximately 40 minutes. During this main experimental period, theresearchers adopted an intervention protocol that specified the allowable interactions and prompts. In the last 30minutes of the session, the students were asked to complete the final instruments. The online fractions test wasICLS 2016 Proceedings60¬© ISLSpresented following the user experience questionnaire, both together in one browser window. Students were giventwenty minutes in total for these two instruments.iTalk2Learn platformThe pedagogy of the iTalk2Learn platform is based on an intervention model for fostering robust knowledgedescribed by Mazziotti et al. (2015). For the present studies, the model was instantiated for the topic of equivalentfractions. The platform combined an ELE delivering exploratory tasks, developed within the iTalk2Learn project,Fractions Lab (Hansen, Mavrikis, Holmes, & Geraniou, 2015; http://fractionslab.lkl.ac.uk), with one of two ITSsdelivering structured tasks. In the UK, the ITS was a commercial system, Maths-Whizz (www.whizz.com); inGermany, it was an academic system, Fractions Tutor (e.g., Olsen, Belenky, Aleven, & Rummel, 2014; Rau,Aleven, & Rummel, 2013). The next section describes these learning environments and the tasks provided bythem. Tasks were chosen by mathematics education experts based on an original coherent system for fractionslearning that takes into account misconceptions and errors that are typical for learners at the beginning of formalfractions instruction (Hansen et al, 2014). Then, the adaptive support available to students is described. Finally, asection on the Student Needs Analysis (SNA) explains how tasks were sequenced within and switched betweenlearning environments.(a)(b)(c)Figure 2. Exploratory Learning Environment (Fractions Lab; a), Structured Practice Environment used in theUK (Maths Whizz; b), and Structured Practice Environment used in Germany (Fractions Tutor; c).Fractions LabFractions Lab is an ELE that provides exploratory tasks that aim to help the student develop conceptual knowledgeof fractions. In the Fractions Lab interface (see Figure 2a), a learning task is displayed at the top of the screen.Students can choose fraction representations (from the right-hand side menu) which they manipulate in order tosolve the given task. For example, they can change the fraction‚Äôs numerator or denominator, and find an equivalentfraction. An example task is shown in Figure 2a, which served both to introduce the student to available FractionsLab functionality, and to introduce them to the idea and appearance of fraction equivalence with representations(Hansen et al., 2015).Maths-WhizzMaths-Whizz is a commercial system that provides structured practice content. This content is delivered in threestages: a teaching page which explains, procedurally, how to complete the following exercises successfully,interactive exercises with guided instruction and immediate feedback (see Figure 2b), and a short test. Theexercises use a range of graphical representations such as circles, rectangles, number lines, liquid measures,symbols and sets of objects within contexts that the students may be familiar with.Fractions TutorThis web-based Cognitive Tutor for learning fractions (e.g., Olsen et al., 2014) enables students to solve fractionsproblems step-by-step, and receive immediate feedback or ask for on-demand hints. Content is presented on thesame page and revealed step by step while students solve the problem (for an example, see Figure 2c). Theexercises use a range of graphical representations such as circles, number lines, and symbols.Adaptive supportWhile the students interacted with the ELE and with the ITS, they were given automatic task-independent support(TIS) and task-dependent support (TDS).Within the ELE, the type of support provided (TIS or TDS) was based on a Bayesian Network whichaims to change a negative affective state, for example frustration or boredom, into a positive affective state suchICLS 2016 Proceedings61¬© ISLSas enjoyment by adapting the feedback to the student‚Äôs affective state. Affective states were inferred from thestudent‚Äôs speech and from interaction data, that is, whether or not feedback had been followed. TIS supportincluded affect boosts (e.g., ‚ÄúWell done. You're working really hard!‚Äù), or talk-aloud prompts (e.g., ‚ÄúPleaseexplain what are you doing.‚Äù). TDS support included instructive feedback (e.g., ‚ÄúUse the comparison box tocompare your fractions.‚Äù, Holmes, Mavrikis, Hansen, & Grawemeyer, 2015), more open-ended feedback (e.g.‚ÄúGood. What do you need to do now, to complete the fraction?‚Äù), reflective prompts (e.g., ‚ÄúWhat do you noticeabout the two fractions?‚Äù), affirmation prompts (e.g., ‚ÄúThe way that you worked that out was excellent.‚Äù), or tasksequence prompts (e.g. ‚ÄúAre you sure that you have answered the task fully? Please read the task again.‚Äù). Theway how the feedback was provided to the student (high- or low- interruptive) was adapted according to theiraffective states (Grawemeyer, Holmes, Gutierrez-Santos, Hansen, Loibl & Mavrikis, 2015).Within the ITS, TDS was provided based on students‚Äô performance and consisted of highlightingmistakes and providing problem-solving instruction. TIS was provided as described above, based on the Bayesiannetwork and adapted to students affect states deduced from their speech.SNA: Sequencing within and switching between learning environmentsIn the Full Platform condition, students began their iTalk2Learn session in the ELE. While the student wasengaged with the ELE, the Student Needs Analysis (SNA) component drew on various inputs (e.g., screen/mouseaction, speech) to determine whether the student was under-, over-, or appropriately challenged by the task andthus to identify the next task appropriate for them. After each second task completed by the student, the SNAswitched to the alternative type of task (i.e. when they had completed two exploratory tasks, they were switchedto the ITS, and vice versa). If the student was switched to the ELE, the level of challenge that they had experiencedon the previous task was taken into account when calculating the next task. The first task in the ITS was mappedto the fine-grain goal of the completed task in the ELE (e.g., partition a fraction to find its equivalent). The nexttask in the ITS stayed within the same fine-grain goal but increased the level of challenge based on a sequencedetermined by math education experts. Students continued in this fashion, alternating between exploratorylearning and structured practice every second task until the 40 minutes were concluded. In the No ELE condition,students worked on the ITS only and received tasks based on the same sequence used in the Full Platformcondition.FindingsTable 1 presents scores on the online fractions knowledge test for the conceptual and procedural subscales. Therewas a medium correlation between these subscales on the post-test, r(151) = .25 in Germany and r(121) = .26 inUK, both p < .01.Table 1: Scores on online fractions knowledge testPre-testSubscaleConceptualCountryGermanyUKProceduralGermanyUKPost-testConditionFull PlatformM0.79SD0.74M1.21SD0.69d0.5995% CI[0.30, 0.87]No ELE0.730.630.530.64-0.32[-0.71, 0.07]Full Platform1.000.951.520.850.58[0.22, 0.94]No ELE0.880.920.700.77-0.21[-0.57, 0.15]Full Platform0.950.801.420.940.54[0.26, 0.82]No ELE0.690.650.900.850.28[-0.11, 0.67]Full Platform1.330.961.971.020.65[0.28, 1.01]0.38[0.02, 0.74]No ELE1.471.021.871.07Note. Scores are summed across three items per subscale and can vary between 0 and 3.ICLS 2016 ProceedingsEffect size62¬© ISLSTwo-way 2 (condition: Full Platform or No ELE) x 2 (time of measurement: pre-test or post-test)multivariate ANOVAs with repeated measures on the time variable and conceptual and procedural subscale scoresas the two dependent measures were conducted for each country separately. Using Pillai‚Äôs trace, analyses showedsignificant effects of time of measurement for participants from both Germany, V = .117, F(2,148) = 9.834, p <.001, ùúÇùúÇùëùùëù2 = .117, and UK, V = .277, F(2,118) = 22.643, p < .001, ùúÇùúÇùëùùëù2 = .277. There were also significant effects ofcondition for participants from both Germany, V = .132, F(2,148) = 11.274, p < .001, ùúÇùúÇùëùùëù2 = .132, and UK, V =.133, F(2,118) = 9.025, p < .001, ùúÇùúÇùëùùëù2 = .133. Importantly, there were also significant interaction effects of time ofmeasurement and condition for participants from both Germany, V = .109, F(2,148) = 9.068, p < .001, ùúÇùúÇùëùùëù2 = .109,and UK, V = .114, F(2,118) = 7.604, p < .001, ùúÇùúÇùëùùëù2 = .114. Results were similar in both countries: Students in bothconditions showed learning gains, but these were stronger for the Full Platform condition. This interaction is nowinvestigated further.Follow-up univariate analyses showed significant effects of time of measurement on the proceduralscores for participants from both Germany, F(1,149) = 18.552, p < .001, ùúÇùúÇùëùùëù2 = .111 and UK, F(1,119) = 16.337, p< .001, ùúÇùúÇùëùùëù2 = .265, but not on the conceptual scores for participants from neither Germany, F(1,149) = 2.206, p >.05, nor UK, F(1,119) = 3.078, p > .05. There were significant effects of condition on the procedural scores forparticipants from Germany, F(1,149) = 10.618, p < .001, ùúÇùúÇùëùùëù2 = .067, but not from UK, F(1,119) < 1. For conceptualscores, there were significant effects of condition for participants from both Germany, F(1,149) = 16.465, p <.001, ùúÇùúÇùëùùëù2 = .100, and UK, F(1,119) = 13.999, p < .001, ùúÇùúÇùëùùëù2 = .105. Finally, there were no significant interactioneffects of time and condition on the procedural scores for participants from neither Germany F(1,149) = 2.552, p> .05, nor UK, F(1,119) = 2.279, p > .05. But on the conceptual scores, there were significant interaction effectsfor participants from both Germany, F(1,149) = 16.697, p < .001, ùúÇùúÇùëùùëù2 = .101, and UK, F(1,119) = 13.245, p < .001,ùúÇùúÇùëùùëù2 = .100. Results were similar in both countries: Students in both conditions showed equal learning gains onprocedural scores. The decrease of conceptual scores in the No ELE condition is not significant: the 95%confidence interval of the effect indicates that a small increase is similarly likely. Students in the Full Platformcondition did show significant learning gains on conceptual scores.DiscussionRobust knowledge consists of conceptual and procedural knowledge that need different types of instructionalsupport. Yet, learning systems that have been developed for mathematics education are usually constrained eitherto exploratory tasks or to structured tasks and thus can promote learning only to a limited extent. We demonstratedin this paper our attempt to overcome this limitation by combining exploratory tasks from Fractions Lab, a newlydeveloped exploratory learning environment, and structured tasks from Maths-Whizz and Fractions Tutor, twoproven intelligent tutoring systems.Two studies provided clear evidence that the combination of exploratory tasks (to foster primarilyconceptual knowledge) and structured tasks (to foster primarily procedural knowledge) in one learningenvironment promotes fractions knowledge more than state-of-the-art ITSs providing structured tasks only. Morespecifically, the combination of tasks led to stronger conceptual learning gains without hindering procedurallearning. The latter is particularly remarkable given that learning time was split between exploratory andstructured tasks in the Full Platform condition, and given that exploratory tasks primarily target conceptualknowledge. Interestingly, procedural learning gains were smaller in the No ELE than in the Full condition.Different from the contexts in which Maths-Whizz and Fractions Tutor are usually deployed, in the present studiesstudents had very limited time to study very specific learning content. Moreover, participants had not worked withthese learning environments before. Against this background, the clear learning gains observed in the FullPlatform condition are even more impressive.In spite of the overall results, there are some limitations worth discussing. The first limitation concernsthe measurement of procedural versus conceptual knowledge. These constructs can hardly be measuredindependently (Schneider & Stern, 2010), but we emphasize that our measures are meant to primarily tap oneversus the other type of knowledge. Moreover, in the German sample, the conceptual scores are not internallyconsistent which highlights the need to investigate their dimensional structure and further develop a validmeasurement of procedural versus conceptual knowledge. That said, the clear result patterns overall does providefirst evidence of an interesting effect. Following a multi-method approach, we have collected more data which,once analyzed, will shed further light on the validity of the results presented here. Another limitation is the shortduration of the intervention. While conducting the studies in school classrooms increased external validity, it alsoplaced constraints on the learning time available to us through the schools. An extended follow-up study may leadICLS 2016 Proceedings63¬© ISLSto more robust knowledge gains, evidenced by larger internal consistencies of measures, and retention and transfereffects.Despite these limitations, and the differences between the two studies conducted in Germany and in theUK, the results were remarkably similar between the two countries. This speaks to the generalizability of ourfindings and the external validity of the combination effect. Finding evidence for the combination effect underlinesthe need to foster both types of knowledge jointly, as Rittle-Johnson et al. (2001) highlighted with their iterativemodel of knowledge development.The effect of combining task types prompts a series of follow-up questions. One of these questions asksfor the component that makes the combination effect effective. For example, is the order of exploratory followedby structured tasks essential for realizing the combination effect? Or could the order be reversed? We based theorder of exploratory and structured tasks implemented in our studies on prior research that showed conceptuallearning should be fostered first (e.g., Kapur, 2008). This principle was not only realized within the first two tasks,but formed one of the rules of our intervention model employed throughout learning with iTalk2Learn. TheiTalk2Learn system now provides an additional, proven research context in which the generalizability of the priorresearch findings can be tested.ReferencesAnderson, J. R. (1982). Acquisition of cognitive skill. Psychological Review, 89(4), 369‚Äì406. doi:10.1037/0033295X.89.4.369Anderson, J. R. (1987). Skill acquisition: Compilation of weak-method problem situations. Psychological Review,94(2), 192‚Äì210. doi:10.1037/0033-295X.94.2.192Anderson, J. R., Boyle, C., Corbett, A. T., & Lewis, M. W. (1990). Cognitive modeling and intelligent tutoring.Artificial Intelligence, 42(1), 7‚Äì49. doi:10.1016/0004-3702(90)90093-FCanobi, K. H., Reeve, R. A., & Pattison, P. E. (2003). Patterns of knowledge in children‚Äôs addition. DevelopmentalPsychology, 39(3), 521‚Äì534. doi:10.1037/0012-1649.39.3.521Charalambous, C. Y., & Pitta-Pantazi, D. (2007). Drawing on a theoretical model to study students‚Äôunderstandings of fractions. Educational Studies in Mathematics, 64(3), 293‚Äì316. doi:10.1007/s10649006-9036-2Grawemeyer, B., Mavrikis, M., Holmes, W., & Guti√©rrez-Santos, S. (2015). Adapting feedback types accordingto students‚Äô affective states. In C. Conati, N. Heffernan, A. Mitrovic, & M. F. Verdejo (Eds.), Lecturenotes in computer science. Artificial Intelligence in Education (pp. 586‚Äì590). Springer InternationalPublishing.Grawemeyer, B., Holmes, W., Guti√©rrez-Santos, S., Hansen, A., Loibl, K., & Mavrikis, M. (2015). Light-bulbmoment? Towards adaptive presentation of feedback based on students' affective state. In Proceedingsof the 20th International Conference on Intelligent User Interfaces (pp. 400‚Äì404). Atlanta, Georgia,USA: ACM. doi:10.1145/2678025.2701377Hansen, A., Mavrikis, M., Holmes, W., Grawemeyer, B., Mazziotti, C., Mubeen, J., & Koshkarbayeva, A. (2014).Report on learning tasks and cognitive models (iTalk2Learn deliverable 1.2). Retrieved fromhttp://www.italk2learn.eu/deliverables-and-publications/deliverables/Hansen, A., Mavrikis, M., Holmes, W. & Geraniou, E. (2015). Designing interactive representations for learningfraction equivalence. Paper presented at ICTMT. Faro, Portugal. 24-27 June.Holmes, W. (2013). Level Up! A design‚Äê based investigation of a prototype digital game for children who arelow‚Äê attaining in mathematics. Doctoral thesis (D.Phil.) University of Oxford. Retrieved fromhttp://solo.bodleian.ox.ac.uk.Holmes, W., Mavrikis, M., Hansen, A., & Grawemeyer, B. (2015). Purpose and level of feedback in an exploratorylearning environment for fractions. In C. Conati, N. Heffernan, A. Mitrovic, & M. F. Verdejo (Eds.),Artificial Intelligence in Education (Vol. 9112, pp. 620‚Äì623). Cham: Springer.Hoyles, C. (1993). Microworlds/Schoolworlds: The transformation of an innovation. In C. Keitel & K. Ruthven(Eds.), Learning from Computers: Mathematics Education and Technology (pp. 1‚Äì17). Berlin,Heidelberg: Springer.Kapur,M.(2008).Productivefailure.CognitionandInstruction,26(3),379‚Äì424.doi:10.1080/07370000802212669Koedinger, K. R., & Corbett, A. T. (2006). Cognitive Tutors: Technology bringing learning sciences to theclassroom. In K. R. Sawyer (Ed.), The Cambridge handbook of the learning sciences (pp. 61‚Äì77). NewYork, NY, US: Cambridge University Press.ICLS 2016 Proceedings64¬© ISLSKoedinger, K. R., Corbett, A. T., & Perfetti, C. (2012). The knowledge-learning-instruction framework: Bridgingthe science-practice chasm to enhance robust student learning. Cognitive Science, 36(5), 757‚Äì798.doi:10.1111/j.1551-6709.2012.01245.xLeFevre, J.-A., Smith-Chant, B. L., Fast, L., Skwarchuk, S.-L., Sargla, E., Arnup, J. S.,. . . Kamawar, D. (2006).What counts as knowing? The development of conceptual and procedural knowledge of counting fromkindergarten through Grade 2. Journal of Experimental Child Psychology, 93(4), 285‚Äì303.doi:10.1016/j.jecp.2005.11.002Mavrikis, M., & Guti√©rrez-Santos, S. (2009). Informing the design of intelligent support for ELE bycommunication capacity tapering. In U. Cress, V. Dimitrova, & M. Specht (Eds.), Lecture notes incomputer science. Learning in the synergy of multiple disciplines (pp. 556‚Äì571). Springer Berlin.Mavrikis, M., Guti√©rrez-Santos, S., Geraniou, E., & Noss, R. (2013). Design requirements, student perceptionindicators and validation metrics for intelligent exploratory learning environments. Personal andUbiquitous Computing, 17(8), 1605‚Äì1620. doi:10.1007/s00779-012-0524-3Mazziotti, C., Holmes, W., Wiedmann, M., Loibl, K., Rummel, N., Mavrikis, M.,. . . Grawemeyer, B. (2015).Robust student knowledge: Adapting to individual student needs as they explore the concepts andpractice the procedures of fractions. In M. Mavrikis, G. Biswas, S. Guti√©rrez-Santos, T. Dragon, R.Luckin, D. Spikol, & J. Segedy (Eds.), Proceedings of the Workshops at the 17th International Conferenceon Artificial Intelligence in Education AIED 2015 (Volume 2; pp. 32‚Äì40).Olsen, J. K., Belenky, D. M., Aleven, V., & Rummel, N. (2014). Using an intelligent tutoring system to supportcollaborative as well as individual learning. In S. Trausan-Matu, K. Boyer, M. Crosby, & K. Panourgia(Eds.), Lecture notes in computer science. Intelligent tutoring systems (pp. 134‚Äì143). SpringerInternational Publishing.Rau, M. A., Aleven, V., & Rummel, N. (2013). Interleaved practice in multi-dimensional learning tasks: Whichdimensionshouldweinterleave?LearningandInstruction,23,98‚Äì114.doi:10.1016/j.learninstruc.2012.07.003Rittle-Johnson, B., & Alibali, M. W. (1999). Conceptual and procedural knowledge of mathematics: Does onelead to the other? Journal of Educational Psychology, 91(1), 175‚Äì189. doi:10.1037/0022-0663.91.1.175Rittle-Johnson, B., & Koedinger, K. (2009). Iterating between lessons on concepts and procedures can improvemathematics knowledge. The British Journal of Educational Psychology, 79(Pt 3), 483‚Äì500.doi:10.1348/000709908X398106Rittle-Johnson, B., Siegler, R. S., & Alibali, M. W. (2001). Developing conceptual understanding and proceduralskill in mathematics: An iterative process. Journal of Educational Psychology, 93(2), 346‚Äì362.doi:10.1037/0022-0663.93.2.346Schneider, M., & Stern, E. (2010). The developmental relations between conceptual and procedural knowledge:a multimethod approach. Developmental Psychology, 46(1), 178‚Äì192. doi:10.1037/a0016701Siegler, R. S., Duncan, G. J., Davis-Kean, P. E., Duckworth, K., Claessens, A., Engel, M.,. . . Chen, M. (2012).Early predictors of high school mathematics achievement. Psychological Science, 23(7), 691‚Äì697.doi:10.1177/0956797612440101Thompson, P. W. (1987). Mathematical microworlds and intelligent computer-assisted instruction. In G. P.Kearsley (Ed.), Artificial intelligence and instruction: Applications and methods (pp. 83‚Äì109). AddisonWesley Longman Publishing Co., Inc.VanLehn, K. (2006). The behavior of tutoring Systems. International Journal of Artificial Intelligence inEducation, 16(3), 227‚Äì265.AcknowledgmentsWe thank participating students and teachers, and the iTalk2learn consortium. We would like to extend specialthanks to Sergio Guti√©rrez-Santos, Beate Grawemeyer, and Jos√© Luis Fernandez-Gomez for the development ofthe iTalk2Learn platform and their support. The research leading to these results has received funding from theEuropean Commission‚Äôs Seventh Framework Program under grant agreement n¬∞318051.ICLS 2016 Proceedings65¬© ISLS