{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import regex as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file_path): \n",
    "    i = 0 \n",
    "    tmp = ''\n",
    "    key = ''\n",
    "    xml2 = etree.iterparse(file_path, recover=True)\n",
    "    data = []\n",
    "    for action, elem in xml2:\n",
    "        data.append((elem.attrib, elem.tag, elem.text))\n",
    "    data_dict = {}\n",
    "    \n",
    "    for attrib, tag, text in data: \n",
    "        try : \n",
    "            tmp = key\n",
    "            \n",
    "            key = attrib.get('qualifier')\n",
    "            element = attrib.get('element')\n",
    "            \n",
    "            #way to distinguish eliminate some nan!\n",
    "            if key == 'none':\n",
    "                key = element\n",
    "            \n",
    "            if key in data_dict.keys() : \n",
    "                i = i + 1 \n",
    "                data_dict[key + str(i)] = text\n",
    "            else : \n",
    "                i = 0 \n",
    "                data_dict[key] = text\n",
    "                \n",
    "        except TypeError: \n",
    "            if 'subject' in tag:\n",
    "                if 'subject' in data_dict.keys():\n",
    "                    data_dict['subject'].append(text)\n",
    "                else:\n",
    "                    data_dict['subject'] = [text]\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rootdir = '/Users/lguillain/Documents/EPFL2018/Git-semester-project/papers-import/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "i= 0\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        if 'dublin_core' in (path) :\n",
    "            i += 1\n",
    "            num_doc = subdir[len(rootdir):]\n",
    "            all_data[num_doc] = parse(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data from 874 files\n"
     ]
    }
   ],
   "source": [
    "print('got data from {} files'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(list(all_data.values()), index=all_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arg): \n",
    "    try : \n",
    "        arg = dateutil.parser.parse(arg)\n",
    "    except TypeError: \n",
    "        arg = arg \n",
    "    return arg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "df_data['available'] = df_data['available'].apply(lambda x : convert(x))\n",
    "df_data['accessioned'] = df_data['accessioned'].apply(lambda x : convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>accessioned</th>\n",
       "      <th>author</th>\n",
       "      <th>author1</th>\n",
       "      <th>author2</th>\n",
       "      <th>author3</th>\n",
       "      <th>available</th>\n",
       "      <th>citation</th>\n",
       "      <th>iso</th>\n",
       "      <th>issued</th>\n",
       "      <th>...</th>\n",
       "      <th>author17</th>\n",
       "      <th>author18</th>\n",
       "      <th>author19</th>\n",
       "      <th>author20</th>\n",
       "      <th>author21</th>\n",
       "      <th>author22</th>\n",
       "      <th>author23</th>\n",
       "      <th>author24</th>\n",
       "      <th>author25</th>\n",
       "      <th>author26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>import2016full/78</th>\n",
       "      <td>Students often have problems formulating und u...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Vogel, Freydis</td>\n",
       "      <td>Kollar, Ingo</td>\n",
       "      <td>Ufer, Stefan</td>\n",
       "      <td>Reiss, Kristina</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Vogel, F., Kollar, I., Ufer, S., Reiss, K., &amp; ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import2015short/373</th>\n",
       "      <td>Argumentation scripts have been proposed as an...</td>\n",
       "      <td>2017-06-19 14:51:54+00:00</td>\n",
       "      <td>Vogel, Freydis</td>\n",
       "      <td>Kollar, Ingo</td>\n",
       "      <td>Ufer, Stefan</td>\n",
       "      <td>Reichersdorfer, Elisabeth</td>\n",
       "      <td>2017-06-19 14:51:54+00:00</td>\n",
       "      <td>Vogel, F., Kollar, I., Ufer, S., Reichersdorfe...</td>\n",
       "      <td>en</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              abstract  \\\n",
       "import2016full/78    Students often have problems formulating und u...   \n",
       "import2015short/373  Argumentation scripts have been proposed as an...   \n",
       "\n",
       "                                  accessioned          author       author1  \\\n",
       "import2016full/78   2017-03-21 12:05:42+00:00  Vogel, Freydis  Kollar, Ingo   \n",
       "import2015short/373 2017-06-19 14:51:54+00:00  Vogel, Freydis  Kollar, Ingo   \n",
       "\n",
       "                          author2                    author3  \\\n",
       "import2016full/78    Ufer, Stefan            Reiss, Kristina   \n",
       "import2015short/373  Ufer, Stefan  Reichersdorfer, Elisabeth   \n",
       "\n",
       "                                    available  \\\n",
       "import2016full/78   2017-03-21 12:05:42+00:00   \n",
       "import2015short/373 2017-06-19 14:51:54+00:00   \n",
       "\n",
       "                                                              citation iso  \\\n",
       "import2016full/78    Vogel, F., Kollar, I., Ufer, S., Reiss, K., & ...  en   \n",
       "import2015short/373  Vogel, F., Kollar, I., Ufer, S., Reichersdorfe...  en   \n",
       "\n",
       "                      issued   ...    author17 author18 author19 author20  \\\n",
       "import2016full/78    2016-07   ...         NaN      NaN      NaN      NaN   \n",
       "import2015short/373  2015-07   ...         NaN      NaN      NaN      NaN   \n",
       "\n",
       "                    author21 author22 author23 author24 author25 author26  \n",
       "import2016full/78        NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "import2015short/373      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[df_data['author'].str.contains(\"Vogel\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   'abstract', 'accessioned',      'author',     'author1',\n",
       "           'author2',     'author3',   'available',    'citation',\n",
       "               'iso',      'issued',   'publisher',       'title',\n",
       "              'type',         'uri',          None,     'author4',\n",
       "           'author5',     'author6',     'author7',     'author8',\n",
       "           'subject',     'author9',    'author10',    'author11',\n",
       "          'author12',    'author13',    'author14',    'author15',\n",
       "          'author16',    'author17',    'author18',    'author19',\n",
       "          'author20',    'author21',    'author22',    'author23',\n",
       "          'author24',    'author25',    'author26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all authors in to one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = df_data.reset_index().melt(id_vars=['index','subject', 'iso', 'uri','type','publisher','title', 'issued', 'accessioned', 'citation', 'available', 'abstract'])\n",
    "cleaning = cleaning[cleaning.value.notna()]\n",
    "cleaning = cleaning[cleaning.variable.notna()]\n",
    "\n",
    "cleaning = cleaning[cleaning.value.map(lambda x: len(x) > 2)]\n",
    "\n",
    "cleaning['author_name_length'] = cleaning.value.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = cleaning[cleaning.value.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning['index'].map(lambda x: '2016' in x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleaning['author_order'] = cleaning.variable.map(lambda x: 0 if len(re.search('\\d*$', x).group(0)) == 0 else int(re.search('\\d*$', x).group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cleaning['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>iso</th>\n",
       "      <th>uri</th>\n",
       "      <th>type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>issued</th>\n",
       "      <th>accessioned</th>\n",
       "      <th>citation</th>\n",
       "      <th>available</th>\n",
       "      <th>abstract</th>\n",
       "      <th>value</th>\n",
       "      <th>author_name_length</th>\n",
       "      <th>author_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import2016full/61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>info:doi/10.22318/icls2016.61</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>Singapore: International Society of the Learni...</td>\n",
       "      <td>Exposing Piaget’s Scheme: Empirical Evidence f...</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Abrahamson, D., Shayan, S., Bakker, A., &amp; van ...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>The combination of two methodological resource...</td>\n",
       "      <td>Abrahamson, Dor</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import2016full/95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>info:doi/10.22318/icls2016.95</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>Singapore: International Society of the Learni...</td>\n",
       "      <td>Secondary Teachers’ Emergent Understanding of ...</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Sandoval, W. A., Kawasaki, J., Cournoyer, N., ...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Abstract: The Next Generation Science Standard...</td>\n",
       "      <td>Sandoval, William A.</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import2016full/59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>info:doi/10.22318/icls2016.59</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>Singapore: International Society of the Learni...</td>\n",
       "      <td>Blending Play and Inquiry in Augmented Reality...</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>DeLiema, D., Saleh, A., Lee, C., Enyedy, N., D...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Researchers have increasingly demonstrated how...</td>\n",
       "      <td>DeLiema, David</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import2016full/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>info:doi/10.22318/icls2016.92</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>Singapore: International Society of the Learni...</td>\n",
       "      <td>Making Sense of Making Waves: Co-constructing ...</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Hardy, L. &amp; White, T. (2016). Making Sense of ...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>In this paper we argue that collaborative lear...</td>\n",
       "      <td>Hardy, Lisa</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import2016full/66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>info:doi/10.22318/icls2016.66</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>Singapore: International Society of the Learni...</td>\n",
       "      <td>The Effects of Coaching on the Teaching and Le...</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Raval, H., Kaul, C., &amp; McKenney, S. (2016). Th...</td>\n",
       "      <td>2017-03-21 12:05:42+00:00</td>\n",
       "      <td>Although English is mandatorily introduced as ...</td>\n",
       "      <td>Raval, Harini</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index subject iso                            uri          type  \\\n",
       "0  import2016full/61     NaN  en  info:doi/10.22318/icls2016.61  Book chapter   \n",
       "1  import2016full/95     NaN  en  info:doi/10.22318/icls2016.95  Book chapter   \n",
       "2  import2016full/59     NaN  en  info:doi/10.22318/icls2016.59  Book chapter   \n",
       "3  import2016full/92     NaN  en  info:doi/10.22318/icls2016.92  Book chapter   \n",
       "4  import2016full/66     NaN  en  info:doi/10.22318/icls2016.66  Book chapter   \n",
       "\n",
       "                                           publisher  \\\n",
       "0  Singapore: International Society of the Learni...   \n",
       "1  Singapore: International Society of the Learni...   \n",
       "2  Singapore: International Society of the Learni...   \n",
       "3  Singapore: International Society of the Learni...   \n",
       "4  Singapore: International Society of the Learni...   \n",
       "\n",
       "                                               title   issued  \\\n",
       "0  Exposing Piaget’s Scheme: Empirical Evidence f...  2016-07   \n",
       "1  Secondary Teachers’ Emergent Understanding of ...  2016-07   \n",
       "2  Blending Play and Inquiry in Augmented Reality...  2016-07   \n",
       "3  Making Sense of Making Waves: Co-constructing ...  2016-07   \n",
       "4  The Effects of Coaching on the Teaching and Le...  2016-07   \n",
       "\n",
       "                accessioned  \\\n",
       "0 2017-03-21 12:05:42+00:00   \n",
       "1 2017-03-21 12:05:42+00:00   \n",
       "2 2017-03-21 12:05:42+00:00   \n",
       "3 2017-03-21 12:05:42+00:00   \n",
       "4 2017-03-21 12:05:42+00:00   \n",
       "\n",
       "                                            citation  \\\n",
       "0  Abrahamson, D., Shayan, S., Bakker, A., & van ...   \n",
       "1  Sandoval, W. A., Kawasaki, J., Cournoyer, N., ...   \n",
       "2  DeLiema, D., Saleh, A., Lee, C., Enyedy, N., D...   \n",
       "3  Hardy, L. & White, T. (2016). Making Sense of ...   \n",
       "4  Raval, H., Kaul, C., & McKenney, S. (2016). Th...   \n",
       "\n",
       "                  available  \\\n",
       "0 2017-03-21 12:05:42+00:00   \n",
       "1 2017-03-21 12:05:42+00:00   \n",
       "2 2017-03-21 12:05:42+00:00   \n",
       "3 2017-03-21 12:05:42+00:00   \n",
       "4 2017-03-21 12:05:42+00:00   \n",
       "\n",
       "                                            abstract                 value  \\\n",
       "0  The combination of two methodological resource...       Abrahamson, Dor   \n",
       "1  Abstract: The Next Generation Science Standard...  Sandoval, William A.   \n",
       "2  Researchers have increasingly demonstrated how...        DeLiema, David   \n",
       "3  In this paper we argue that collaborative lear...           Hardy, Lisa   \n",
       "4  Although English is mandatorily introduced as ...         Raval, Harini   \n",
       "\n",
       "   author_name_length  author_order  \n",
       "0                  15             0  \n",
       "1                  20             0  \n",
       "2                  14             0  \n",
       "3                  11             0  \n",
       "4                  13             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now parse citation to get the shortened name (which can be matched to refrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_names = r'([\\w\\-\\&]*[\\,] [\\p{L}\\.\\ ]+[\\&\\,]?)'\n",
    "\n",
    "cleaning.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cleaning['shortend_names'] = cleaning.citation.map(lambda x: re.match(r'[\\S\\s]*\\(\\d{4}\\)', x, re.U)\\\n",
    "                                                   .group(0)).map(lambda x: [x.replace(',', '').replace('&', '').rstrip() for x in regex.findall(get_names, x)])\n",
    "\n",
    "cleaning['shortend_names'] = cleaning.apply(lambda x: x['shortend_names'][x['author_order']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Viswanathan, S. A. & Vanlehn, K. (2017). High Accuracy Detection of Collaboration From Log Data and Superficial Speech Features In Smith, B. K., Borge, M., Mercier, E., and Lim, K. Y. (Eds.). (2017). Making a Difference: Prioritizing Equity and Access in CSCL, 12th International Conference on Computer Supported Collaborative Learning (CSCL) 2017, Volume 1. Philadelphia, PA: International Society of the Learning Sciences.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning.iloc[845].citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>iso</th>\n",
       "      <th>uri</th>\n",
       "      <th>type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>issued</th>\n",
       "      <th>accessioned</th>\n",
       "      <th>citation</th>\n",
       "      <th>available</th>\n",
       "      <th>abstract</th>\n",
       "      <th>value</th>\n",
       "      <th>author_name_length</th>\n",
       "      <th>author_order</th>\n",
       "      <th>shortend_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>import2018/219</td>\n",
       "      <td>[boundary crossing, quantified self, infograph...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://doi.dx.org/10.22318/cscl2018.1001</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>International Society of the Learning Science...</td>\n",
       "      <td>From Quantified Self to Building a More Fit Co...</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>2018-11-04 23:26:23+00:00</td>\n",
       "      <td>sommer, s. &amp; Polman, J. L. (2018). From Quanti...</td>\n",
       "      <td>2018-11-04 23:26:23+00:00</td>\n",
       "      <td>This design case study considers one teacher's...</td>\n",
       "      <td>sommer, stephen</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>sommer s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>import2018/219</td>\n",
       "      <td>[boundary crossing, quantified self, infograph...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://doi.dx.org/10.22318/cscl2018.1001</td>\n",
       "      <td>Book chapter</td>\n",
       "      <td>International Society of the Learning Science...</td>\n",
       "      <td>From Quantified Self to Building a More Fit Co...</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>2018-11-04 23:26:23+00:00</td>\n",
       "      <td>sommer, s. &amp; Polman, J. L. (2018). From Quanti...</td>\n",
       "      <td>2018-11-04 23:26:23+00:00</td>\n",
       "      <td>This design case study considers one teacher's...</td>\n",
       "      <td>Polman, Joseph L</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Polman J. L.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index                                            subject iso  \\\n",
       "399   import2018/219  [boundary crossing, quantified self, infograph...  en   \n",
       "1238  import2018/219  [boundary crossing, quantified self, infograph...  en   \n",
       "\n",
       "                                            uri          type  \\\n",
       "399   https://doi.dx.org/10.22318/cscl2018.1001  Book chapter   \n",
       "1238  https://doi.dx.org/10.22318/cscl2018.1001  Book chapter   \n",
       "\n",
       "                                              publisher  \\\n",
       "399    International Society of the Learning Science...   \n",
       "1238   International Society of the Learning Science...   \n",
       "\n",
       "                                                  title   issued  \\\n",
       "399   From Quantified Self to Building a More Fit Co...  2018-07   \n",
       "1238  From Quantified Self to Building a More Fit Co...  2018-07   \n",
       "\n",
       "                   accessioned  \\\n",
       "399  2018-11-04 23:26:23+00:00   \n",
       "1238 2018-11-04 23:26:23+00:00   \n",
       "\n",
       "                                               citation  \\\n",
       "399   sommer, s. & Polman, J. L. (2018). From Quanti...   \n",
       "1238  sommer, s. & Polman, J. L. (2018). From Quanti...   \n",
       "\n",
       "                     available  \\\n",
       "399  2018-11-04 23:26:23+00:00   \n",
       "1238 2018-11-04 23:26:23+00:00   \n",
       "\n",
       "                                               abstract             value  \\\n",
       "399   This design case study considers one teacher's...   sommer, stephen   \n",
       "1238  This design case study considers one teacher's...  Polman, Joseph L   \n",
       "\n",
       "      author_name_length  author_order shortend_names  \n",
       "399                   15             0      sommer s.  \n",
       "1238                  16             1   Polman J. L.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning[cleaning['index'] == 'import2018/219']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning.rename(columns={'index': 'file', 'value':'long_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the identifier string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors_month(sentence, debug = False):\n",
    "    regex = r'[ééüş\\xad\\p{L}\\,\\ \\.\\:\\;\\/\\&\\-\\'\\`\\(\\)\\’\\–\\¨\\…\\‐\\*\\´\\＆\\\\]*\\([\\,\\ \\p{L}\\d\\-]*(18|19|20)\\d{2}[\\,\\ \\p{L}\\d\\-]*\\)'\n",
    "    match_bad_year = r'[\\S\\s]*\\((18|19|20)\\d{2}\\/(18|19|20)\\d{2}\\)'\n",
    "\n",
    "    match_press = r'[\\S\\s]*\\((i|I)n (P|p)ress|manuscript under review\\)'\n",
    "    match_forth = r'[\\S\\s]*\\((f|F)orthcoming\\)'\n",
    "    match_accepted = r'[\\S\\s]*\\((a|A)ccepted\\)'\n",
    "    match_submitted = r'[\\S\\s]*\\((s|S)ubmitted\\)'\n",
    "    match_underreview = r'[\\S\\s]*\\((u|U)nder (R|r)eview\\)'\n",
    "\n",
    "    #sentence = sentence.lower()\n",
    "    if reg.match(regex, sentence):\n",
    "        s = reg.search(regex, sentence).group(0)\n",
    "        if len(s) > 9:\n",
    "            return s\n",
    "    elif re.match(match_bad_year, sentence):\n",
    "        return re.search(match_bad_year, sentence).group(0)\n",
    "    elif re.match(match_press, sentence):\n",
    "        return re.search(match_press, sentence).group(0)\n",
    "    elif re.match(match_forth, sentence):\n",
    "        return re.search(match_forth, sentence).group(0)\n",
    "    elif re.match(match_accepted, sentence):\n",
    "        return re.search(match_accepted, sentence).group(0)\n",
    "    elif re.match(match_submitted, sentence):\n",
    "        return re.search(match_submitted, sentence).group(0)\n",
    "    elif re.match(match_underreview, sentence):\n",
    "        return re.search(match_underreview, sentence).group(0)\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def author_title(x):\n",
    "    \"\"\"Gets author and tite part of reference string\"\"\"\n",
    "    ref = x\n",
    "    authors = get_authors_month(x)  \n",
    "    if isinstance(authors, float):\n",
    "        return None\n",
    "    \n",
    "    search = len(authors)+1\n",
    "\n",
    "    end = re.search('\\.|\\?|In Looi', ref[search:])\n",
    "    if end:\n",
    "        end = end.start()\n",
    "    else:\n",
    "        end = 0\n",
    "    return ref[: (search+end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning['identifier'] = cleaning[cleaning.citation.notna()].citation.map(lambda x: author_title(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning.to_csv('../data/Parsed_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning['merge_index'] = cleaning.apply(lambda x: x['file']+str(x['author_order']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaning.long_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cleaning.long_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandoval, William | Sandoval, William A.\n",
      "Barth-Cohen, Lauren | Barth-Cohen, Lauren A.\n",
      "Gil, Alfredo Jornet | Jornet, Alfredo\n",
      "Flood, Virginia J | Flood, Virginia J.\n",
      "Yoon, Susan | Yoon, Susan A.\n",
      "Gutiérrez, José | Gutiérrez, José Francisco\n",
      "Olsen, Jennifer | Olsen, Jennifer K.\n",
      "Dornfeld, Catherine | Dornfeld, Catherine L.\n",
      "Tissenbaum, Catherine Louise Dornfeld | Dornfeld, Catherine L.\n",
      "Lanouette, Kathryn | Lanouette, Kathryn A.\n",
      "Litts, Breanne K | Litts, Breanne K.\n",
      "Tan, Edna Tan | Tan, Edna\n",
      "Tomar, Gaurav | Tomar, Gaurav Singh\n",
      "Yip, Jason | Yip, Jason C.\n",
      "Hickey, Daniel | Hickey, Daniel T.\n",
      "Margulieux, Lauren E | Margulieux, Lauren E.\n",
      "Evenstone, Amanda L. | Siebert-Evenstone, Amanda L.\n",
      "Siebert-Evenstone, Amanda | Siebert-Evenstone, Amanda L.\n",
      "Martin, Nicole | Martin, Nicole D.\n",
      "Wise, Alyssa | Wise, Alyssa Friend\n",
      "Irgens, Golnaz Arastoopour | Arastoopour, Golnaz\n",
      "Tissenbaum, Catherine Louise Dornfeld | Dornfeld, Catherine\n",
      "Danish, Joshua | Danish, Joshua A.\n",
      "Richard, Gabriela | Richard, Gabriela T.\n",
      "Jacobson, Michael | Jacobson, Michael J.\n",
      "Jordan, Michelle E. Jordan | Jordan, Michelle E.\n",
      "Minshew, Lana | Minshew, Lana M.\n",
      "Slotta, James | Slotta, James D.\n",
      "sommer, stephen | Sommer, Stephen\n",
      "Pöysä-Tarhonen, Johanna | Pöysä-Tarhonen, Johanna\n",
      "Penuel, William R. | Penuel, William\n",
      "Clegg, Tamara L. | Clegg, Tamara\n",
      "Ramey, Kay E | Ramey, Kay E.\n",
      "McBride, Elizabeth | McBride, Elizabeth A.\n",
      "Walsh, Elizabeth | Walsh, Elizabeth M.\n",
      "Barber-Lester, Kelly Johnson | Barber-Lester, Kelly J.\n",
      "Barber-Lester, Kelly | Barber-Lester, Kelly J.\n",
      "Splichal, Jin Michael | Splichal, Jin MIchael\n",
      "Siebert-Evenstone, Amanda | Evenstone, Amanda L.\n",
      "Rau, Martina | Rau, Martina A.\n",
      "Smith, Blaine Elizabeth | Smith, Blaine\n",
      "Chan, Carol K.K. | Chan, Carol\n",
      "Chan, Carol K. K. | Chan, Carol\n",
      "Searle, Kristin A. | Searle, Kristin A\n",
      "Polman, Joseph | Polman, Joseph L\n",
      "Linn, Marcia C. | Linn, Marcia\n",
      "Ruis, Andrew R. | Ruis, Andrew\n",
      "Wan, Sancia Wai-San | Wan, Sally Wai Yan\n",
      "Wallon, Robert C. | Wallon, Robert C\n",
      "Peppler, Kylie | Peppler, Kylie A\n",
      "betser, sagit | Betser, Sagit\n",
      "Keifert, Danielle | Keifert, Danielle Teodora\n",
      "Keifert, Danielle T. | Keifert, Danielle Teodora\n",
      "Lui, Debora A. | Lui, Debora\n",
      "Walker, Justice T. | Walker, Justice Toshiba\n",
      "Wu, Sally P. W. | Wu, Sally P.W.\n",
      "Wu, Sally | Wu, Sally P.W.\n",
      "Chase, Catherine C. | Chase, Catherine\n",
      "Halverson, Erica R. | Halverson, Erica\n",
      "Gomoll, Andrea S. | Gomoll, Andrea Sarah\n",
      "Kafai, Yasmin B. | kafai, yasmin\n",
      "Kafai, Yasmin | kafai, yasmin\n",
      "Quintana, Rebecca | Quintana, Rebecca M\n",
      "Quintana, Rebecca M. | Quintana, Rebecca M\n",
      "Dyer, Elizabeth B | Dyer, Elizabeth B.\n",
      "Keifert, Danielle T. | Keifert, Danielle\n",
      "Cavera, Veronica L. | Cavera, Veronica L\n",
      "Lankes, Eva-Maria | Ternblad, Eva-Maria\n",
      "Applebaum, Lauren | Applebaum, Lauren R.\n",
      "Quintana, Rebecca M. | Quintana, Rebecca\n",
      "Lund, Kristine S. | Lund, Kristine\n",
      "Noushad, Noora F Noushad | Noushad, Noora F.\n",
      "Taylor, Katie Headrick Taylor | Taylor, Katie Headrick\n",
      "Wu, Sally | Wu, Sally P. W.\n",
      "Schwendimann, Beat | Schwendimann, Beat A.\n",
      "Vitale, Jonathan M. | Vitale, Jonathan\n",
      "Eagan, Brendan | Eagan, Brendan R.\n",
      "Eagan, Brendan R | Eagan, Brendan R.\n",
      "Brami, Uzi | Brami, Uzi Zevik\n",
      "de Jong, Ton | de Jong, Frank\n",
      "Schmitt, Lara | Schmitt, Lara Johanna\n",
      "Levy, Sharona T. | Levy, Sharona T\n",
      "Levy, Sharona | Levy, Sharona T\n",
      "Harrer, Benedikt Walter | Harrer, Benedikt W.\n",
      "Easterday, Matthew | Easterday, Matthew W.\n",
      "Silver, Cindy Hmelo | Hmelo-Silver, Cindy E.\n",
      "Hmelo-Silver, Cindy | Hmelo-Silver, Cindy E.\n",
      "Kafai, Yasmin | Kafai, Yasmin B.\n",
      "Pea, Roy D. | Pea, Roy\n",
      "Chan, Carol K. K. | Chan, Carol K.K.\n",
      "Shaffer, David | Shaffer, David Williamson\n",
      "Graville, Cynthia Story | Graville-Smith, Cynthia\n",
      "Gu, Xiaoqing Gu | Gu, Xiaoqing\n",
      "Krämer, Nicole | Krämer, Nicole C.\n",
      "Krämer, Nicole | Krämer, Nicole C.\n",
      "Champion, Dionne | Champion, Dionne N.\n",
      "Chee, Joon Kit Kelvin | Looi, Chee-Kit\n",
      "Rosé, Carolyn Penstein | Rosé, Carolyn\n",
      "Rosé, Carolyn P. | Rosé, Carolyn\n",
      "Sayre, Eleanor C. | Sayre, Eleanor C\n",
      "Williams, Joseph Jay | Williams, Joseph\n",
      "de los Santos, Elizabeth Xeng | de Freitas, Elizabeth\n",
      "Barber-Lester, Kelly | Barber-Lester, Kelly Johnson\n",
      "Kang, Seokbin | kang, Seokbin\n",
      "Brown, David E. | Brown, David\n",
      "Levy, Sharona | Levy, Sharona T.\n",
      "Hmelo-Silver, Cindy | Silver, Cindy Hmelo\n",
      "McDonald, Scott P. | McDonald, Scott\n",
      "McElhaney, Kevin W. | McElhaney, Kevin W\n",
      "Eagan, Brendan R | Eagan, Brendan\n",
      "Gerber, Elizabeth | Gerber, Elizabeth M.\n",
      "Quick, Joshua | Quick, Joshua D.\n",
      "Rosé, Carolyn P. | Rosé, Carolyn Penstein\n",
      "Trăușan-Matu, Ștefan | Trăușan-Matu, Ștefan\n",
      "Anderson, Janice L. | Anderson, Janice\n",
      "Fields, Deborah | Fields, Deborah A.\n",
      "von Davier, Alina A. | von Davier, Alina\n",
      "Franklin, Scott V. | Franklin, Scott\n",
      "Nathan, Mitchell J. | Nathan, Mitchell\n",
      "Silva, Brenda López | Silva, Brenda Lopez\n",
      "Phillips, Abigail | Phillips, Abigail Leigh\n",
      "Kirschner, Paul A. | Kirschner, Paul\n",
      "Krämer, Nicole | Krämer, Nicole\n",
      "Lin, Chiu-Pin | Lin, Chiu Pin\n",
      "Häkkinen, Päivi | Häkkinen, Päivi\n",
      "Froehlich, Jon | Froehlich, Jon E.\n",
      "Mäkitalo, Åsa | Mäkitalo, Åsa\n",
      "Weiss, Patrice L. | Weiss, Patrice L. Tamar\n"
     ]
    }
   ],
   "source": [
    "d= {}\n",
    "for i, m in enumerate(names):\n",
    "    for j, n in enumerate(names):\n",
    "        if i < j:\n",
    "            y = set([i.lower() for i in reg.split(' |\\,|\\-', unicodedata.normalize('NFC', m)) if len(reg.sub('\\.', '', i)) > 1])\n",
    "            name = set([i.lower() for i in reg.split(' |\\,|\\-', unicodedata.normalize('NFC', n)) if len(reg.sub('\\.', '', i)) > 1])\n",
    "            if len(name.intersection(y)) > 1 and n!= m and not ('Lee' in n or 'Lee' in m):\n",
    "                d[n]= m\n",
    "                print(n, '|', m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-08ed57e4e49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcleaning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Biblio/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'"
     ]
    }
   ],
   "source": [
    "cleaning.loc[cleaning['value'].isin(d.keys()), 'value'] = cleaning.long_name.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaning.value.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning.loc[cleaning['value'].isin(d.keys()), 'long_name'] = cleaning.long_name.map(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
