{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import regex as reg\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "USER_ENV = 'data/' \n",
    "rootdir = USER_ENV + 'papers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will describe the extraction of information relating to the affiliation of the paper authors.\n",
    "To this means, I used the header section of each paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads txt file of each paper and stores it in contents\n",
    "contents = []\n",
    "i = 0\n",
    "source = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        source.append(file[:-4])\n",
    "        if 'txt' in file:\n",
    "            i += 1\n",
    "            path = os.path.join(subdir, file)\n",
    "            with open(path) as file:\n",
    "                try:\n",
    "                    text = file.read()\n",
    "                    contents.append(text)\n",
    "                except:\n",
    "                    #Will fails for some files in python 3 \n",
    "                    name, message, content = sys.exc_info()\n",
    "                    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_text = pd.DataFrame([contents, source]).T.rename(columns={0:'text', 1:'file'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning Scientific Practices Through Particip...</td>\n",
       "      <td>import2018_371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visualizing Complex Classrooms Through Real Ti...</td>\n",
       "      <td>import2018_417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opening the Door to Algebra: The Role of Fract...</td>\n",
       "      <td>import2018_403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Measuring Maker Mindset: Establishing Content ...</td>\n",
       "      <td>import2018_365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fostering University Freshmen’s Mathematical A...</td>\n",
       "      <td>import2016full_78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               file\n",
       "0  Learning Scientific Practices Through Particip...     import2018_371\n",
       "1  Visualizing Complex Classrooms Through Real Ti...     import2018_417\n",
       "2  Opening the Door to Algebra: The Role of Fract...     import2018_403\n",
       "3  Measuring Maker Mindset: Establishing Content ...     import2018_365\n",
       "4  Fostering University Freshmen’s Mathematical A...  import2016full_78"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding affiliation (University) using email:\n",
    "\n",
    "### Domain mapping:\n",
    "\n",
    "Importing the mapping from domain to university (and country!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = open(USER_ENV+'/world_universities_and_domains.json').read()\n",
    "parsed_json = json.loads(schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of schools in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9682"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rational for using email vs extracting institution from text:\n",
    "- easier to parse from text\n",
    "- unique / more robust to spelling changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the maximal number of domains per school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal number of domains per school:  3\n"
     ]
    }
   ],
   "source": [
    "print('Maximal number of domains per school: ', max([len(j['domains']) for j in parsed_json]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the mapping from domain to university\n",
    "mapping = {}\n",
    "#creating mapping from domain to country\n",
    "country_uni = {}\n",
    "for j in parsed_json:\n",
    "    mapping[j['domains'][0]] = j['name']\n",
    "    country_uni[j['domains'][0]] = j['country']\n",
    "    if len(j['domains']) > 1:\n",
    "        mapping[j['domains'][1]] = j['name']\n",
    "        country_uni[j['domains'][1]] = j['country']\n",
    "    if len(j['domains']) > 2:\n",
    "        mapping[j['domains'][2]] = j['name']\n",
    "        country_uni[j['domains'][2]] = j['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to add the following domains as they come up often and do not appear in the above dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in the most common university names not in json\n",
    "mapping['nie.edu.sg'] = \"National Institute of Education (NIE), Singapore\"\n",
    "mapping['rub.de'] = \"Ruhr-University Bochum\"\n",
    "mapping['uni-due.de'] = \"Universität Duisburg-Essen\"\n",
    "mapping['collide.info'] = \"Universität Duisburg-Essen\"\n",
    "mapping['dawsoncollege.qc.ca'] = \"Dawson College\"\n",
    "mapping['dawsoncollege.ca'] = \"Dawson College\"\n",
    "mapping['johnabbott.qc.ca'] = \"John Abbott College\"\n",
    "mapping['johnabbott.ca'] = \"John Abbott College\"\n",
    "mapping['vaniercollege.qc.ca'] = 'Vanier Colleege'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions are used to get the mapping for a given email and extract the email from text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_from_mail(mail, mapping):\n",
    "    \"\"\"Maps email to institution\"\"\"\n",
    "    if mail in mapping:\n",
    "        return mapping[mail], mail\n",
    "    elif reg.findall('[\\p{L}0-9\\-]*\\.[\\p{L}0-9\\-]*$', mail)[0] in mapping:\n",
    "        double = reg.findall('[\\p{L}0-9\\-]*\\.[\\p{L}0-9\\-]*$', mail)[0]\n",
    "        return mapping[double], double\n",
    "    else:\n",
    "        triplet = reg.findall('[\\p{L}0-9\\-]*\\.[\\p{L}0-9\\-]*\\.[\\p{L}0-9\\-]*$', mail)\n",
    "        if len(triplet) > 0 and triplet[0] in mapping:\n",
    "            return (mapping[triplet[0]], triplet[0])\n",
    "        else:\n",
    "            return np.nan, mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emails(x):\n",
    "    text, file = x.text, x.file\n",
    "    abstract_pos = text.find('\\nAbstract')\n",
    "    mails_in_paper = reg.findall('[\\p{L}0-9\\.\\-\\+\\_]*@[\\p{L}0-9\\.\\-]*\\.[\\p{L}0-9\\.\\-]*(?!\\S*\\:\\S*)', \n",
    "                                 text[:abstract_pos])\n",
    "    return [(file, get_school_from_mail(m.split('@')[1].lower(), mapping), m) for m in mails_in_paper]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.DataFrame([ (email[0], email[1][0], email[1][1], email[2], i) \n",
    "              for paper in paper_text.apply(find_emails, axis=1).tolist() for i, email in enumerate(paper)]\n",
    "            , columns=['file', 'name', 'domain', 'email', 'author_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>rebecca.swanson@colorado.edu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>leighanna.hinojosa@colorado.edu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>joseph.polman@colorado.edu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>indiana.edu</td>\n",
       "      <td>huang220@indiana.edu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>agomoll90@gmail.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                               name        domain  \\\n",
       "0  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "1  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "2  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "3  import2018_417  Indiana University at Bloomington   indiana.edu   \n",
       "4  import2018_417                                NaN     gmail.com   \n",
       "\n",
       "                             email  author_order  \n",
       "0     rebecca.swanson@colorado.edu             0  \n",
       "1  leighanna.hinojosa@colorado.edu             1  \n",
       "2       joseph.polman@colorado.edu             2  \n",
       "3             huang220@indiana.edu             0  \n",
       "4              agomoll90@gmail.com             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of files that could be parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers from which we parse mails :  864\n",
      "Total number of papers :  874\n"
     ]
    }
   ],
   "source": [
    "print('Papers from which we parse mails : ', len(emails.file.unique()))\n",
    "print('Total number of papers : ', len(paper_text.file.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers for which we can not find emails are papers that were not parsed propperly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'import2016full_91',\n",
       " 'import2016full_92',\n",
       " 'import2016full_93',\n",
       " 'import2016full_94',\n",
       " 'import2016full_95',\n",
       " 'import2016full_96',\n",
       " 'import2016full_97',\n",
       " 'import2016full_98',\n",
       " 'import2016short_146',\n",
       " 'import2018_246'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_files = set(paper_text.file.tolist())- set(emails.file.tolist())\n",
    "bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106    Author Index\\nPages 1-702: Volume 1\\nPages 703...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_text[paper_text.file == 'import2016full_91'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multimodal Learning Analytics for the Qualitative Researcher\\nAuthor Name, Institution, Email\\nAbstract: The area of learning analytics is often viewed as a tool for supporting quantitative\\nanalysis. Ba'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_text[paper_text.file == 'import2018_246'].text.tolist()[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are unable to get the university for 1/5 of all emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1689836268149521"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails['name'].isna()].shape[0]/emails.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails['name'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is largely due to so many people using gmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com         215\n",
       "sri.com            24\n",
       "concord.org        16\n",
       "msichicago.org     11\n",
       "ets.org            11\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails['name'].isna()].domain.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the country to a person:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can simply use the mapping that we had defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['country'] = emails.domain.map(country_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>rebecca.swanson@colorado.edu</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>leighanna.hinojosa@colorado.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>joseph.polman@colorado.edu</td>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>indiana.edu</td>\n",
       "      <td>huang220@indiana.edu</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>agomoll90@gmail.com</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                               name        domain  \\\n",
       "0  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "1  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "2  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "3  import2018_417  Indiana University at Bloomington   indiana.edu   \n",
       "4  import2018_417                                NaN     gmail.com   \n",
       "\n",
       "                             email  author_order        country  \n",
       "0     rebecca.swanson@colorado.edu             0  United States  \n",
       "1  leighanna.hinojosa@colorado.edu             1  United States  \n",
       "2       joseph.polman@colorado.edu             2  United States  \n",
       "3             huang220@indiana.edu             0  United States  \n",
       "4              agomoll90@gmail.com             1            NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of people to whom we could not associate a country, same as number of peopel to which we could not associate a University:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.country.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we can still add the country based on the email by identifying Country Code Top-Level Domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = open(USER_ENV+'/country-by-domain-tld.json').read()\n",
    "parsed_countries = json.loads(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Afghanistan', 'tld': '.af'},\n",
       " {'country': 'Albania', 'tld': '.al'},\n",
       " {'country': 'Algeria', 'tld': '.dz'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_countries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering to define mapping\n",
    "parsed_countries = { parsed['tld']: parsed['country'] for parsed in parsed_countries}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some values are missing and add them to the mapping in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_countries['.uk']= \"United Kingdom\"\n",
    "parsed_countries['.us']  = \"United States\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following regex will match the top level domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_domain = '(\\.[a-zA-Z0-9]*$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.uk']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example:\n",
    "re.findall(match_domain,'ahaha.ad.uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first extract top level domain, the use matching to assign country\n",
    "emails.loc[emails.country.isna(), 'country'] = emails[emails.country.isna()].domain.map(\n",
    "    lambda x: re.findall(match_domain,x)[0]).map(parsed_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give a country to a large number of authors that way, keeping in mind that many of them are gmail adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.country.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com         215\n",
       "sri.com            24\n",
       "collide.info       20\n",
       "concord.org        16\n",
       "msichicago.org     11\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.country.isna()].domain.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unmatched domains are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".com             287\n",
       ".org              87\n",
       ".edu              22\n",
       ".info             20\n",
       ".net              16\n",
       ".gov               2\n",
       ".northwestern      1\n",
       ".college           1\n",
       ".cg                1\n",
       ".ed                1\n",
       ".swiss             1\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.country.isna()].domain.map(lambda x: re.findall(match_domain,x)[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't say much about location from the remaining emails.\n",
    "\n",
    "As still a lot of mails are remaining, we use more fancy ways to parse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better email parsing using named entity detection: \n",
    "\n",
    "In this section we will use a complementary approach to extract more universities by using Name entitiy dectection and some clever heuristics.\n",
    "\n",
    "First defining the data to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude bad files\n",
    "pre_abstract = paper_text[~paper_text.file.isin(bad_files)].copy()\n",
    "\n",
    "#only consider portion before abstract\n",
    "pre_abstract['text'] = pre_abstract.text.map(lambda paper: paper[:paper.find('\\nAbstract')])\n",
    "pre_abstract['file'] = paper_text.file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning Scientific Practices Through Particip...</td>\n",
       "      <td>import2018_371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visualizing Complex Classrooms Through Real Ti...</td>\n",
       "      <td>import2018_417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opening the Door to Algebra: The Role of Fract...</td>\n",
       "      <td>import2018_403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Measuring Maker Mindset: Establishing Content ...</td>\n",
       "      <td>import2018_365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fostering University Freshmen’s Mathematical A...</td>\n",
       "      <td>import2016full_78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               file\n",
       "0  Learning Scientific Practices Through Particip...     import2018_371\n",
       "1  Visualizing Complex Classrooms Through Real Ti...     import2018_417\n",
       "2  Opening the Door to Algebra: The Role of Fract...     import2018_403\n",
       "3  Measuring Maker Mindset: Establishing Content ...     import2018_365\n",
       "4  Fostering University Freshmen’s Mathematical A...  import2016full_78"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_abstract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split up the pre-abstract string in order to get the different parts, names, emails, the associated organisation.\n",
    "\n",
    "As some universities have the following format (general location, precise location):\n",
    "`University of California, Berkely`\n",
    "We merge strings together if there are two subsequents segments of the string which contain a mention of a country or city. The GeoText library allows to do that. The library can not perfectly recoginize all location strings, but as it does not make calls to an external API we prefer it here. It is sufficient for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geotext import GeoText\n",
    "\n",
    "def get_header_units(text):\n",
    "    x = [reg.sub('\\([\\w]*\\)' , '', i.strip()) for i in reg.split('\\n|\\,|/|;', text) if len(i.strip()) > 0]\n",
    "    for i, sentence in enumerate(x):\n",
    "        places = GeoText(sentence)\n",
    "        if (len(places.cities) > 0 and sentence == places.cities[0]) or \\\n",
    "        (len(places.countries) > 0 and sentence == places.countries[0]):\n",
    "            x[i-1] += ', '+sentence\n",
    "            x[i] = ''\n",
    "        if '@' in sentence:\n",
    "            x[i] = [mail.strip() for mail in sentence.split(' ') if '@' in mail][0]\n",
    "    return [i.strip() for i in x if len(i.strip()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_abstract['split_header'] = pre_abstract.text.map(get_header_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get a first idea what kind of words could help us identify universities we look at frequency counts in the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(x):\n",
    "    name = []\n",
    "    for i, sentence in enumerate(x):\n",
    "        if '@' in sentence:\n",
    "            if not '@' in x[i-1]:\n",
    "                name.append(x[i-1].split(' '))\n",
    "    return [i for x in name for i in x if (len(GeoText(i).cities) == 0 and len(GeoText(i).countries) == 0) or 'University' in i]\n",
    "\n",
    "Potential_universities = [i for x in pre_abstract.split_header.tolist() for i in explore_data(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "University        1706\n",
       "of                1067\n",
       "and                270\n",
       "State              171\n",
       "The                115\n",
       "at                  98\n",
       "Institute           95\n",
       "College             86\n",
       "Technology          78\n",
       "Pennsylvania        73\n",
       "Indiana             69\n",
       "Illinois            65\n",
       "California,         57\n",
       "New                 55\n",
       "Stanford            48\n",
       "Hong                46\n",
       "Northwestern        45\n",
       "Mellon              44\n",
       "Kong                41\n",
       "Duisburg-Essen      41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Potential_universities).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from this list we gathered the following list of words marking a string as an institution of some kind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Institutions = ['Universiteit', 'Università', 'Universität','University','Universidad', 'Institute',\n",
    "                'Instituto', 'College', 'Col·legi', 'École','Ecole', 'Center', 'Gimnasio', 'UniDistance', \n",
    "                'Gymnasium', 'School', 'Bundeswehr', 'Foundation', 'Department', 'Universidade', 'Google', 'Technion',\n",
    "               'Consortium', 'Faculty', 'CNRS', 'Ministry', 'Museum', 'Lab', 'Scuola']\n",
    "\n",
    "match_institutions = '|'.join(Institutions+['Eureka']).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list will be used later to refine our search and is not used uniquely to idenfity if a subsequence of a sentence is the university name or not. To find the whole list we manually went through the not so long list of potential universities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we use spacy to tag certain entities (Named entity dectection). Spacy works reasonably well, but not well enough to just use it by itself, as it is is very error prone for the categories we use it for. It also labels asian names as organisations :(. To circumvent this we use regex to detect alternative entities and clean up string to increase the chances of a string getting labeled correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def person_or_org(doc):\n",
    "    for ent in doc.ents:\n",
    "        if  ent.label_ == 'ORG':\n",
    "            return 'ORG'\n",
    "        if  ent.label_ == 'PERSON' and len(ent.text) < 50:\n",
    "            return 'PERSON'\n",
    "    return '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the names from the metadata to identify people for when is person fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../data/Parsed_metadata.csv')\n",
    "names = metadata.long_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the unicode data to increase overlap so that characters that look the same are treated the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isname(names, x):\n",
    "    pot = []\n",
    "    for n in names:\n",
    "        y = set([i for i in reg.split(' |\\,|\\-', unicodedata.normalize('NFC', x)) if len(i) > 0])\n",
    "        name = set([i for i in reg.split(' |\\,|\\-', unicodedata.normalize('NFC', n)) if len(i) > 0])\n",
    "        if len(name.intersection(y)) > 1:\n",
    "            pot.append(n)\n",
    "    if len(pot) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unis = set(emails.name.dropna().unique()+['Ben-Gurion University of the Negev'])#set(pd.Series(list(mapping.values())).drop_duplicates().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a tagger that tagges the first part of the emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_element(x):\n",
    "    if reg.search('@', x):\n",
    "        return 'EMAIL'\n",
    "    \n",
    "    #do cheap operations first\n",
    "    if isname(set(names), x):\n",
    "        return 'PERSON'\n",
    "    if re.search(match_institutions, x):\n",
    "        return 'ORG'\n",
    "    if isname(unis, x):\n",
    "        return 'ORG'\n",
    "    \n",
    "    y = nlp(x)\n",
    "    return person_or_org(y)\n",
    "\n",
    "def tag_elements(sentence):\n",
    "    return [(i, tag_element(i)) for j, i in enumerate(sentence)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'>Warning: this line takes forever to run</sapn>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = pre_abstract.split_header.map(tag_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is the used to extract emails and the corresponding institution.\n",
    "The idea behind the algoritms is that there are two ways the people and emails are listed. We decide what type of listing a paper used and extract email - association using this additonal knowledge: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Collaborative Scientizing in Pokémon GO Online Communities', 'ORG'),\n",
       "  ('Jason C. Yip', 'PERSON'),\n",
       "  ('Travis W. Windleharth', 'PERSON'),\n",
       "  ('and Jin Ha Lee', 'PERSON'),\n",
       "  ('jcyip@uw.edu', 'EMAIL'),\n",
       "  ('travisw@uw.edu', 'EMAIL'),\n",
       "  ('jinhalee@uw.edu', 'EMAIL'),\n",
       "  ('University of Washington', 'ORG'),\n",
       "  ('The Information School – GAMER Lab', 'ORG')]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure.sample(1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Combinations:\n",
    "\n",
    "1. PERSON '' ORG EMAIL\n",
    "2. PERSON PERSON () EMAIL EMAIL () ORG\n",
    "\n",
    "The function below identifies which type we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_type_1(list_):\n",
    "    string = ''.join(list_)\n",
    "    return 'EMAILORG' in string or 'EMAILEMAIL' in string\n",
    "\n",
    "def list_type_2(list_):\n",
    "    string = ''.join(list_)\n",
    "    #second part handles missclassification\n",
    "    return 'ORG'+'EMAIL' in string or 'ORGORGEMAIL' in string or '?EMAIL' in string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions are then used to extract the corresponding mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_org_mapping(tagged):\n",
    "    mapping = {}\n",
    "    mail_before_org = []\n",
    "    org = ''\n",
    "    for index, (text, tag) in enumerate(tagged):\n",
    "        if tag == 'EMAIL':\n",
    "            mail_before_org.append(text)\n",
    "        if tag == 'ORG' or tag=='?' and len(mail_before_org) > 0:\n",
    "            org += text\n",
    "            \n",
    "            if not (index+1 < len(tagged) and tagged[index+1][1] == 'ORG'):\n",
    "                for mail in mail_before_org:\n",
    "                    mapping[mail] = text\n",
    "                mail_before_org = []\n",
    "                org = ''\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_email_mapping(tagged):\n",
    "    mapping = {}\n",
    "    for index, (text, tag) in enumerate(tagged):\n",
    "\n",
    "        if tag == 'EMAIL' and tagged[index-1][1] == 'ORG':\n",
    "            org = ''\n",
    "            if tagged[index-2][1] == 'ORG':\n",
    "                org = tagged[index-2][0] + ', ' \n",
    "            \n",
    "            mapping.update({text: org+tagged[index-1][0]})\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_uni_1 = {}\n",
    "\n",
    "_ = structure[structure.map(lambda x: [i for j, i in x]).map(list_type_1)].map(email_org_mapping\n",
    "                                                                             ).map(lambda x: mail_uni_1.update(x))\n",
    "mail_uni_2 = {}\n",
    "_ = structure[structure.map(lambda x: [i for j, i in x]).map(list_type_2)].map(org_email_mapping\n",
    "                                                                                 ).map(lambda x: mail_uni_2.update(x) if x else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we only have few mails for which we do not find an assoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.email.map(mail_uni_1).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.email.map(mail_uni_2).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['alternate_uni'] = emails.email.map(mail_uni_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[emails.alternate_uni.isna(), 'alternate_uni'] = emails.email.map(mail_uni_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people for which we don't have an association through either method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[(emails.name.isna()) & (emails.alternate_uni.isna())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So less than 1% goes unmapped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029182879377431907"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[(emails.name.isna()) & (emails.alternate_uni.isna())].shape[0]/emails.email.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additionaly, we could also find the names using this! as we tag person aswell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we unify the university namings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the overlap between the mapping we found using the first method and the second method to get them the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_unification = {}\n",
    "for i, row in emails[emails.alternate_uni.notna() &(emails.name.notna())][['name', 'alternate_uni']].iterrows():\n",
    "    if row.alternate_uni != row['name']:\n",
    "        uni_unification[row.alternate_uni] = row['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['fixed_uni'] = emails.alternate_uni.map(uni_unification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[emails.name.isna() & emails.fixed_uni.notna(), 'name'] = emails.fixed_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[emails.name.isna() & emails.alternate_uni.notna(), 'name'] = emails.alternate_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del emails['alternate_uni'], emails['fixed_uni']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the mails that are still missing. The issue with these two is due to the useage of `and`. Two isn't that bad so we ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>import2016short_166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kent.ac.uk</td>\n",
       "      <td>s.a.fincher@kent.ac.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>import2016short_166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kent.ac.uk</td>\n",
       "      <td>sd485@kent.ac.uk</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>import2016short_166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>getdown.org</td>\n",
       "      <td>ben+web@getdown.org</td>\n",
       "      <td>4</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>import2015short_191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>soeren.werneburg@gmail.com</td>\n",
       "      <td>3</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>import2016short_173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exeter.ac.uk</td>\n",
       "      <td>R.B.Wegerif@exeter.ac.uk</td>\n",
       "      <td>11</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file name        domain                       email  \\\n",
       "70   import2016short_166  NaN    kent.ac.uk      s.a.fincher@kent.ac.uk   \n",
       "71   import2016short_166  NaN    kent.ac.uk            sd485@kent.ac.uk   \n",
       "74   import2016short_166  NaN   getdown.org         ben+web@getdown.org   \n",
       "113  import2015short_191  NaN     gmail.com  soeren.werneburg@gmail.com   \n",
       "144  import2016short_173  NaN  exeter.ac.uk    R.B.Wegerif@exeter.ac.uk   \n",
       "\n",
       "     author_order         country  \n",
       "70              0  United Kingdom  \n",
       "71              1  United Kingdom  \n",
       "74              4       Singapore  \n",
       "113             3       Singapore  \n",
       "144            11  United Kingdom  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.loc[emails.name.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.to_csv('Uni.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fix the country aswell now that we have uni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_matching = {}\n",
    "for i, row in emails[emails.country.notna()].iterrows():\n",
    "    country_matching[row['name']] = row.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[emails.country.isna(), 'country'] = emails.name.map(country_matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a lot of non matching unis, we will fix this while we get the longitude and latitude of each location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.loc[emails.country.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>import2015short_218</td>\n",
       "      <td>Utsunomiya University</td>\n",
       "      <td>kubota-lab.net</td>\n",
       "      <td>kubota@kubota-lab.net</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>import2015short_218</td>\n",
       "      <td>Ibaraki University</td>\n",
       "      <td>suzuki-lab.net</td>\n",
       "      <td>hideyuki@suzuki-lab.net</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>import2017_77</td>\n",
       "      <td>Swiss Federal Institute for Vocational Educati...</td>\n",
       "      <td>iuffp.swiss</td>\n",
       "      <td>Alberto.Cattaneo@iuffp.swiss</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>import2018_211</td>\n",
       "      <td>School of Education, University of Nottingham</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>nurjanah.mjaafar@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>import2016short_167</td>\n",
       "      <td>South China Normal University</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>kateb369@gmail.com</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file                                               name  \\\n",
       "53   import2015short_218                              Utsunomiya University   \n",
       "54   import2015short_218                                 Ibaraki University   \n",
       "63         import2017_77  Swiss Federal Institute for Vocational Educati...   \n",
       "88        import2018_211      School of Education, University of Nottingham   \n",
       "163  import2016short_167                      South China Normal University   \n",
       "\n",
       "             domain                         email  author_order country  \n",
       "53   kubota-lab.net         kubota@kubota-lab.net             4     NaN  \n",
       "54   suzuki-lab.net       hideyuki@suzuki-lab.net             5     NaN  \n",
       "63      iuffp.swiss  Alberto.Cattaneo@iuffp.swiss             3     NaN  \n",
       "88        gmail.com    nurjanah.mjaafar@gmail.com             0     NaN  \n",
       "163       gmail.com            kateb369@gmail.com            18     NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.loc[emails.country.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using external sources to complete the dataset:\n",
    "\n",
    "First we use wikipedia as it does not have a limit on how many requests we can make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_uni = emails.name.dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "urllib3.disable_warnings()\n",
    "from urllib.parse import quote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "n_found = [] #saves names for which we do not find a matching\n",
    "\n",
    "for uni in Full_uni:\n",
    "    #Only use the first part of university name, removing specifications\n",
    "    u = reg.search('([\\p{L}\\ \\'\\-\\.\\&]*)', uni).group(0).strip()\n",
    "    if ' - ' in u:\n",
    "        u = reg.split(' - ', u)[0]\n",
    "        \n",
    "    #url with which we will query to find location\n",
    "    url =u'https://en.wikipedia.org/wiki/'+quote(u)\n",
    "    try:\n",
    "        http_pool = urllib3.connection_from_url(url)\n",
    "        r = http_pool.urlopen('GET',url)\n",
    "        data = r.data\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        loc = soup.find_all('span', class_='geo')[0].get_text()\n",
    "        country = soup.find_all('div', class_='country-name')[0].get_text()\n",
    "        location.append((uni, loc, country))\n",
    "        \n",
    "    except:\n",
    "        #list of universities for which we can not find a location\n",
    "        n_found.append((uni, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the locations in a dataframe and extract longitude and latitude separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_uni = pd.DataFrame(location, columns=['University', 'Location', 'Country'])\n",
    "\n",
    "location_uni.Location = location_uni.Location.map(lambda x: x.split(';'))\n",
    "\n",
    "location_uni['Lat'] = location_uni.Location.map(lambda x: float(x[0]))\n",
    "location_uni['Lon'] = location_uni.Location.map(lambda x: float(x[1]))\n",
    "\n",
    "del location_uni['Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make countries we got from wikipedia more uniform & extract country substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_uni.Country = location_uni.Country.map(lambda x: 'United States' if \n",
    "                                                ('U.S.' in x) or ('US' in x) else 'United Kingdom' if 'UK' in x else x)\n",
    "location_uni.Country = location_uni.Country.map(lambda x: GeoText(x).countries\n",
    "                                               ).map(lambda x: x[0] if len(x) else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly plotting to check whether longitude and latitude are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1284a6b00>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(location_uni['Lon'],  location_uni['Lat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still have 132 unfound locations!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an alternative method with geopy to get even more location matches:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using geopy every input will return some location, to avoid getting bad results we only check the location for Institutions, using the previously defined regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_found_institutions = [i for i, j in  n_found if reg.search(match_institutions, i.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_found_institutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hence we will try to find the location for 100 more places.\n",
    "\n",
    "Geopy has the dissadvantage that we can only make 1 request per second, and it can't be used heavily. \n",
    "When re-run to often the api will reject the requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"application_for_project_\")\n",
    "\n",
    "d= []\n",
    "not_found = []\n",
    "for n in n_found_institutions:\n",
    "    location = geolocator.geocode(n)\n",
    "    if location:\n",
    "        d.append({'Lat': location.latitude, 'Lon': location.longitude, 'University': n})\n",
    "    else:\n",
    "        not_found.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_locations = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>University</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.869481</td>\n",
       "      <td>-84.879569</td>\n",
       "      <td>Indiana University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.954725</td>\n",
       "      <td>-75.153469</td>\n",
       "      <td>Temple University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.296202</td>\n",
       "      <td>103.776899</td>\n",
       "      <td>National University of Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.729253</td>\n",
       "      <td>-73.996254</td>\n",
       "      <td>New York University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lat         Lon                        University\n",
       "0  39.869481  -84.879569                Indiana University\n",
       "1  39.954725  -75.153469                 Temple University\n",
       "2   1.296202  103.776899  National University of Singapore\n",
       "3  37.936437  -88.609499                  Tokyo University\n",
       "4  40.729253  -73.996254               New York University"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also associate a country to these universities, again using the country code:\n",
    "\n",
    "A small issue we have is that countries in the special administrative zone of china will be mapped to china instead of their original location (Universities in HongKong will be mapped to china instead of Hong Kong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = []\n",
    "for i, row in additional_locations.iterrows():\n",
    "    pos = str(row['Lat']) + ', ' + str(row['Lon'])\n",
    "    country = geolocator.reverse(pos, timeout = 10)\n",
    "    countries.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_mapping = {}\n",
    "_ = [country_code_mapping.update({c['alpha_two_code'].lower() : c['country']}) for c in parsed_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_locations['Country'] = pd.Series(\n",
    "    [c.raw['address']['country_code'] for c in countries]).map(country_code_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.869481</td>\n",
       "      <td>-84.879569</td>\n",
       "      <td>Indiana University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.954725</td>\n",
       "      <td>-75.153469</td>\n",
       "      <td>Temple University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.296202</td>\n",
       "      <td>103.776899</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.729253</td>\n",
       "      <td>-73.996254</td>\n",
       "      <td>New York University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lat         Lon                        University        Country\n",
       "0  39.869481  -84.879569                Indiana University  United States\n",
       "1  39.954725  -75.153469                 Temple University  United States\n",
       "2   1.296202  103.776899  National University of Singapore      Singapore\n",
       "3  37.936437  -88.609499                  Tokyo University  United States\n",
       "4  40.729253  -73.996254               New York University  United States"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the complete mapping is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_universities = pd.concat([additional_locations, location_uni], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now again unify a bit by checking if we have the same locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_uni = {}\n",
    "for i, row in location_universities.iterrows():\n",
    "    for j, row_2 in location_universities.iterrows():\n",
    "        if i < j and ',' not in row_2.University and row_2.University != row.University:\n",
    "            if (row_2['Lon'] == row['Lon']) & (row_2['Lat'] == row['Lat']):\n",
    "                number_used_row2 = emails[emails.name == row_2.University].shape[0]\n",
    "                number_used_row = emails[emails.name == row.University].shape[0]\n",
    "                if number_used_row > number_used_row2:\n",
    "                    rename_uni[row_2.University] =  row.University\n",
    "                else:\n",
    "                    rename_uni[row.University] =  row_2.University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ruhr-Universität Bochum': 'Ruhr-University Bochum'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this renaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_universities.loc[location_universities.University.isin(rename_uni.keys()), 'University'] = location_universities[location_universities.University.isin(rename_uni.keys())].University.map(rename_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[emails.name.isin(rename_uni.keys()),'name'] = emails.name.map(rename_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities = pd.merge(emails, location_universities, left_on='name', right_on='University', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>rebecca.swanson@colorado.edu</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.006670</td>\n",
       "      <td>-105.267220</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>leighanna.hinojosa@colorado.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.006670</td>\n",
       "      <td>-105.267220</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import2018_371</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>colorado.edu</td>\n",
       "      <td>joseph.polman@colorado.edu</td>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.006670</td>\n",
       "      <td>-105.267220</td>\n",
       "      <td>University of Colorado at Boulder</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>indiana.edu</td>\n",
       "      <td>huang220@indiana.edu</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.167222</td>\n",
       "      <td>-86.521389</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import2018_417</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>agomoll90@gmail.com</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.167222</td>\n",
       "      <td>-86.521389</td>\n",
       "      <td>Indiana University at Bloomington</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                               name        domain  \\\n",
       "0  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "1  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "2  import2018_371  University of Colorado at Boulder  colorado.edu   \n",
       "3  import2018_417  Indiana University at Bloomington   indiana.edu   \n",
       "4  import2018_417  Indiana University at Bloomington     gmail.com   \n",
       "\n",
       "                             email  author_order        country        Lat  \\\n",
       "0     rebecca.swanson@colorado.edu             0  United States  40.006670   \n",
       "1  leighanna.hinojosa@colorado.edu             1  United States  40.006670   \n",
       "2       joseph.polman@colorado.edu             2  United States  40.006670   \n",
       "3             huang220@indiana.edu             0  United States  39.167222   \n",
       "4              agomoll90@gmail.com             1  United States  39.167222   \n",
       "\n",
       "          Lon                         University        Country  \n",
       "0 -105.267220  University of Colorado at Boulder  United States  \n",
       "1 -105.267220  University of Colorado at Boulder  United States  \n",
       "2 -105.267220  University of Colorado at Boulder  United States  \n",
       "3  -86.521389  Indiana University at Bloomington  United States  \n",
       "4  -86.521389  Indiana University at Bloomington  United States  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mail extensions are a better indication, we use them as default and use the country found using the second method only we could not associate one using the first method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>import2015short_218</td>\n",
       "      <td>Utsunomiya University</td>\n",
       "      <td>kubota-lab.net</td>\n",
       "      <td>kubota@kubota-lab.net</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.549200</td>\n",
       "      <td>139.913900</td>\n",
       "      <td>Utsunomiya University</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>import2015short_218</td>\n",
       "      <td>Ibaraki University</td>\n",
       "      <td>suzuki-lab.net</td>\n",
       "      <td>hideyuki@suzuki-lab.net</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.401110</td>\n",
       "      <td>140.443060</td>\n",
       "      <td>Ibaraki University</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>import2016short_167</td>\n",
       "      <td>South China Normal University</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>kateb369@gmail.com</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.136500</td>\n",
       "      <td>113.349600</td>\n",
       "      <td>South China Normal University</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>import2016short_165</td>\n",
       "      <td>Universidade Federal de Sergipe</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>mapquero@gmail.com</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.924811</td>\n",
       "      <td>-37.100551</td>\n",
       "      <td>Universidade Federal de Sergipe</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>import2018_24</td>\n",
       "      <td>University of New South Wales</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>polly.k.lai@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.917780</td>\n",
       "      <td>151.231110</td>\n",
       "      <td>University of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file                             name          domain  \\\n",
       "53   import2015short_218            Utsunomiya University  kubota-lab.net   \n",
       "54   import2015short_218               Ibaraki University  suzuki-lab.net   \n",
       "163  import2016short_167    South China Normal University       gmail.com   \n",
       "294  import2016short_165  Universidade Federal de Sergipe       gmail.com   \n",
       "316        import2018_24    University of New South Wales       gmail.com   \n",
       "\n",
       "                       email  author_order country        Lat         Lon  \\\n",
       "53     kubota@kubota-lab.net             4     NaN  36.549200  139.913900   \n",
       "54   hideyuki@suzuki-lab.net             5     NaN  36.401110  140.443060   \n",
       "163       kateb369@gmail.com            18     NaN  23.136500  113.349600   \n",
       "294       mapquero@gmail.com             8     NaN -10.924811  -37.100551   \n",
       "316    polly.k.lai@gmail.com             0     NaN -33.917780  151.231110   \n",
       "\n",
       "                          University    Country  \n",
       "53             Utsunomiya University      Japan  \n",
       "54                Ibaraki University      Japan  \n",
       "163    South China Normal University      China  \n",
       "294  Universidade Federal de Sergipe     Brazil  \n",
       "316    University of New South Wales  Australia  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universities[(universities.country != universities.Country) & (\n",
    "    universities.country.isna()) & (universities.Country.notna())].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that country names are uniform we first run a mapping from country to University:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>email</th>\n",
       "      <th>author_order</th>\n",
       "      <th>country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>import2015short_218</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>u-tokyo.ac.jp</td>\n",
       "      <td>wakimoto@kals.c.u-tokyo.ac.jp</td>\n",
       "      <td>2</td>\n",
       "      <td>Japan</td>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>import2016short_167</td>\n",
       "      <td>Hong Kong Institute of Education</td>\n",
       "      <td>ied.edu.hk</td>\n",
       "      <td>mkapur@ied.edu.hk</td>\n",
       "      <td>19</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>22.469357</td>\n",
       "      <td>114.194742</td>\n",
       "      <td>Hong Kong Institute of Education</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>import2018_366</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>u-tokyo.ac.jp</td>\n",
       "      <td>ikejiri@iii.u-tokyo.ac.jp</td>\n",
       "      <td>1</td>\n",
       "      <td>Japan</td>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>import2018_366</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>u-tokyo.ac.jp</td>\n",
       "      <td>knakaya@iii.u-tokyo.ac.jp</td>\n",
       "      <td>2</td>\n",
       "      <td>Japan</td>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>import2018_366</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>u-tokyo.ac.jp</td>\n",
       "      <td>ryota@iii.u-tokyo.ac.jp</td>\n",
       "      <td>3</td>\n",
       "      <td>Japan</td>\n",
       "      <td>37.936437</td>\n",
       "      <td>-88.609499</td>\n",
       "      <td>Tokyo University</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file                              name         domain  \\\n",
       "51   import2015short_218                  Tokyo University  u-tokyo.ac.jp   \n",
       "164  import2016short_167  Hong Kong Institute of Education     ied.edu.hk   \n",
       "216       import2018_366                  Tokyo University  u-tokyo.ac.jp   \n",
       "217       import2018_366                  Tokyo University  u-tokyo.ac.jp   \n",
       "218       import2018_366                  Tokyo University  u-tokyo.ac.jp   \n",
       "\n",
       "                             email  author_order    country        Lat  \\\n",
       "51   wakimoto@kals.c.u-tokyo.ac.jp             2      Japan  37.936437   \n",
       "164              mkapur@ied.edu.hk            19  Hong Kong  22.469357   \n",
       "216      ikejiri@iii.u-tokyo.ac.jp             1      Japan  37.936437   \n",
       "217      knakaya@iii.u-tokyo.ac.jp             2      Japan  37.936437   \n",
       "218        ryota@iii.u-tokyo.ac.jp             3      Japan  37.936437   \n",
       "\n",
       "            Lon                        University        Country  \n",
       "51   -88.609499                  Tokyo University  United States  \n",
       "164  114.194742  Hong Kong Institute of Education          China  \n",
       "216  -88.609499                  Tokyo University  United States  \n",
       "217  -88.609499                  Tokyo University  United States  \n",
       "218  -88.609499                  Tokyo University  United States  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universities[(universities.country != universities.Country) & (\n",
    "    universities.country.notna()) & (universities.Country.notna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_uni = {}\n",
    "for i, row in universities[universities.University.notna() & universities.country.notna()].iterrows():\n",
    "    uni_uni[row.University] = row.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities.loc[universities.University.isin(uni_uni.keys()), 'country'] = universities.University.map(uni_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities.loc[(universities.country != universities.Country) & (\n",
    "    universities.country.isna()) & (universities.Country.notna()), 'country'] = universities.Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "del universities['University'], universities['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities.to_csv('data/Universities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with this data we can do some stuff:\n",
    "- Papers with authors of different origin\n",
    "- use predominant nation to remake above plot - maybe papers in the us have more coauthors -> need to find some way to normalize data\n",
    "- look at cross institution & cross country\n",
    "- maybe even look at cross continent collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
